{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fixed to have subjects stay within one fold\n",
    "\n",
    "# thresh = 0\n",
    "# k_folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# train_rmse_scores = []\n",
    "# val_rmse_scores = []\n",
    "# subjects_profiles_CVsplit_LR = {}\n",
    "# all_train_data = {}\n",
    "# all_val_data = {}\n",
    "\n",
    "# # Groups setup\n",
    "# groups = [str(group) for group in np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed['Group'])]\n",
    "# group_train_rmse = {group: [] for group in groups}\n",
    "# group_val_rmse = {group: [] for group in groups}\n",
    "\n",
    "# group_k_fold = GroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# for fold_idx, (train_idx, val_idx) in enumerate(group_k_fold.split(X_train10, groups=X_train10['Subject'])):\n",
    "#     X_fold_train, X_fold_val = X_train10.iloc[train_idx], X_train10.iloc[val_idx]\n",
    "#     y_fold_train, y_fold_val = y1_train10.iloc[train_idx], y1_train10.iloc[val_idx]\n",
    "    \n",
    "#     print(f\"\\nProcessing Fold {fold_idx+1}\")\n",
    "    \n",
    "#     # First, build the Bayesian profiles for each subject\n",
    "#     for subject in np.unique(X_fold_train['Subject']):\n",
    "#         profile_key = f\"{subject}\"\n",
    "#         subjects_profiles_CVsplit_LR[profile_key] = BayesianProfile_LRcompare()\n",
    "        \n",
    "#         subject_data = X_fold_train[X_fold_train['Subject'] == subject]\n",
    "        \n",
    "#         # Group by the combination of features that define unique conditions\n",
    "#         grouped = subject_data.groupby([\n",
    "#             'Freq(kHz) (x1)', 'Amplitude (x3)', 'Strain (x5)',   \n",
    "#             'Group'\n",
    "#         ])\n",
    "        \n",
    "#         # Process each group (condition)\n",
    "#         for group_key, group_data in grouped:\n",
    "#             if group_data['Level(dB) (x2)'].min() < thresh:\n",
    "#                 continue\n",
    "                \n",
    "#             # Get all y1 values for this condition\n",
    "#             indices = group_data.index\n",
    "#             y_values = y_fold_train.loc[indices]\n",
    "            \n",
    "#             # Extract feature values (same for all rows in group)\n",
    "#             x1_val = group_data['Freq(kHz) (x1)'].iloc[0]\n",
    "#             x2_val = group_data['Level(dB) (x2)'].iloc[0]\n",
    "#             x3_val = group_data['Amplitude (x3)'].iloc[0]\n",
    "            \n",
    "#             # Add each observation with same features but different y values\n",
    "#             for idx, y1_val in zip(indices, y_values):\n",
    "#                 subjects_profiles_CVsplit_LR[profile_key].add_observation_y1(\n",
    "#                     x1=x1_val, x2=x2_val, x3=x3_val,\n",
    "#                     y1=float(y1_val),\n",
    "#                 )\n",
    "    \n",
    "#     # Now calculate RMSE for this fold (both training and validation)\n",
    "#     # Store predictions in a dictionary keyed by index\n",
    "#         train_predictions = {}\n",
    "        \n",
    "#         for idx, row in X_fold_train.iterrows():\n",
    "#             if row['Level(dB) (x2)'] >= thresh:\n",
    "#                 subject = row['Subject']\n",
    "#                 profile_key = f\"{subject}\"\n",
    "#                 x1_train = row['Freq(kHz) (x1)']\n",
    "#                 x2_train = row['Level(dB) (x2)']\n",
    "#                 x3_train = row['Amplitude (x3)']\n",
    "#             if profile_key in subjects_profiles_CVsplit_LR:\n",
    "#                 pred = subjects_profiles_CVsplit_LR[profile_key].predict_y1(x1= x1_train, x2=x2_train, x3=x3_train)\n",
    "#                 train_predictions[idx] = float(pred)  # Ensure it's a scalar\n",
    "\n",
    "#         # Create pandas Series with predictions matched to proper indices\n",
    "#         successful_train_indices = list(train_predictions.keys())\n",
    "        \n",
    "#         if successful_train_indices:\n",
    "#             y_train_true = y_fold_train.loc[successful_train_indices]\n",
    "#             y_train_pred = pd.Series([train_predictions[idx] for idx in successful_train_indices], \n",
    "#                                     index=successful_train_indices)\n",
    "            \n",
    "#             # Do the same for validation\n",
    "#         val_predictions = {}\n",
    "        \n",
    "#         for idx, row in X_fold_val.iterrows():\n",
    "#             if row['Level(dB) (x2)'] >= thresh:\n",
    "#                 subject = row['Subject']\n",
    "#                 profile_key = f\"{subject}\"\n",
    "#                 x1_val = row['Freq(kHz) (x1)']\n",
    "#                 x2_val = row['Level(dB) (x2)']\n",
    "#                 x3_val = row['Amplitude (x3)']\n",
    "#             if profile_key in subjects_profiles_CVsplit_LR:\n",
    "#                 pred = subjects_profiles_CVsplit_LR[profile_key].predict_y1(x1= x1_val, x2=x2_val, x3=x3_val)\n",
    "#                 val_predictions[idx] = float(pred)  # Ensure it's a scalar\n",
    "\n",
    "        \n",
    "#         # Create properly indexed validation predictions\n",
    "#         successful_val_indices = list(val_predictions.keys())\n",
    "        \n",
    "#         if successful_val_indices:\n",
    "#             y_val_true = y_fold_val.loc[successful_val_indices]\n",
    "#             y_val_pred = pd.Series([val_predictions[idx] for idx in successful_val_indices], \n",
    "#                                 index=successful_val_indices)\n",
    "            \n",
    "#             # Print basic information\n",
    "#             print(f\"Train: {len(successful_train_indices)} successful predictions out of {len(X_fold_train)}\")\n",
    "#             print(f\"Validation: {len(successful_val_indices)} successful predictions out of {len(X_fold_val)}\")\n",
    "            \n",
    "#             # Calculate RMSE\n",
    "#             true_name = f'{fold_idx} - train - true'\n",
    "#             pred_name = f'{fold_idx} - train - pred'\n",
    "#             all_train_data[true_name] = y_train_true\n",
    "#             all_train_data[pred_name] = y_train_pred\n",
    "\n",
    "#             fold_train_rmse = np.sqrt(np.mean((y_train_true - y_train_pred)**2))\n",
    "#             train_rmse_scores.append(fold_train_rmse)\n",
    "            \n",
    "#             true_name = f'{fold_idx} - val - true'\n",
    "#             pred_name = f'{fold_idx} - val - pred'\n",
    "#             all_val_data[true_name] = y_val_true\n",
    "#             all_val_data[pred_name] = y_val_pred\n",
    "\n",
    "#             fold_val_rmse = np.sqrt(np.mean((y_val_true - y_val_pred)**2))\n",
    "#             val_rmse_scores.append(fold_val_rmse)\n",
    "            \n",
    "#             print(f\"Fold {fold_idx+1}: Train RMSE = {fold_train_rmse:.4f}, Validation RMSE = {fold_val_rmse:.4f}\")\n",
    "                \n",
    "#                 # Calculate group-specific RMSE\n",
    "#     for group in groups:\n",
    "#         # Get the subject groups\n",
    "#         train_subjects_df = final_clean_strained_grouped_pos_cleangroup_vs_timed.loc[successful_train_indices]\n",
    "#         val_subjects_df = final_clean_strained_grouped_pos_cleangroup_vs_timed.loc[successful_val_indices]\n",
    "        \n",
    "#         # Filter for successful predictions for this group\n",
    "#         group_train_mask = train_subjects_df['Group'] == group\n",
    "#         if group_train_mask.any():\n",
    "#             group_indices = group_train_mask.index[group_train_mask]\n",
    "#             group_rmse = np.sqrt(np.mean((y_train_true.loc[group_indices] - y_train_pred.loc[group_indices])**2))\n",
    "#             group_train_rmse[group].append(group_rmse)\n",
    "        \n",
    "#         group_val_mask = val_subjects_df['Group'] == group\n",
    "#         if group_val_mask.any():\n",
    "#             group_indices = group_val_mask.index[group_val_mask]\n",
    "#             group_rmse = np.sqrt(np.mean((y_val_true.loc[group_indices] - y_val_pred.loc[group_indices])**2))\n",
    "#             group_val_rmse[group].append(group_rmse)\n",
    "#     else:\n",
    "#         print(f\"Fold {fold_idx+1}: No successful training predictions\")\n",
    "\n",
    "# # Calculate average RMSE across all folds\n",
    "# if train_rmse_scores:\n",
    "#     avg_train_rmse = np.mean(train_rmse_scores)\n",
    "#     std_train_rmse = np.std(train_rmse_scores)\n",
    "#     print(f\"\\nAverage Train RMSE across folds: {avg_train_rmse:.4f} ± {std_train_rmse:.4f}\")\n",
    "\n",
    "# if val_rmse_scores:\n",
    "#     avg_val_rmse = np.mean(val_rmse_scores)\n",
    "#     std_val_rmse = np.std(val_rmse_scores)\n",
    "#     print(f\"Average Validation RMSE across folds: {avg_val_rmse:.4f} ± {std_val_rmse:.4f}\")\n",
    "\n",
    "# # Calculate group-specific RMSE \n",
    "# print(\"\\nGroup-specific RMSE:\")\n",
    "# print(\"Group | Train RMSE (Mean ± Std) | Validation RMSE (Mean ± Std)\")\n",
    "# print(\"----- | ----------------------- | -----------------------------\")\n",
    "# for group in groups:\n",
    "#     train_values = group_train_rmse[group]\n",
    "#     val_values = group_val_rmse[group]\n",
    "    \n",
    "#     if train_values:\n",
    "#         train_mean = np.mean(train_values)\n",
    "#         train_std = np.std(train_values)\n",
    "#         train_str = f\"{train_mean:.6f} ± {train_std:.6f}\"\n",
    "#     else:\n",
    "#         train_str = \"N/A\"\n",
    "        \n",
    "#     if val_values:\n",
    "#         val_mean = np.mean(val_values)\n",
    "#         val_std = np.std(val_values)\n",
    "#         val_str = f\"{val_mean:.6f} ± {val_std:.6f}\"\n",
    "#     else:\n",
    "#         val_str = \"N/A\"\n",
    "        \n",
    "#     print(f\"{group:15s} | {train_str:25s} | {val_str:25s}\")\n",
    "\n",
    "# # Visualization of group-specific RMSE\n",
    "# if any(group_train_rmse[group] for group in groups) and any(group_val_rmse[group] for group in groups):\n",
    "#     # Prepare data for plotting\n",
    "#     plot_groups = []\n",
    "#     plot_train_rmse = []\n",
    "#     plot_val_rmse = []\n",
    "#     plot_train_std = []\n",
    "#     plot_val_std = []\n",
    "    \n",
    "#     for group in groups:\n",
    "#         if group_train_rmse[group] and group_val_rmse[group]:\n",
    "#             plot_groups.append(group)\n",
    "#             plot_train_rmse.append(np.mean(group_train_rmse[group]))\n",
    "#             plot_val_rmse.append(np.mean(group_val_rmse[group]))\n",
    "#             plot_train_std.append(np.std(group_train_rmse[group]))\n",
    "#             plot_val_std.append(np.std(group_val_rmse[group]))\n",
    "    \n",
    "#     # Create plot if we have data\n",
    "#     if plot_groups:\n",
    "#         plt.figure(figsize=(14, 7))\n",
    "#         x = np.arange(len(plot_groups))\n",
    "#         width = 0.35\n",
    "        \n",
    "#         plt.bar(x - width/2, plot_train_rmse, width, yerr=plot_train_std, \n",
    "#                 label='Train RMSE', color='blue', alpha=0.7, capsize=5)\n",
    "#         plt.bar(x + width/2, plot_val_rmse, width, yerr=plot_val_std,\n",
    "#                 label='Validation RMSE', color='red', alpha=0.7, capsize=5)\n",
    "        \n",
    "#         plt.xlabel('Group')\n",
    "#         plt.ylabel('RMSE')\n",
    "#         plt.ylim((0,5))\n",
    "#         plt.title('Bayesian Model Performance by Group (Mean ± Std)')\n",
    "#         plt.xticks(x, plot_groups, rotation=90)\n",
    "#         plt.legend()\n",
    "#         plt.grid(True, axis='y', alpha=0.3)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "# groups_list = []\n",
    "# train_mean_list = []\n",
    "# train_std_list = []\n",
    "# val_mean_list = []\n",
    "# val_std_list = []\n",
    "\n",
    "# # Extract values for each group\n",
    "# for group in sorted(group_train_rmse.keys()):\n",
    "#     train_values = group_train_rmse[group]\n",
    "#     val_values = group_val_rmse[group]\n",
    "    \n",
    "#     groups_list.append(group)\n",
    "    \n",
    "#     if train_values:\n",
    "#         train_mean_list.append(np.mean(train_values))\n",
    "#         train_std_list.append(np.std(train_values))\n",
    "#     else:\n",
    "#         train_mean_list.append(np.nan)\n",
    "#         train_std_list.append(np.nan)\n",
    "        \n",
    "#     if val_values:\n",
    "#         val_mean_list.append(np.mean(val_values))\n",
    "#         val_std_list.append(np.std(val_values))\n",
    "#     else:\n",
    "#         val_mean_list.append(np.nan)\n",
    "#         val_std_list.append(np.nan)\n",
    "\n",
    "\n",
    "# # Create lists to store the data\n",
    "# groups_list = []\n",
    "# train_mean_list = []\n",
    "# train_std_list = []\n",
    "# val_mean_list = []\n",
    "# val_std_list = []\n",
    "\n",
    "# # Extract values for each group\n",
    "# for group in sorted(group_train_rmse.keys()):\n",
    "#     train_values = group_train_rmse[group]\n",
    "#     val_values = group_val_rmse[group]\n",
    "    \n",
    "#     groups_list.append(group)\n",
    "    \n",
    "#     if train_values:\n",
    "#         train_mean_list.append(np.mean(train_values))\n",
    "#         train_std_list.append(np.std(train_values))\n",
    "#     else:\n",
    "#         train_mean_list.append(np.nan)\n",
    "#         train_std_list.append(np.nan)\n",
    "        \n",
    "#     if val_values:\n",
    "#         val_mean_list.append(np.mean(val_values))\n",
    "#         val_std_list.append(np.std(val_values))\n",
    "#     else:\n",
    "#         val_mean_list.append(np.nan)\n",
    "#         val_std_list.append(np.nan)\n",
    "\n",
    "# group_metrics_df = pd.DataFrame({\n",
    "#     'Group': groups_list,\n",
    "#     'Train_RMSE_Mean': train_mean_list,\n",
    "#     'Val_RMSE_Mean': val_mean_list,\n",
    "#     'Train_RMSE_Std': train_std_list,\n",
    "#     'Val_RMSE_Std': val_std_list\n",
    "# })\n",
    "\n",
    "# group_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 10:57:05.149 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.439 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/new_manorimagepred/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-14 10:57:05.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.442 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.442 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.444 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.445 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.445 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.446 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-14 10:57:05.447 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.448 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.449 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.449 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.449 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-14 10:57:05.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.distributed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ABRA_35 import interpolate_and_smooth, CNN, plot_wave, calculate_and_plot_wave, plot_waves_single_frequency, arfread, get_str, calculate_hearing_threshold, all_thresholds, peak_finding\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import os\n",
    "import struct\n",
    "import datetime\n",
    "# from skfda import FDataGrid\n",
    "# from skfda.preprocessing.dim_reduction import FPCA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import torch.nn as nn\n",
    "import splitfolders\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import find_peaks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np4\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (fc1): Linear(in_features=1952, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (dropout_fc): Dropout(p=0.1, inplace=False)\n",
       "  (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter1 = 128\n",
    "filter2 = 32\n",
    "dropout1 = 0.5\n",
    "dropout2 = 0.3\n",
    "dropout_fc = 0.1\n",
    "\n",
    "# Model initialization\n",
    "peak_finding_model = CNN(filter1, filter2, dropout1, dropout2, dropout_fc)\n",
    "model_loader = torch.load('./models/waveI_cnn.pth')\n",
    "peak_finding_model.load_state_dict(model_loader)\n",
    "peak_finding_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_finding(wave):\n",
    "    # Prepare waveform\n",
    "    waveform=interpolate_and_smooth(wave) # Added indexing per calculate and plot wave function\n",
    "    # waveform_torch = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0) archived ABRA\n",
    "    waveform_torch = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).unsqueeze(0) #newer ABRA\n",
    "    # print(waveform_torch)\n",
    "    # Get prediction from model\n",
    "    outputs = peak_finding_model(waveform_torch)\n",
    "    prediction = int(round(outputs.detach().numpy()[0][0], 0))\n",
    "    # prediction_test = int(round(outputs.detach().numpy()[0], 0))\n",
    "    # print(\"Model output:\", outputs, \"Prediction true start:\", prediction)\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    smoothed_waveform = gaussian_filter1d(waveform, sigma=1)\n",
    "\n",
    "    # Find peaks and troughs\n",
    "    n = 18\n",
    "    t = 14\n",
    "    # start_point = prediction - 9 archived ABRA\n",
    "    start_point = prediction - 6 #newer ABRA\n",
    "    smoothed_peaks, _ = find_peaks(smoothed_waveform[start_point:], distance=n)\n",
    "    smoothed_troughs, _ = find_peaks(-smoothed_waveform, distance=t)\n",
    "    sorted_indices = np.argsort(smoothed_waveform[smoothed_peaks+start_point])\n",
    "    highest_smoothed_peaks = np.sort(smoothed_peaks[sorted_indices[-5:]] + start_point)\n",
    "    relevant_troughs = np.array([])\n",
    "    for p in range(len(highest_smoothed_peaks)):\n",
    "        c = 0\n",
    "        for t in smoothed_troughs:\n",
    "            if t > highest_smoothed_peaks[p]:\n",
    "                if p != 4:\n",
    "                    try:\n",
    "                        if t < highest_smoothed_peaks[p+1]:\n",
    "                            relevant_troughs = np.append(relevant_troughs, int(t))\n",
    "                            break\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                else:\n",
    "                    relevant_troughs = np.append(relevant_troughs, int(t))\n",
    "                    break\n",
    "    relevant_troughs = relevant_troughs.astype('i')\n",
    "    return highest_smoothed_peaks, relevant_troughs\n",
    "\n",
    "def extract_metadata(metadata_lines):\n",
    "    # Dictionary to store extracted metadata\n",
    "    metadata = {}\n",
    "    \n",
    "    for line in metadata_lines:\n",
    "        # Extract SW FREQ\n",
    "        freq_match = re.search(r'SW FREQ:\\s*(\\d+\\.?\\d*)', line)\n",
    "        if freq_match:\n",
    "            metadata['SW_FREQ'] = float(freq_match.group(1))\n",
    "        \n",
    "        # Extract LEVELS\n",
    "        levels_match = re.search(r':LEVELS:\\s*([^:]+)', line)\n",
    "        if levels_match:\n",
    "            # Split levels and convert to list of floats\n",
    "            metadata['LEVELS'] = [float(level) for level in levels_match.group(1).split(';') if level]\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def read_custom_tsv(file_path):\n",
    "    # Read the entire file\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split the content into metadata and data sections\n",
    "    metadata_lines = []\n",
    "    data_section = None\n",
    "    \n",
    "    # Find the ':DATA' marker\n",
    "    data_start = content.find(':DATA')\n",
    "    \n",
    "    if data_start != -1:\n",
    "        # Extract metadata (lines before ':DATA')\n",
    "        metadata_lines = content[:data_start].split('\\n')\n",
    "        \n",
    "        # Extract data section\n",
    "        data_section = content[data_start:].split(':DATA')[1].strip()\n",
    "    \n",
    "    # Extract specific metadata\n",
    "    metadata = extract_metadata(metadata_lines)\n",
    "    \n",
    "    # Read the data section directly\n",
    "    try:\n",
    "        # Use StringIO to create a file-like object from the data section\n",
    "        raw_data = pd.read_csv(\n",
    "            io.StringIO(data_section), \n",
    "            sep='\\s+',  # Use whitespace as separator\n",
    "            header=None\n",
    "        )\n",
    "        raw_data = raw_data.T\n",
    "        # Add metadata columns to the DataFrame\n",
    "        if 'SW_FREQ' in metadata:\n",
    "            raw_data['Freq(kHz)'] = metadata['SW_FREQ']\n",
    "            # raw_data['Freq(Hz)'] = raw_data['Freq(Hz)'].apply(lambda x: x*1000)\n",
    "        \n",
    "        if 'LEVELS' in metadata:\n",
    "            # Repeat levels to match the number of rows\n",
    "            levels_repeated = metadata['LEVELS'] * (len(raw_data) // len(metadata['LEVELS']) + 1)\n",
    "            raw_data['Level(dB)'] = levels_repeated[:len(raw_data)]\n",
    "        \n",
    "        filtered_data = raw_data.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "        filtered_data.columns = filtered_data.columns.map(str)\n",
    "\n",
    "        columns = ['Freq(kHz)'] + ['Level(dB)'] + [col for col in filtered_data.columns if col.isnumeric() == True]\n",
    "        filtered_data = filtered_data[columns]\n",
    "        return filtered_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data: {e}\")\n",
    "        return None, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_troughs_amp_final(df, freq, db, time_scale=10, multiply_y_factor=1.0, units='Microvolts'):\n",
    "    db_column = 'Level(dB)'\n",
    "    \n",
    "    khz = df[(df['Freq(kHz)'] == freq) & (df[db_column] == db)]\n",
    "    if not khz.empty:\n",
    "        index = khz.index.values[0]\n",
    "        final = df.loc[index, '0':].dropna()\n",
    "        final = pd.to_numeric(final, errors='coerce').dropna()\n",
    "\n",
    "        target = int(244 * (time_scale / 10))\n",
    "        \n",
    "        # Process the wave as in calculate_and_plot_wave\n",
    "        y_values = interpolate_and_smooth(final, target)\n",
    "        \n",
    "        # Apply scaling factor\n",
    "        y_values *= multiply_y_factor\n",
    "        \n",
    "        # Handle units conversion if needed\n",
    "        if units == 'Nanovolts':\n",
    "            y_values /= 1000\n",
    "            \n",
    "        # Generate normalized version for peak finding\n",
    "        y_values_fpf = interpolate_and_smooth(y_values[:244])\n",
    "        \n",
    "        # Standardize and normalize for peak finding, exactly as in the original\n",
    "        flattened_data = y_values_fpf.flatten().reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        standardized_data = scaler.fit_transform(flattened_data)\n",
    "        min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = min_max_scaler.fit_transform(standardized_data).reshape(y_values_fpf.shape)\n",
    "        y_values_fpf = interpolate_and_smooth(scaled_data[:244])\n",
    "        \n",
    "        # Find peaks using the normalized data\n",
    "        highest_peaks, relevant_troughs = peak_finding(y_values_fpf)\n",
    "        \n",
    "        # Calculate amplitude on the processed but non-normalized data\n",
    "        if highest_peaks.size > 0 and relevant_troughs.size > 0:\n",
    "            # Following the same approach as in the display_metrics_table function\n",
    "            first_peak_amplitude = y_values[highest_peaks[0]] - y_values[relevant_troughs[0]]\n",
    "            return highest_peaks, relevant_troughs, first_peak_amplitude\n",
    "    \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del int\n",
    "time_scale = 18\n",
    "amp_per_freq = {'Subject': [], 'Freq(kHz) (x1)': [], 'Level(dB) (x2)': [], 'Amplitude (x3)':[]}\n",
    "start_path = '/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/abr_data/WPZ Electrophysiology'\n",
    "for subject in os.listdir(start_path):\n",
    "    # print(\"Subject:\",subject)\n",
    "    for fq in os.listdir(os.path.join(start_path,subject)):\n",
    "        # print(fq)\n",
    "        if fq.startswith('ABR') and fq.endswith('.tsv'):\n",
    "            path = os.path.join(start_path,subject,fq)\n",
    "            data_df = read_custom_tsv(path)\n",
    "            # print(data_df)\n",
    "            freqs = data_df['Freq(kHz)'].unique().tolist()\n",
    "            levels = data_df['Level(dB)'].unique().tolist()\n",
    "            for freq in freqs:\n",
    "                for lvl in levels:\n",
    "                    # print(\"Frequency=\",freq, \"Level=\", lvl)\n",
    "                    _, _, amp = peaks_troughs_amp_final(df=data_df, freq=freq, db=lvl, time_scale=time_scale)\n",
    "                    # print(f'Amplitude: {amp}\\n')\n",
    "                    amp_per_freq['Subject'].append(subject)\n",
    "                    amp_per_freq['Freq(kHz) (x1)'].append(freq)\n",
    "                    amp_per_freq['Level(dB) (x2)'].append(lvl)\n",
    "                    amp_per_freq['Amplitude (x3)'].append(amp)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "amp_df_full = pd.DataFrame(data=amp_per_freq)\n",
    "\n",
    "raw_synapse_counts = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Ribbon and Synapse Counts.xlsx')\n",
    "raw_synapse_counts = raw_synapse_counts.mask(lambda x: x.isnull()).dropna()\n",
    "raw_synapse_counts['Synapses to IHC (y1)'] = raw_synapse_counts.iloc[:,6]\n",
    "raw_synapse_counts['vx (x4)'] = raw_synapse_counts['vx']\n",
    "raw_synapse_counts.drop(columns=['vx'], inplace=True)\n",
    "raw_synapse_counts.rename(columns={'Freq':'Freq(kHz) (x1)'}, inplace=True)\n",
    "# raw_synapse_counts['Freq(Hz) (x1)'] = raw_synapse_counts['Freq(Hz) (x1)'].apply(lambda x: x*1000) # PUTTING BACK\n",
    "raw_synapse_counts.rename(columns={'Case':'Subject'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1 - values per vx\n",
    "\n",
    "paired = amp_df_full.join(raw_synapse_counts.set_index(['Subject', 'Freq(kHz) (x1)']), on=['Subject', 'Freq(kHz) (x1)'])\n",
    "# slice = paired[paired['Subject']=='WPZ174'][['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs (y2)']]\n",
    "final = paired[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs']]\n",
    "final_clean = final.dropna()\n",
    "\n",
    "# adding in the strain feature\n",
    "strains = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Mouse groups.xlsx')\n",
    "final_clean_strained = final_clean.join(strains.set_index('ID#'), on='Subject')\n",
    "final_clean_strained['Strain'] = final_clean_strained['Strain'].str.strip()\n",
    "final_clean_strained = final_clean_strained.rename(columns={'Strain': 'Strain (x5)'})\n",
    "final_clean_strained = final_clean_strained.dropna()\n",
    "final_clean_strained = final_clean_strained[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)', 'Strain (x5)', 'Synapses to IHC (y1)', 'Group']]\n",
    "\n",
    "final_clean_strained_grouped = final_clean_strained.copy()\n",
    "final_clean_strained_grouped['Group - dB'] = final_clean_strained_grouped['Group'].apply(lambda x: x.split(' ')[0] if x.split(' ')[0].endswith('dB') else 'Control')\n",
    "final_clean_strained_grouped['Group - Time Elapsed'] = final_clean_strained_grouped['Group'].apply(lambda x: x.split(' ')[1] if x.split(' ')[1].endswith(('h', 'wks', 'w')) else x.split(' ')[0])\n",
    "final_clean_strained_grouped.head()\n",
    "\n",
    "final_clean_strained_grouped_pos = final_clean_strained_grouped.copy()\n",
    "final_clean_strained_grouped_pos['Amplitude (x3)'] = final_clean_strained_grouped['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup = final_clean_strained_grouped_pos.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup['Group'] = final_clean_strained_grouped_pos_cleangroup['Group'].apply(lambda x: x.strip())\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup.head()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs = final_clean_strained_grouped_pos_cleangroup.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - dB']\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed']\n",
    "final_clean_strained_grouped_pos_cleangroup_vs = final_clean_strained_grouped_pos_cleangroup_vs[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)',\n",
    "       'vx (x4)', 'Strain (x5)','Group - dB (x6)', 'Group - Time Elapsed', 'Group','Synapses to IHC (y1)']]\n",
    "\n",
    "def split_on_number(input_string):\n",
    "    return re.findall(r\"[A-Za-z]+|\\d+\", input_string)\n",
    "\n",
    "hrs_week = 24*7\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed = final_clean_strained_grouped_pos_cleangroup_vs.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: '0dB' if x == 'Control' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'].apply(lambda x: x[1])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'].apply(lambda x: \"wks\" if x == 'w' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Hours Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed.apply(lambda row: row['Group - Time Elapsed - Magn.']* hrs_week if row['Group - Time Elapsed - Unit'] == 'wks' else row['Group - Time Elapsed - Magn.'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9.831461\n",
       "0        9.831461\n",
       "1        9.831461\n",
       "1        9.831461\n",
       "2        9.831461\n",
       "          ...    \n",
       "7328    16.170213\n",
       "7329    16.170213\n",
       "7329    16.170213\n",
       "7330    16.170213\n",
       "7330    16.170213\n",
       "Name: Synapse to IHC Ratio per Freq (y2), Length: 12187, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 2 - Averaged per Vx\n",
    "\n",
    "paired2 = amp_df_full.join(raw_synapse_counts.set_index(['Subject', 'Freq(kHz) (x1)']), on=['Subject', 'Freq(kHz) (x1)'])\n",
    "# lilslice = paired[paired['Subject']=='WPZ174'][['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs']]\n",
    "final2 = paired2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'Synapses', 'IHCs']]\n",
    "final_clean2 = final2.dropna()\n",
    "\n",
    "# adding in the strain feature\n",
    "strains = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Mouse groups.xlsx')\n",
    "final_clean_strained2 = final_clean2.join(strains.set_index('ID#'), on='Subject')\n",
    "final_clean_strained2['Strain'] = final_clean_strained2['Strain'].str.strip()\n",
    "final_clean_strained2 = final_clean_strained2.rename(columns={'Strain': 'Strain (x5)'})\n",
    "final_clean_strained2 = final_clean_strained2.dropna()\n",
    "final_clean_strained2 = final_clean_strained2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)', 'Strain (x5)', 'Synapses to IHC (y1)', 'Group', 'Synapses', 'IHCs']]\n",
    "# np.unique(final_clean_strained2['Group'])\n",
    "\n",
    "# final_clean_70 = final_clean[final_clean['Level(dB) (x2)'] >= 70.0]\n",
    "# final_clean_strained_70 = final_clean_strained[final_clean_strained['Level(dB) (x2)'] >= 70.0]\n",
    "# # np.unique(final_clean['Level(dB) (x2)']) max level is 80 db\n",
    "# len(final_clean), len(final_clean_70) # 10000 less data points!!!\n",
    "\n",
    "final_clean_strained_grouped2 = final_clean_strained2.copy()\n",
    "final_clean_strained_grouped2['Group - dB'] = final_clean_strained_grouped2['Group'].apply(lambda x: x.split(' ')[0] if x.split(' ')[0].endswith('dB') else 'Control')\n",
    "final_clean_strained_grouped2['Group - Time Elapsed'] = final_clean_strained_grouped2['Group'].apply(lambda x: x.split(' ')[1] if x.split(' ')[1].endswith(('h', 'wks', 'w')) else x.split(' ')[0])\n",
    "final_clean_strained_grouped2.head()\n",
    "\n",
    "final_clean_strained_grouped_pos2 = final_clean_strained_grouped2.copy()\n",
    "final_clean_strained_grouped_pos2['Amplitude (x3)'] = final_clean_strained_grouped2['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "len(final_clean_strained_grouped_pos2[final_clean_strained_grouped_pos2['Amplitude (x3)'] < 0])\n",
    "\n",
    "final_clean_strained_grouped_pos2['Amplitude (x3)'] = final_clean_strained_grouped2['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# final_clean_strained_grouped_pos[(final_clean_strained_grouped_pos['Subject'] == 'WPZ66') & (final_clean_strained_grouped_pos['Amplitude (x3)'] ==0.055901451434921576)\n",
    "final_clean_strained_grouped_pos_cleangroup2 = final_clean_strained_grouped_pos2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup2['Group'] = final_clean_strained_grouped_pos_cleangroup2['Group'].apply(lambda x: x.strip())\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup2['Group'])\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup2.head()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2 = final_clean_strained_grouped_pos_cleangroup2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs2['Group - dB']\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed']\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2 = final_clean_strained_grouped_pos_cleangroup_vs2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)',\n",
    "       'vx (x4)', 'Strain (x5)','Group - dB (x6)', 'Group - Time Elapsed', 'Group','Synapses to IHC (y1)', 'Synapses', 'IHCs']]\n",
    "\n",
    "def split_on_number(input_string):\n",
    "    return re.findall(r\"[A-Za-z]+|\\d+\", input_string)\n",
    "\n",
    "hrs_week = 24*7\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2 = final_clean_strained_grouped_pos_cleangroup_vs2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: '0dB' if x == 'Control' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'].apply(lambda x: x[1])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'].apply(lambda x: \"wks\" if x == 'w' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Hours Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2.apply(lambda row: row['Group - Time Elapsed - Magn.']* hrs_week if row['Group - Time Elapsed - Unit'] == 'wks' else row['Group - Time Elapsed - Magn.'], axis = 1)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2\n",
    "\n",
    "freqs = np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2['Freq(kHz) (x1)'])\n",
    "subs = np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2['Subject'])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx = final_clean_strained_grouped_pos_cleangroup_vs_timed2.copy()\n",
    "for freq in freqs:\n",
    "    for sub in subs:\n",
    "        mask = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub)] # global for updates\n",
    "        if len(mask) > 0:\n",
    "\n",
    "            mask1 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['vx (x4)'] == 'v1')]\n",
    "            mask2 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['vx (x4)'] == 'v2')]\n",
    "\n",
    "            if not mask1.empty and not mask2.empty:\n",
    "                mask1 = mask1.reset_index().iloc[0,:]\n",
    "                mask2 = mask2.reset_index().iloc[0,:]\n",
    "\n",
    "                total_syns = float(mask1['Synapses'] + mask2['Synapses'])\n",
    "                total_ihcs = float(mask1['IHCs'] + mask2['IHCs'])\n",
    "                ratio = total_syns / total_ihcs\n",
    "                # print(total_syns, total_ihcs)\n",
    "                # if total_syns == 0.0 or total_ihcs == 0.0:\n",
    "                #     print(sub, freq)\n",
    "                mask_index = mask.index\n",
    "                final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[mask_index,'Synapse to IHC Ratio per Freq (y2)'] = ratio\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Synapse to IHC Ratio per Freq (y2)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianProfile_LRcompare:\n",
    "    def __init__(self, training_data=None, prior_mean_y1=None, prior_cov_y1=None):\n",
    "        \"\"\"\n",
    "        Initialize a Bayesian profile with static scaling\n",
    "        \n",
    "        Parameters:\n",
    "        training_data: DataFrame with initial data to fit scalers\n",
    "        prior_mean: Initial guess for parameters (default: zeros)\n",
    "        prior_cov: Initial uncertainty in parameters (default: identity matrix)\n",
    "        \"\"\"\n",
    "        # For 48 parameters: intercept, x1, x3, interaction\n",
    "        self.n_params = 4\n",
    "        \n",
    "        # Initialize priors\n",
    "        if prior_mean_y1 is None:\n",
    "            self.mean_y1 = np.zeros(self.n_params)\n",
    "        else:\n",
    "            self.mean_y1 = prior_mean_y1\n",
    "            \n",
    "        if prior_cov_y1 is None:\n",
    "            self.cov_y1 = np.eye(self.n_params) * 10  # Start with high uncertainty\n",
    "        else:\n",
    "            self.cov_y1 = prior_cov_y1\n",
    "\n",
    "        # Keep track of all data points\n",
    "        self.X_history = []\n",
    "        self.y1_history = []\n",
    "        \n",
    "        # For tracking prediction performance\n",
    "        self.rmse_history_y1 = []\n",
    "        \n",
    "        # Initialize scalers\n",
    "        self.x1_scaler = StandardScaler()\n",
    "        self.x3_scaler = StandardScaler()\n",
    "        \n",
    "        # Initialize scaling flag\n",
    "        self.scaling_applied = False\n",
    "        \n",
    "        # Fit scalers if training data is provided\n",
    "        if training_data is not None:\n",
    "            self._initialize_scalers(training_data)\n",
    "\n",
    "    def _initialize_scalers(self, data):\n",
    "        \"\"\"\n",
    "        Initialize scalers with training data\n",
    "        \"\"\"\n",
    "        if 'Freq(kHz) (x1)' in data.columns and 'Amplitude (x3)' in data.columns:\n",
    "            # Fit scalers to all training data once\n",
    "            self.x1_scaler.fit(data['Freq(kHz) (x1)'].values.reshape(-1,1))\n",
    "            self.x3_scaler.fit(data['Amplitude (x3)'].values.reshape(-1, 1))\n",
    "            self.scaling_applied = True\n",
    "            print(f\"Scalers initialized with {len(data)} records\")\n",
    "        else:\n",
    "            print(\"Warning: Training data missing required columns for scaling\")\n",
    "\n",
    "    def _scale_x1(self, x1):\n",
    "        \"\"\"\n",
    "        Scale x3 using the fitted scaler\n",
    "        \"\"\"\n",
    "        if not self.scaling_applied:\n",
    "            return x1  # Return as is if scaler not fit\n",
    "        \n",
    "        x1_array = np.array([float(x1)]).reshape(-1, 1)\n",
    "        return self.x1_scaler.transform(x1_array)[0][0]\n",
    "\n",
    "    def _scale_x3(self, x3):\n",
    "        \"\"\"\n",
    "        Scale x3 using the fitted scaler\n",
    "        \"\"\"\n",
    "        if not self.scaling_applied:\n",
    "            return x3\n",
    "        \n",
    "        x3_array = np.array([float(x3)]).reshape(-1, 1)\n",
    "        return self.x3_scaler.transform(x3_array)[0][0]\n",
    "        \n",
    "    def add_observation_y1(self, x1, x3, y1, noise_var=1.0, prior_mean_y1=None, prior_cov_y1=None):\n",
    "        \"\"\"\n",
    "        Update the profile with a new observation using static scaling\n",
    "        \"\"\"\n",
    "        self.raw_x1 = float(x1)\n",
    "        self.raw_x3 = float(x3)\n",
    "        self.raw_y1 = float(y1)\n",
    "        \n",
    "        x1_scaled = self._scale_x1(x1)\n",
    "        x3_scaled = self._scale_x3(x3)\n",
    "        \n",
    "        # Reshape for processing\n",
    "        x1_scaled = np.asarray(x1_scaled).reshape(1, -1)\n",
    "        x3_scaled = np.asarray(x3_scaled).reshape(1, -1)\n",
    "        \n",
    "        arrays_to_stack = [\n",
    "            np.ones(1).reshape(1, -1),        \n",
    "            x1_scaled,\n",
    "            x3_scaled,\n",
    "            (x1_scaled.T @ x3_scaled).reshape(1,-1)                                  \n",
    "        ]\n",
    "\n",
    "        X = np.hstack(arrays_to_stack)\n",
    "        self.X_history.append(X[0])\n",
    "        self.y1_history.append(float(y1))\n",
    "        \n",
    "        # Numerical stability in matrix inversion\n",
    "        try:\n",
    "            # regularization for numerical stability\n",
    "            K = self.cov_y1 @ X.T @ np.linalg.inv(X @ self.cov_y1 @ X.T + noise_var + 1e-8 * np.eye(X.shape[0]))\n",
    "            \n",
    "            innovation = y1 - float(X @ self.mean_y1)\n",
    "            self.mean_y1 = self.mean_y1 + (K.flatten() * innovation) # our coefficients/parameters!\n",
    "            self.cov_y1 = self.cov_y1 - (K @ X @ self.cov_y1) # prep for our next set of observations\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            print(f\"Matrix inversion error: {e}\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            predictions = []\n",
    "            for i, x_hist in enumerate(self.X_history):\n",
    "                # Extract features from history\n",
    "                hist_x1 = x_hist[1]\n",
    "                hist_x3 = x_hist[2]\n",
    "                    \n",
    "                try:\n",
    "                    # print(f\"self.mean_y1: {self.mean_y1}, self.cov_y1 shape: {self.cov_y1.shape}\")\n",
    "                    # print(f\"Trying to predict with x1={hist_x1}, x3={hist_x3}\")\n",
    "                    pred = self.predict_y1(x1=hist_x1, x3=hist_x3)\n",
    "                    # print(pred)\n",
    "                    if pred is not None and np.isfinite(pred):\n",
    "                        predictions.append(pred)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in !prediction! for RMSE: {e}\")\n",
    "                    predictions.append(self.y1_history[i])\n",
    "                    \n",
    "            if predictions:\n",
    "                rmse = np.sqrt(np.mean((np.array(self.y1_history) - np.array(predictions))**2))\n",
    "                if np.isfinite(rmse):\n",
    "                    self.rmse_history_y1.append(rmse)\n",
    "                else:\n",
    "                    # If we got an invalid RMSE, append the last valid one or 0\n",
    "                    if self.rmse_history_y1:\n",
    "                        self.rmse_history_y1.append(self.rmse_history_y1[-1])\n",
    "                        print(\"Invalid RMSE!! Check here\")\n",
    "                    else:\n",
    "                        self.rmse_history_y1.append(0.0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error !calculating! RMSE: {e}\")\n",
    "            # Append last RMSE or 0 if none exists\n",
    "            if self.rmse_history_y1:\n",
    "                self.rmse_history_y1.append(self.rmse_history_y1[-1])\n",
    "            else:\n",
    "                self.rmse_history_y1.append(0.0)\n",
    "\n",
    "    def predict_y1(self, x1,x3):\n",
    "        \"\"\"\n",
    "        Make a prediction for given input values with static scaling\n",
    "        \n",
    "        Parameters:\n",
    "        x1, x3: Input features (will be scaled if scaling is enabled)\n",
    "        x5: Categorical feature\n",
    "        x6, x7: Additional input features\n",
    "        \n",
    "        Returns:\n",
    "        float: Predicted value (in original scale)\n",
    "        \"\"\"\n",
    "        # Apply scaling if enabled\n",
    "        x1_scaled = self._scale_x1(x1)\n",
    "        x3_scaled = self._scale_x3(x3)\n",
    "        \n",
    "        # Reshape and encode\n",
    "        x1_scaled = np.asarray(x1_scaled).reshape(1, -1)\n",
    "        x3_scaled = np.asarray(x3_scaled).reshape(1, -1)\n",
    "        \n",
    "        # Create arrays to stack with correct shapes\n",
    "        arrays_to_stack = [\n",
    "            np.ones(1).reshape(1, -1),        \n",
    "            x1_scaled,\n",
    "            x3_scaled,\n",
    "            np.array(x1_scaled * x3_scaled).reshape(1, -1)                                  \n",
    "        ]\n",
    "\n",
    "        X = np.hstack(arrays_to_stack)\n",
    "\n",
    "        raw_pred = float(X @ self.mean_y1)\n",
    "        if not np.isfinite(raw_pred):\n",
    "            print(f\"Non-finite prediction for x1={x1_scaled},x3={x3_scaled}\")\n",
    "            # print(f\"Model coefficients: {self.mean_y1}\")\n",
    "        pred = max(0, raw_pred)\n",
    "        return pred\n",
    "\n",
    "    def predict_with_uncertainty_y1(self, x1, x3):\n",
    "        \"\"\"\n",
    "        Make a prediction with uncertainty bounds\n",
    "        \n",
    "        Returns:\n",
    "        tuple: (prediction, standard_deviation)\n",
    "        \"\"\"\n",
    "        # Apply scaling if enabled\n",
    "        x1_scaled = self._scale_x1(x1)\n",
    "        x3_scaled = self._scale_x3(x3)\n",
    "        \n",
    "        # Reshape and encode\n",
    "        x1_scaled = np.asarray(x1_scaled).reshape(1, -1)\n",
    "        x3_scaled = np.asarray(x3_scaled).reshape(1, -1)\n",
    "\n",
    "        # Create arrays to stack with correct shapes\n",
    "        arrays_to_stack = [\n",
    "            np.ones(1).reshape(1, -1),        \n",
    "            x1_scaled,\n",
    "            x3_scaled,\n",
    "            np.array(x1_scaled * x3_scaled).reshape(1, -1)                            \n",
    "        ]\n",
    "        \n",
    "        X = np.hstack(arrays_to_stack)\n",
    "        \n",
    "        # Predict\n",
    "        pred = float(X @ self.mean_y1)\n",
    "        std = float(np.sqrt(X @ self.cov_y1 @ X.T))\n",
    "        # pred_scaled = float(X @ self.mean_y1)\n",
    "        # std_scaled = float(np.sqrt(X @ self.cov_y1 @ X.T))\n",
    "\n",
    "        # if self.scaling_applied:\n",
    "        #     std = std_scaled * self.y1_scaler.scale_[0]\n",
    "        # else:\n",
    "        #     std = std_scaled\n",
    "        \n",
    "        # Check for valid values\n",
    "        if not np.isfinite(pred) or not np.isfinite(std):\n",
    "            print(f\"Warning: Non-finite prediction or std: {pred}, {std}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Transform back to original scale\n",
    "        # pred = self._inverse_scale_y1(pred_scaled)\n",
    "\n",
    "        pred = float(X @ self.mean_y1)\n",
    "        pred = max(0, pred)\n",
    "        std = float(np.sqrt(X @ self.cov_y1 @ X.T))\n",
    "\n",
    "        if not np.isfinite(pred) or not np.isfinite(std):\n",
    "            print(f\"Warning: Non-finite prediction or std: {pred}, {std}\")\n",
    "            return None, None\n",
    "        # Convert back to original scale if scaling was applied\n",
    "        return pred, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Older Approach - CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [8.0, 22.6], 1: [11.3, 32.0], 2: [16.0, 45.2]}\n"
     ]
    }
   ],
   "source": [
    "# Split data based on ABR recording frequencies and compare!!!!!!!\n",
    "# Because it doesn't make sense to have TT by subject for this given one model is specific to a subject...\n",
    "np.random.seed(43)\n",
    "groups = np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Group'])\n",
    "sorted_freqs = sorted(np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)']))\n",
    "\n",
    "freq_groups = {}\n",
    "for i, freq in enumerate(sorted_freqs):\n",
    "    # Splits up the frequencies into n groups\n",
    "    group_idx = i % 3\n",
    "    if group_idx not in freq_groups:\n",
    "        freq_groups[group_idx] = []\n",
    "    freq_groups[group_idx].append(freq)\n",
    "\n",
    "print(freq_groups)\n",
    "\n",
    "recs_by_group = {}\n",
    "for group in final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Group'].unique():\n",
    "    recs_in_group = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Group'] == group]\n",
    "    recs_by_group[group] = recs_in_group\n",
    "\n",
    "train_freqs = []\n",
    "test_freqs = []\n",
    "\n",
    "for group_idx, freqs in freq_groups.items():\n",
    "    # Shuffle frequencies within this group (kinda like RF. randomly splits on which freqs to use in train/test)\n",
    "    np.random.shuffle(freqs)\n",
    "    \n",
    "    n_test = max(1, round(len(freqs) * 0.2))  # Ensuring at least 2 frequencies are used for testing\n",
    "\n",
    "    # Add to overall train/test sets\n",
    "    test_freqs.extend(freqs[:n_test])\n",
    "    train_freqs.extend(freqs[n_test:])\n",
    "\n",
    "# train_indices = []\n",
    "# test_indices = []\n",
    "\n",
    "for group in np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Group']):\n",
    "    group_recs = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Group'] == group]\n",
    "    train_group_indices = group_recs[group_recs['Freq(kHz) (x1)'].isin(train_freqs)].index.tolist()\n",
    "    test_group_indices = group_recs[group_recs['Freq(kHz) (x1)'].isin(test_freqs)].index.tolist()\n",
    "\n",
    "    # test_indices.extend(test_group_indices)\n",
    "    # train_indices.extend(train_group_indices)\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for subject in np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject']):\n",
    "    subject_recs = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == subject]\n",
    "\n",
    "    train_subject_indices = subject_recs[subject_recs['Freq(kHz) (x1)'].isin(train_freqs)].index.tolist()\n",
    "    test_subject_indices = subject_recs[subject_recs['Freq(kHz) (x1)'].isin(test_freqs)].index.tolist()\n",
    "\n",
    "    # Ensure the subject has data in both splits\n",
    "    if len(train_subject_indices) == 0 or len(test_subject_indices) == 0:\n",
    "        continue  # Skip this subject to avoid leakage problems\n",
    "\n",
    "    test_indices.extend(test_subject_indices)\n",
    "    train_indices.extend(train_subject_indices)\n",
    "\n",
    "\n",
    "inputs = ['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)', 'Strain (x5)', 'Group']\n",
    "X_train10 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[train_indices, inputs]\n",
    "X_test10 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[test_indices, inputs]\n",
    "y1_train10 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[train_indices, 'Synapses to IHC (y1)']\n",
    "y1_test10 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[test_indices, 'Synapses to IHC (y1)']\n",
    "y2_train10 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[train_indices, 'Synapse to IHC Ratio per Freq (y2)']\n",
    "y2_test10 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[test_indices, 'Synapse to IHC Ratio per Freq (y2)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Fold 1\n",
      "Fold 1: No successful training predictions\n",
      "\n",
      "Processing Fold 2\n",
      "Train: 1899 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0123, Validation RMSE = 1.0472\n",
      "Train: 1899 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0123, Validation RMSE = 1.0472\n",
      "Train: 1899 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0123, Validation RMSE = 1.0472\n",
      "Train: 1899 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0123, Validation RMSE = 1.0472\n",
      "Train: 1928 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0124, Validation RMSE = 1.0472\n",
      "Train: 1928 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0124, Validation RMSE = 1.0472\n",
      "Train: 1928 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0124, Validation RMSE = 1.0472\n",
      "Train: 1928 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0124, Validation RMSE = 1.0472\n",
      "Train: 1958 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0118, Validation RMSE = 1.0472\n",
      "Train: 1984 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0065, Validation RMSE = 1.0472\n",
      "Train: 1984 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0065, Validation RMSE = 1.0472\n",
      "Train: 1984 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0065, Validation RMSE = 1.0472\n",
      "Train: 1984 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0065, Validation RMSE = 1.0472\n",
      "Train: 2011 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0027, Validation RMSE = 1.0472\n",
      "Train: 2011 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0027, Validation RMSE = 1.0472\n",
      "Train: 2011 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0027, Validation RMSE = 1.0472\n",
      "Train: 2011 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0027, Validation RMSE = 1.0472\n",
      "Train: 2011 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0027, Validation RMSE = 1.0472\n",
      "Train: 2011 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0027, Validation RMSE = 1.0472\n",
      "Train: 2011 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0027, Validation RMSE = 1.0472\n",
      "Train: 2038 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0068, Validation RMSE = 1.0472\n",
      "Train: 2038 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0068, Validation RMSE = 1.0472\n",
      "Train: 2038 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0068, Validation RMSE = 1.0472\n",
      "Train: 2068 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0081, Validation RMSE = 1.0472\n",
      "Train: 2087 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0097, Validation RMSE = 1.0472\n",
      "Train: 2087 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0097, Validation RMSE = 1.0472\n",
      "Train: 2105 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0098, Validation RMSE = 1.0472\n",
      "Train: 2105 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0098, Validation RMSE = 1.0472\n",
      "Train: 2105 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0098, Validation RMSE = 1.0472\n",
      "Train: 2105 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0098, Validation RMSE = 1.0472\n",
      "Train: 2105 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0098, Validation RMSE = 1.0472\n",
      "Train: 2105 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0098, Validation RMSE = 1.0472\n",
      "Train: 2105 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0098, Validation RMSE = 1.0472\n",
      "Train: 2138 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0113, Validation RMSE = 1.0472\n",
      "Train: 2138 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0113, Validation RMSE = 1.0472\n",
      "Train: 2156 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0085, Validation RMSE = 1.0472\n",
      "Train: 2156 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0085, Validation RMSE = 1.0472\n",
      "Train: 2156 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0085, Validation RMSE = 1.0472\n",
      "Train: 2156 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0085, Validation RMSE = 1.0472\n",
      "Train: 2156 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0085, Validation RMSE = 1.0472\n",
      "Train: 2156 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0085, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2183 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0030, Validation RMSE = 1.0472\n",
      "Train: 2215 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0053, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2248 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0180, Validation RMSE = 1.0472\n",
      "Train: 2286 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0174, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2319 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0129, Validation RMSE = 1.0472\n",
      "Train: 2346 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0110, Validation RMSE = 1.0472\n",
      "Train: 2346 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0110, Validation RMSE = 1.0472\n",
      "Train: 2346 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0110, Validation RMSE = 1.0472\n",
      "Train: 2346 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0110, Validation RMSE = 1.0472\n",
      "Train: 2346 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0110, Validation RMSE = 1.0472\n",
      "Train: 2368 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0137, Validation RMSE = 1.0472\n",
      "Train: 2368 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0137, Validation RMSE = 1.0472\n",
      "Train: 2402 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0121, Validation RMSE = 1.0472\n",
      "Train: 2402 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0121, Validation RMSE = 1.0472\n",
      "Train: 2402 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0121, Validation RMSE = 1.0472\n",
      "Train: 2431 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0100, Validation RMSE = 1.0472\n",
      "Train: 2431 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0100, Validation RMSE = 1.0472\n",
      "Train: 2431 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0100, Validation RMSE = 1.0472\n",
      "Train: 2431 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0100, Validation RMSE = 1.0472\n",
      "Train: 2467 successful predictions out of 9868\n",
      "Validation: 657 successful predictions out of 2628\n",
      "Fold 2: Train RMSE = 1.0050, Validation RMSE = 1.0472\n",
      "Fold 2: No successful training predictions\n",
      "\n",
      "Processing Fold 3\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Train: 2488 successful predictions out of 9952\n",
      "Validation: 636 successful predictions out of 2544\n",
      "Fold 3: Train RMSE = 1.0338, Validation RMSE = 0.9326\n",
      "Fold 3: No successful training predictions\n",
      "\n",
      "Processing Fold 4\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Train: 2513 successful predictions out of 10052\n",
      "Validation: 611 successful predictions out of 2444\n",
      "Fold 4: Train RMSE = 0.9819, Validation RMSE = 1.1369\n",
      "Fold 4: No successful training predictions\n",
      "\n",
      "Processing Fold 5\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Train: 2503 successful predictions out of 10012\n",
      "Validation: 621 successful predictions out of 2484\n",
      "Fold 5: Train RMSE = 1.0222, Validation RMSE = 0.9805\n",
      "Fold 5: No successful training predictions\n",
      "\n",
      "Average Train RMSE across folds: 1.0120 ± 0.0195\n",
      "Average Validation RMSE across folds: 1.0243 ± 0.0767\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Train_RMSE_Mean</th>\n",
       "      <th>Val_RMSE_Mean</th>\n",
       "      <th>Train_RMSE_Std</th>\n",
       "      <th>Val_RMSE_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101dB 24h post</td>\n",
       "      <td>0.978406</td>\n",
       "      <td>1.010828</td>\n",
       "      <td>0.305007</td>\n",
       "      <td>0.428902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14wks ctrl</td>\n",
       "      <td>1.008727</td>\n",
       "      <td>0.966016</td>\n",
       "      <td>0.072967</td>\n",
       "      <td>0.261657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6wks ctrl</td>\n",
       "      <td>1.027716</td>\n",
       "      <td>0.894390</td>\n",
       "      <td>0.057897</td>\n",
       "      <td>0.116552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>0.850256</td>\n",
       "      <td>0.969308</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.257919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90dB 0h post</td>\n",
       "      <td>0.969269</td>\n",
       "      <td>0.932447</td>\n",
       "      <td>0.090601</td>\n",
       "      <td>0.258693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>0.894460</td>\n",
       "      <td>1.014232</td>\n",
       "      <td>0.052467</td>\n",
       "      <td>0.060713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90dB 2w post</td>\n",
       "      <td>0.983162</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.047837</td>\n",
       "      <td>0.165073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94dB 0h post</td>\n",
       "      <td>1.071978</td>\n",
       "      <td>1.087340</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.458758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94dB 24h post</td>\n",
       "      <td>0.870703</td>\n",
       "      <td>0.749104</td>\n",
       "      <td>0.168378</td>\n",
       "      <td>0.355262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94dB 2w post</td>\n",
       "      <td>0.993267</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.077603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>94dB 8wks post</td>\n",
       "      <td>0.695101</td>\n",
       "      <td>0.565698</td>\n",
       "      <td>0.050616</td>\n",
       "      <td>0.152249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>98dB 24h post</td>\n",
       "      <td>1.190661</td>\n",
       "      <td>1.259850</td>\n",
       "      <td>0.079190</td>\n",
       "      <td>0.328657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>98dB 2w post</td>\n",
       "      <td>1.209657</td>\n",
       "      <td>1.342838</td>\n",
       "      <td>0.057234</td>\n",
       "      <td>0.295211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>1.148109</td>\n",
       "      <td>1.194249</td>\n",
       "      <td>0.097957</td>\n",
       "      <td>0.334510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Group  Train_RMSE_Mean  Val_RMSE_Mean  Train_RMSE_Std  \\\n",
       "0   101dB 24h post         0.978406       1.010828        0.305007   \n",
       "1       14wks ctrl         1.008727       0.966016        0.072967   \n",
       "2        6wks ctrl         1.027716       0.894390        0.057897   \n",
       "3        8wks ctrl         0.850256       0.969308        0.053936   \n",
       "4     90dB 0h post         0.969269       0.932447        0.090601   \n",
       "5    90dB 24h post         0.894460       1.014232        0.052467   \n",
       "6     90dB 2w post         0.983162       0.980913        0.047837   \n",
       "7     94dB 0h post         1.071978       1.087340        0.205128   \n",
       "8    94dB 24h post         0.870703       0.749104        0.168378   \n",
       "9     94dB 2w post         0.993267       0.995966        0.029321   \n",
       "10  94dB 8wks post         0.695101       0.565698        0.050616   \n",
       "11   98dB 24h post         1.190661       1.259850        0.079190   \n",
       "12    98dB 2w post         1.209657       1.342838        0.057234   \n",
       "13  98dB 8wks post         1.148109       1.194249        0.097957   \n",
       "\n",
       "    Val_RMSE_Std  \n",
       "0       0.428902  \n",
       "1       0.261657  \n",
       "2       0.116552  \n",
       "3       0.257919  \n",
       "4       0.258693  \n",
       "5       0.060713  \n",
       "6       0.165073  \n",
       "7       0.458758  \n",
       "8       0.355262  \n",
       "9       0.077603  \n",
       "10      0.152249  \n",
       "11      0.328657  \n",
       "12      0.295211  \n",
       "13      0.334510  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixed to have subjects stay within one fold\n",
    "\n",
    "thresh = 0\n",
    "# k_folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_rmse_scores = []\n",
    "val_rmse_scores = []\n",
    "subjects_profiles_CVsplit_LR = {}\n",
    "all_train_data = {}\n",
    "all_val_data = {}\n",
    "\n",
    "groups = [str(group) for group in np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed['Group'])]\n",
    "group_train_rmse = {group: [] for group in groups}\n",
    "group_val_rmse = {group: [] for group in groups}\n",
    "\n",
    "group_k_fold = GroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(group_k_fold.split(X_train10, groups=X_train10['Subject'])):\n",
    "    X_fold_train, X_fold_val = X_train10.iloc[train_idx], X_train10.iloc[val_idx]\n",
    "    y_fold_train, y_fold_val = y1_train10.iloc[train_idx], y1_train10.iloc[val_idx]\n",
    "    print(f\"\\nProcessing Fold {fold_idx+1}\")\n",
    "    \n",
    "    for subject in np.unique(X_fold_train['Subject']):\n",
    "        profile_key = f\"{subject}\"\n",
    "        subjects_profiles_CVsplit_LR[profile_key] = BayesianProfile_LRcompare()\n",
    "        \n",
    "        subject_data = X_fold_train[X_fold_train['Subject'] == subject]\n",
    "        \n",
    "        grouped = subject_data.groupby([\n",
    "            'Freq(kHz) (x1)', 'Amplitude (x3)', 'Strain (x5)',   \n",
    "            'Group'\n",
    "        ])\n",
    "        \n",
    "        for group_key, group_data in grouped:\n",
    "            if group_data['Level(dB) (x2)'].min() < thresh:\n",
    "                continue\n",
    "                \n",
    "            indices = group_data.index\n",
    "            y_values = y_fold_train.loc[indices]\n",
    "            \n",
    "            x1_val = group_data['Freq(kHz) (x1)'].iloc[0]\n",
    "            x3_val = group_data['Amplitude (x3)'].iloc[0]\n",
    "            \n",
    "            for idx, y1_val in zip(indices, y_values):\n",
    "                subjects_profiles_CVsplit_LR[profile_key].add_observation_y1(\n",
    "                    x1=x1_val,x3=x3_val,\n",
    "                    y1=float(y1_val),\n",
    "                )\n",
    "    \n",
    "        train_predictions = {}\n",
    "        \n",
    "        for idx, row in X_fold_train.iterrows():\n",
    "            if row['Level(dB) (x2)'] >= thresh:\n",
    "                subject = row['Subject']\n",
    "                profile_key = f\"{subject}\"\n",
    "                x1_train = row['Freq(kHz) (x1)']\n",
    "                x3_train = row['Amplitude (x3)']\n",
    "            if profile_key in subjects_profiles_CVsplit_LR:\n",
    "                pred = subjects_profiles_CVsplit_LR[profile_key].predict_y1(x1= x1_train, x3=x3_train)\n",
    "                train_predictions[idx] = float(pred) \n",
    "\n",
    "        successful_train_indices = list(train_predictions.keys())\n",
    "        \n",
    "        if successful_train_indices:\n",
    "            y_train_true = y_fold_train.loc[successful_train_indices]\n",
    "            y_train_pred = pd.Series([train_predictions[idx] for idx in successful_train_indices], \n",
    "                                    index=successful_train_indices)\n",
    "            \n",
    "            # Do the same for validation\n",
    "        val_predictions = {}\n",
    "        \n",
    "        for idx, row in X_fold_val.iterrows():\n",
    "            if row['Level(dB) (x2)'] >= thresh:\n",
    "                subject = row['Subject']\n",
    "                profile_key = f\"{subject}\"\n",
    "                x1_val = row['Freq(kHz) (x1)']\n",
    "                x3_val = row['Amplitude (x3)']\n",
    "            if profile_key in subjects_profiles_CVsplit_LR:\n",
    "                pred = subjects_profiles_CVsplit_LR[profile_key].predict_y1(x1= x1_val, x3=x3_val)\n",
    "                val_predictions[idx] = float(pred)  # Ensure it's a scalar\n",
    "\n",
    "        \n",
    "        # Create properly indexed validation predictions\n",
    "            successful_val_indices = list(val_predictions.keys())\n",
    "            \n",
    "        if successful_val_indices:\n",
    "            y_val_true = y_fold_val.loc[successful_val_indices]\n",
    "            y_val_pred = pd.Series([val_predictions[idx] for idx in successful_val_indices], \n",
    "                                index=successful_val_indices)\n",
    "            \n",
    "            # Print basic information\n",
    "            print(f\"Train: {len(successful_train_indices)} successful predictions out of {len(X_fold_train)}\")\n",
    "            print(f\"Validation: {len(successful_val_indices)} successful predictions out of {len(X_fold_val)}\")\n",
    "            \n",
    "            # Calculate RMSE\n",
    "            true_name = f'{fold_idx} - train - true'\n",
    "            pred_name = f'{fold_idx} - train - pred'\n",
    "            all_train_data[true_name] = y_train_true\n",
    "            all_train_data[pred_name] = y_train_pred\n",
    "\n",
    "            fold_train_rmse = np.sqrt(np.mean((y_train_true - y_train_pred)**2))\n",
    "            train_rmse_scores.append(fold_train_rmse)\n",
    "            \n",
    "            true_name = f'{fold_idx} - val - true'\n",
    "            pred_name = f'{fold_idx} - val - pred'\n",
    "            all_val_data[true_name] = y_val_true\n",
    "            all_val_data[pred_name] = y_val_pred\n",
    "\n",
    "            fold_val_rmse = np.sqrt(np.mean((y_val_true - y_val_pred)**2))\n",
    "            val_rmse_scores.append(fold_val_rmse)\n",
    "            \n",
    "            print(f\"Fold {fold_idx+1}: Train RMSE = {fold_train_rmse:.4f}, Validation RMSE = {fold_val_rmse:.4f}\")\n",
    "                    \n",
    "                    # Calculate group-specific RMSE\n",
    "            for group in groups:\n",
    "                # Get the subject groups\n",
    "                train_subjects_df = final_clean_strained_grouped_pos_cleangroup_vs_timed.loc[successful_train_indices]\n",
    "                val_subjects_df = final_clean_strained_grouped_pos_cleangroup_vs_timed.loc[successful_val_indices]\n",
    "                \n",
    "                # Filter for successful predictions for this group\n",
    "                group_train_mask = train_subjects_df['Group'] == group\n",
    "                if group_train_mask.any():\n",
    "                    group_indices = group_train_mask.index[group_train_mask]\n",
    "                    group_rmse = np.sqrt(np.mean((y_train_true.loc[group_indices] - y_train_pred.loc[group_indices])**2))\n",
    "                    group_train_rmse[group].append(group_rmse)\n",
    "                \n",
    "                group_val_mask = val_subjects_df['Group'] == group\n",
    "                if group_val_mask.any():\n",
    "                    group_indices = group_val_mask.index[group_val_mask]\n",
    "                    group_rmse = np.sqrt(np.mean((y_val_true.loc[group_indices] - y_val_pred.loc[group_indices])**2))\n",
    "                    group_val_rmse[group].append(group_rmse) \n",
    "    else:\n",
    "        print(f\"Fold {fold_idx+1}: No successful training predictions\")\n",
    "\n",
    "# Calculate average RMSE across all folds\n",
    "if train_rmse_scores:\n",
    "    avg_train_rmse = np.mean(train_rmse_scores)\n",
    "    std_train_rmse = np.std(train_rmse_scores)\n",
    "    print(f\"\\nAverage Train RMSE across folds: {avg_train_rmse:.4f} ± {std_train_rmse:.4f}\")\n",
    "\n",
    "if val_rmse_scores:\n",
    "    avg_val_rmse = np.mean(val_rmse_scores)\n",
    "    std_val_rmse = np.std(val_rmse_scores)\n",
    "    print(f\"Average Validation RMSE across folds: {avg_val_rmse:.4f} ± {std_val_rmse:.4f}\")\n",
    "\n",
    "# # Calculate group-specific RMSE \n",
    "# print(\"\\nGroup-specific RMSE:\")\n",
    "# print(\"Group | Train RMSE (Mean ± Std) | Validation RMSE (Mean ± Std)\")\n",
    "# print(\"----- | ----------------------- | -----------------------------\")\n",
    "# for group in groups:\n",
    "#     train_values = group_train_rmse[group]\n",
    "#     val_values = group_val_rmse[group]\n",
    "    \n",
    "#     if train_values:\n",
    "#         train_mean = np.mean(train_values)\n",
    "#         train_std = np.std(train_values)\n",
    "#         train_str = f\"{train_mean:.6f} ± {train_std:.6f}\"\n",
    "#     else:\n",
    "#         train_str = \"N/A\"\n",
    "        \n",
    "#     if val_values:\n",
    "#         val_mean = np.mean(val_values)\n",
    "#         val_std = np.std(val_values)\n",
    "#         val_str = f\"{val_mean:.6f} ± {val_std:.6f}\"\n",
    "#     else:\n",
    "#         val_str = \"N/A\"\n",
    "        \n",
    "#     print(f\"{group:15s} | {train_str:25s} | {val_str:25s}\")\n",
    "\n",
    "# Visualization of group-specific RMSE\n",
    "if any(group_train_rmse[group] for group in groups) and any(group_val_rmse[group] for group in groups):\n",
    "    # Prepare data for plotting\n",
    "    plot_groups = []\n",
    "    plot_train_rmse = []\n",
    "    plot_val_rmse = []\n",
    "    plot_train_std = []\n",
    "    plot_val_std = []\n",
    "    \n",
    "    for group in groups:\n",
    "        if group_train_rmse[group] and group_val_rmse[group]:\n",
    "            plot_groups.append(group)\n",
    "            plot_train_rmse.append(np.mean(group_train_rmse[group]))\n",
    "            plot_val_rmse.append(np.mean(group_val_rmse[group]))\n",
    "            plot_train_std.append(np.std(group_train_rmse[group]))\n",
    "            plot_val_std.append(np.std(group_val_rmse[group]))\n",
    "    \n",
    "    # Create plot if we have data\n",
    "    if plot_groups:\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        x = np.arange(len(plot_groups))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, plot_train_rmse, width, yerr=plot_train_std, \n",
    "                label='Train RMSE', color='blue', alpha=0.7, capsize=5)\n",
    "        plt.bar(x + width/2, plot_val_rmse, width, yerr=plot_val_std,\n",
    "                label='Validation RMSE', color='red', alpha=0.7, capsize=5)\n",
    "        \n",
    "        plt.xlabel('Group')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.ylim((0,5))\n",
    "        plt.title('Bayesian Model Performance by Group (Mean ± Std)')\n",
    "        plt.xticks(x, plot_groups, rotation=90)\n",
    "        plt.legend()\n",
    "        plt.grid(True, axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "groups_list = []\n",
    "train_mean_list = []\n",
    "train_std_list = []\n",
    "val_mean_list = []\n",
    "val_std_list = []\n",
    "\n",
    "# Extract values for each group\n",
    "for group in sorted(group_train_rmse.keys()):\n",
    "    train_values = group_train_rmse[group]\n",
    "    val_values = group_val_rmse[group]\n",
    "    \n",
    "    groups_list.append(group)\n",
    "    \n",
    "    if train_values:\n",
    "        train_mean_list.append(np.mean(train_values))\n",
    "        train_std_list.append(np.std(train_values))\n",
    "    else:\n",
    "        train_mean_list.append(np.nan)\n",
    "        train_std_list.append(np.nan)\n",
    "        \n",
    "    if val_values:\n",
    "        val_mean_list.append(np.mean(val_values))\n",
    "        val_std_list.append(np.std(val_values))\n",
    "    else:\n",
    "        val_mean_list.append(np.nan)\n",
    "        val_std_list.append(np.nan)\n",
    "\n",
    "\n",
    "# Create lists to store the data\n",
    "groups_list = []\n",
    "train_mean_list = []\n",
    "train_std_list = []\n",
    "val_mean_list = []\n",
    "val_std_list = []\n",
    "\n",
    "# Extract values for each group\n",
    "for group in sorted(group_train_rmse.keys()):\n",
    "    train_values = group_train_rmse[group]\n",
    "    val_values = group_val_rmse[group]\n",
    "    \n",
    "    groups_list.append(group)\n",
    "    \n",
    "    if train_values:\n",
    "        train_mean_list.append(np.mean(train_values))\n",
    "        train_std_list.append(np.std(train_values))\n",
    "    else:\n",
    "        train_mean_list.append(np.nan)\n",
    "        train_std_list.append(np.nan)\n",
    "        \n",
    "    if val_values:\n",
    "        val_mean_list.append(np.mean(val_values))\n",
    "        val_std_list.append(np.std(val_values))\n",
    "    else:\n",
    "        val_mean_list.append(np.nan)\n",
    "        val_std_list.append(np.nan)\n",
    "\n",
    "group_metrics_df = pd.DataFrame({\n",
    "    'Group': groups_list,\n",
    "    'Train_RMSE_Mean': train_mean_list,\n",
    "    'Val_RMSE_Mean': val_mean_list,\n",
    "    'Train_RMSE_Std': train_std_list,\n",
    "    'Val_RMSE_Std': val_std_list\n",
    "})\n",
    "\n",
    "group_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Approach - CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Improved implementation of frequency-based splitting for Bayesian Profile model\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# # Set seeds for consistency\n",
    "# np.random.seed(42)\n",
    "\n",
    "# def frequency_based_cross_validation(data, target_column, n_splits=3, thresh=0):\n",
    "#     \"\"\"\n",
    "#     Perform frequency-based cross-validation with the BayesianProfile_LRcompare model.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     data : pandas DataFrame\n",
    "#         The full dataset containing features and target\n",
    "#     target_column : str\n",
    "#         The name of the target column to predict\n",
    "#     n_splits : int\n",
    "#         Number of frequency groups to create\n",
    "#     thresh : float\n",
    "#         Threshold for Level(dB) to include in training\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     dict\n",
    "#         Results including RMSE scores and group-specific metrics\n",
    "#     \"\"\"\n",
    "#     # Predictors needed for the model\n",
    "#     predictors = ['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'Strain (x5)', 'Group']\n",
    "    \n",
    "#     # Check if all required columns exist\n",
    "#     for col in predictors + [target_column]:\n",
    "#         if col not in data.columns:\n",
    "#             raise ValueError(f\"Required column '{col}' not found in data\")\n",
    "            \n",
    "#     # Store results\n",
    "#     results = {\n",
    "#         'train_rmse': [],\n",
    "#         'test_rmse': [],\n",
    "#         'group_train_rmse': {},\n",
    "#         'group_test_rmse': {},\n",
    "#         'fold_details': [],\n",
    "#         'all_train_data': {},\n",
    "#         'all_test_data': {}\n",
    "#     }\n",
    "    \n",
    "#     # Setup groups\n",
    "#     groups = [str(group) for group in np.unique(data['Group'])]\n",
    "#     for group in groups:\n",
    "#         results['group_train_rmse'][group] = []\n",
    "#         results['group_test_rmse'][group] = []\n",
    "    \n",
    "#     # Get all unique frequencies and sort them\n",
    "#     all_freqs = sorted(np.unique(data['Freq(kHz) (x1)']))\n",
    "#     print(f\"All frequencies (kHz): {all_freqs}\")\n",
    "#     print(f\"Number of unique frequencies: {len(all_freqs)}\")\n",
    "    \n",
    "#     # Create frequency groups\n",
    "#     freq_groups = {}\n",
    "#     for i, freq in enumerate(all_freqs):\n",
    "#         group_idx = i % n_splits\n",
    "#         if group_idx not in freq_groups:\n",
    "#             freq_groups[group_idx] = []\n",
    "#         freq_groups[group_idx].append(freq)\n",
    "    \n",
    "#     # Print frequency groups\n",
    "#     print(\"\\nFrequency groups:\")\n",
    "#     for i in range(n_splits):\n",
    "#         print(f\"  Group {i+1}: {sorted(freq_groups[i])}\")\n",
    "    \n",
    "#     # Iterate through frequency-based folds\n",
    "#     for fold_idx in range(n_splits):\n",
    "#         print(f\"\\n{'='*50}\")\n",
    "#         print(f\"Processing Fold {fold_idx+1}/{n_splits}\")\n",
    "#         print(f\"{'='*50}\")\n",
    "        \n",
    "#         # Assign test and train frequencies\n",
    "#         test_freqs = freq_groups[fold_idx]\n",
    "#         train_freqs = []\n",
    "#         for i in range(n_splits):\n",
    "#             if i != fold_idx:\n",
    "#                 train_freqs.extend(freq_groups[i])\n",
    "        \n",
    "#         print(f\"Training frequencies: {sorted(train_freqs)}\")\n",
    "#         print(f\"Testing frequencies: {sorted(test_freqs)}\")\n",
    "        \n",
    "#         # Create train and test indices\n",
    "#         train_indices = []\n",
    "#         test_indices = []\n",
    "        \n",
    "#         # First separate by subject to avoid data leakage\n",
    "#         for subject in np.unique(data['Subject']):\n",
    "#             subject_data = data[data['Subject'] == subject]\n",
    "            \n",
    "#             # Get subject's data for train and test based on frequencies\n",
    "#             train_subject_indices = subject_data[subject_data['Freq(kHz) (x1)'].isin(train_freqs)].index.tolist()\n",
    "#             test_subject_indices = subject_data[subject_data['Freq(kHz) (x1)'].isin(test_freqs)].index.tolist()\n",
    "            \n",
    "#             # Only include subject if they have data in both splits\n",
    "#             if len(train_subject_indices) > 0 and len(test_subject_indices) > 0:\n",
    "#                 train_indices.extend(train_subject_indices)\n",
    "#                 test_indices.extend(test_subject_indices)\n",
    "#             else:\n",
    "#                 print(f\"Subject {subject} excluded - not enough data in both splits\")\n",
    "        \n",
    "#         # Check if we have enough data for this fold\n",
    "#         if len(train_indices) == 0 or len(test_indices) == 0:\n",
    "#             print(f\"Skipping fold {fold_idx+1} - not enough data in train or test split\")\n",
    "#             continue\n",
    "            \n",
    "#         # Extract train and test sets\n",
    "#         X_train = data.loc[train_indices, predictors]\n",
    "#         X_test = data.loc[test_indices, predictors]\n",
    "#         y_train = data.loc[train_indices, target_column]\n",
    "#         y_test = data.loc[test_indices, target_column]\n",
    "        \n",
    "#         print(f\"Train set: {len(X_train)} samples\")\n",
    "#         print(f\"Test set: {len(X_test)} samples\")\n",
    "        \n",
    "#         # Track subjects in train and test\n",
    "#         train_subjects = set(X_train['Subject'])\n",
    "#         test_subjects = set(X_test['Subject'])\n",
    "        \n",
    "#         # Check subject overlap (should be high if we filtered correctly)\n",
    "#         shared_subjects = train_subjects.intersection(test_subjects)\n",
    "#         print(f\"Training subjects: {len(train_subjects)}\")\n",
    "#         print(f\"Testing subjects: {len(test_subjects)}\")\n",
    "#         print(f\"Shared subjects: {len(shared_subjects)}/{len(test_subjects)} ({100*len(shared_subjects)/len(test_subjects):.1f}%)\")\n",
    "        \n",
    "#         # Initialize Bayesian profiles\n",
    "#         subjects_profiles = {}\n",
    "        \n",
    "#         # First, build the Bayesian profiles for each subject using training data\n",
    "#         for subject in train_subjects:\n",
    "#             # Initialize profile for this subject\n",
    "#             subjects_profiles[subject] = BayesianProfile_LRcompare()\n",
    "            \n",
    "#             # Get this subject's training data\n",
    "#             subject_data = X_train[X_train['Subject'] == subject]\n",
    "            \n",
    "#             # Group data by conditions (unique combinations of relevant features)\n",
    "#             grouped = subject_data.groupby([\n",
    "#                 'Freq(kHz) (x1)', 'Amplitude (x3)', 'Strain (x5)',\n",
    "#                 'Group'\n",
    "#             ])\n",
    "            \n",
    "#             # Process each group (condition)\n",
    "#             for group_key, group_data in grouped:\n",
    "#                 # Skip if below threshold\n",
    "#                 if group_data['Level(dB) (x2)'].min() < thresh:\n",
    "#                     continue\n",
    "                    \n",
    "#                 # Get indices for this group\n",
    "#                 indices = group_data.index\n",
    "#                 y_values = y_train.loc[indices]\n",
    "                \n",
    "#                 # Get feature values (same for all rows in group)\n",
    "#                 x1_val = group_data['Freq(kHz) (x1)'].iloc[0]  # Frequency\n",
    "#                 x2_val = group_data['Level(dB) (x2)'].iloc[0]  # Level\n",
    "#                 x3_val = group_data['Amplitude (x3)'].iloc[0]  # Amplitude\n",
    "                \n",
    "#                 # Add each observation to the Bayesian profile\n",
    "#                 for idx, y_val in zip(indices, y_values):\n",
    "#                     try:\n",
    "#                         subjects_profiles[subject].add_observation_y1(\n",
    "#                             x1=x1_val, x2=x2_val, x3=x3_val,\n",
    "#                             y1=float(y_val)\n",
    "#                         )\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error adding observation for subject {subject}: {e}\")\n",
    "        \n",
    "#         # Make predictions and calculate RMSE\n",
    "#         # Training predictions\n",
    "#         train_predictions = {}\n",
    "        \n",
    "#         for idx, row in X_train.iterrows():\n",
    "#             try:\n",
    "#                 subject = row['Subject']\n",
    "                \n",
    "#                 # Skip if subject not in profiles or level below threshold\n",
    "#                 if subject in subjects_profiles and row['Level(dB) (x2)'] >= thresh:\n",
    "#                     x1_val = row['Freq(kHz) (x1)']\n",
    "#                     x2_val = row['Level(dB) (x2)']\n",
    "#                     x3_val = row['Amplitude (x3)']\n",
    "                    \n",
    "#                     # Get prediction\n",
    "#                     pred = subjects_profiles[subject].predict_y1(\n",
    "#                         x1=x1_val, x2=x2_val, x3=x3_val\n",
    "#                     )\n",
    "                    \n",
    "#                     # Store valid prediction\n",
    "#                     if pred is not None and np.isfinite(pred):\n",
    "#                         train_predictions[idx] = float(pred)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error in train prediction for row {idx}: {e}\")\n",
    "        \n",
    "#         # Use only successful predictions\n",
    "#         successful_train_indices = list(train_predictions.keys())\n",
    "        \n",
    "#         if not successful_train_indices:\n",
    "#             print(f\"Fold {fold_idx+1}: No successful training predictions\")\n",
    "#             continue\n",
    "            \n",
    "#         # Get true values and predictions\n",
    "#         y_train_true = y_train.loc[successful_train_indices]\n",
    "#         y_train_pred = pd.Series(\n",
    "#             [train_predictions[idx] for idx in successful_train_indices], \n",
    "#             index=successful_train_indices\n",
    "#         )\n",
    "        \n",
    "#         # Test predictions\n",
    "#         test_predictions = {}\n",
    "        \n",
    "#         for idx, row in X_test.iterrows():\n",
    "#             try:\n",
    "#                 subject = row['Subject']\n",
    "                \n",
    "#                 # Skip if subject not in profiles or level below threshold\n",
    "#                 if subject in subjects_profiles and row['Level(dB) (x2)'] >= thresh:\n",
    "#                     x1_val = row['Freq(kHz) (x1)']\n",
    "#                     x2_val = row['Level(dB) (x2)']\n",
    "#                     x3_val = row['Amplitude (x3)']\n",
    "                    \n",
    "#                     # Get prediction\n",
    "#                     pred = subjects_profiles[subject].predict_y1(\n",
    "#                         x1=x1_val, x2=x2_val, x3=x3_val\n",
    "#                     )\n",
    "                    \n",
    "#                     # Store valid prediction\n",
    "#                     if pred is not None and np.isfinite(pred):\n",
    "#                         test_predictions[idx] = float(pred)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error in test prediction for row {idx}: {e}\")\n",
    "        \n",
    "#         # Use only successful predictions\n",
    "#         successful_test_indices = list(test_predictions.keys())\n",
    "        \n",
    "#         if not successful_test_indices:\n",
    "#             print(f\"Fold {fold_idx+1}: No successful test predictions\")\n",
    "#             continue\n",
    "            \n",
    "#         # Get true values and predictions\n",
    "#         y_test_true = y_test.loc[successful_test_indices]\n",
    "#         y_test_pred = pd.Series(\n",
    "#             [test_predictions[idx] for idx in successful_test_indices], \n",
    "#             index=successful_test_indices\n",
    "#         )\n",
    "        \n",
    "#         # Store predictions\n",
    "#         results['all_train_data'][f'{fold_idx}_true'] = y_train_true\n",
    "#         results['all_train_data'][f'{fold_idx}_pred'] = y_train_pred\n",
    "#         results['all_test_data'][f'{fold_idx}_true'] = y_test_true\n",
    "#         results['all_test_data'][f'{fold_idx}_pred'] = y_test_pred\n",
    "        \n",
    "#         # Calculate RMSE\n",
    "#         fold_train_rmse = np.sqrt(np.mean((y_train_true - y_train_pred)**2))\n",
    "#         fold_test_rmse = np.sqrt(np.mean((y_test_true - y_test_pred)**2))\n",
    "        \n",
    "#         # Store RMSE\n",
    "#         results['train_rmse'].append(fold_train_rmse)\n",
    "#         results['test_rmse'].append(fold_test_rmse)\n",
    "        \n",
    "#         print(f\"Fold {fold_idx+1}: Train RMSE = {fold_train_rmse:.4f}, Test RMSE = {fold_test_rmse:.4f}\")\n",
    "        \n",
    "#         # Calculate group-specific RMSE\n",
    "#         for group in groups:\n",
    "#             # Training RMSE by group\n",
    "#             try:\n",
    "#                 # Get data for successful predictions\n",
    "#                 train_data_with_group = data.loc[successful_train_indices]\n",
    "                \n",
    "#                 # Filter for this group\n",
    "#                 group_mask = train_data_with_group['Group'] == group\n",
    "                \n",
    "#                 if group_mask.any():\n",
    "#                     group_indices = group_mask.index[group_mask]\n",
    "#                     group_rmse = np.sqrt(np.mean((y_train_true.loc[group_indices] - y_train_pred.loc[group_indices])**2))\n",
    "#                     results['group_train_rmse'][group].append(group_rmse)\n",
    "#                     print(f\"  Group {group} Train RMSE: {group_rmse:.4f}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error calculating train RMSE for group {group}: {e}\")\n",
    "            \n",
    "#             # Test RMSE by group\n",
    "#             try:\n",
    "#                 # Get data for successful predictions\n",
    "#                 test_data_with_group = data.loc[successful_test_indices]\n",
    "                \n",
    "#                 # Filter for this group\n",
    "#                 group_mask = test_data_with_group['Group'] == group\n",
    "                \n",
    "#                 if group_mask.any():\n",
    "#                     group_indices = group_mask.index[group_mask]\n",
    "#                     group_rmse = np.sqrt(np.mean((y_test_true.loc[group_indices] - y_test_pred.loc[group_indices])**2))\n",
    "#                     results['group_test_rmse'][group].append(group_rmse)\n",
    "#                     print(f\"  Group {group} Test RMSE: {group_rmse:.4f}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error calculating test RMSE for group {group}: {e}\")\n",
    "        \n",
    "#         # Store fold details\n",
    "#         results['fold_details'].append({\n",
    "#             'fold': fold_idx,\n",
    "#             'train_indices': train_indices,\n",
    "#             'test_indices': test_indices,\n",
    "#             'train_freqs': train_freqs,\n",
    "#             'test_freqs': test_freqs,\n",
    "#             'train_subjects': list(train_subjects),\n",
    "#             'test_subjects': list(test_subjects),\n",
    "#             'train_rmse': fold_train_rmse,\n",
    "#             'test_rmse': fold_test_rmse,\n",
    "#             'num_train_predictions': len(successful_train_indices),\n",
    "#             'num_test_predictions': len(successful_test_indices)\n",
    "#         })\n",
    "    \n",
    "#     # Calculate average RMSE across all folds\n",
    "#     if results['train_rmse']:\n",
    "#         avg_train_rmse = np.mean(results['train_rmse'])\n",
    "#         std_train_rmse = np.std(results['train_rmse'])\n",
    "#         print(f\"\\nAverage Train RMSE across folds: {avg_train_rmse:.4f} ± {std_train_rmse:.4f}\")\n",
    "    \n",
    "#     if results['test_rmse']:\n",
    "#         avg_test_rmse = np.mean(results['test_rmse'])\n",
    "#         std_test_rmse = np.std(results['test_rmse'])\n",
    "#         print(f\"Average Test RMSE across folds: {avg_test_rmse:.4f} ± {std_test_rmse:.4f}\")\n",
    "    \n",
    "#     # Group-specific RMSE summary\n",
    "#     print(\"\\nGroup-specific RMSE:\")\n",
    "#     print(\"Group | Train RMSE (Mean ± Std) | Test RMSE (Mean ± Std)\")\n",
    "#     print(\"----- | ----------------------- | ---------------------\")\n",
    "    \n",
    "#     group_metrics = []\n",
    "    \n",
    "#     for group in groups:\n",
    "#         train_values = results['group_train_rmse'][group]\n",
    "#         test_values = results['group_test_rmse'][group]\n",
    "        \n",
    "#         if train_values:\n",
    "#             train_mean = np.mean(train_values)\n",
    "#             train_std = np.std(train_values)\n",
    "#             train_str = f\"{train_mean:.4f} ± {train_std:.4f}\"\n",
    "#         else:\n",
    "#             train_mean = np.nan\n",
    "#             train_std = np.nan\n",
    "#             train_str = \"N/A\"\n",
    "            \n",
    "#         if test_values:\n",
    "#             test_mean = np.mean(test_values)\n",
    "#             test_std = np.std(test_values)\n",
    "#             test_str = f\"{test_mean:.4f} ± {test_std:.4f}\"\n",
    "#         else:\n",
    "#             test_mean = np.nan\n",
    "#             test_std = np.nan\n",
    "#             test_str = \"N/A\"\n",
    "            \n",
    "#         print(f\"{group:15s} | {train_str:25s} | {test_str:25s}\")\n",
    "        \n",
    "#         # Store in group metrics list\n",
    "#         group_metrics.append({\n",
    "#             'Group': group,\n",
    "#             'Train_RMSE_Mean': train_mean,\n",
    "#             'Train_RMSE_Std': train_std,\n",
    "#             'Test_RMSE_Mean': test_mean,\n",
    "#             'Test_RMSE_Std': test_std\n",
    "#         })\n",
    "    \n",
    "#     # Create DataFrame for group metrics\n",
    "#     results['group_metrics_df'] = pd.DataFrame(group_metrics)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def plot_group_rmse(results):\n",
    "#     \"\"\"\n",
    "#     Plot group-specific RMSE from cross-validation results\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     results : dict\n",
    "#         Results from frequency_based_cross_validation function\n",
    "#     \"\"\"\n",
    "#     # Prepare data for plotting\n",
    "#     df = results['group_metrics_df']\n",
    "    \n",
    "#     # Filter groups with valid data\n",
    "#     valid_groups = df[df['Train_RMSE_Mean'].notna() & df['Test_RMSE_Mean'].notna()]['Group'].tolist()\n",
    "    \n",
    "#     if not valid_groups:\n",
    "#         print(\"No valid group data to plot\")\n",
    "#         return None\n",
    "    \n",
    "#     # Filter data for valid groups\n",
    "#     plot_data = df[df['Group'].isin(valid_groups)]\n",
    "    \n",
    "#     # Create plot\n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     x = np.arange(len(valid_groups))\n",
    "#     width = 0.35\n",
    "    \n",
    "#     # Plot bars\n",
    "#     plt.bar(x - width/2, plot_data['Train_RMSE_Mean'], width, \n",
    "#             yerr=plot_data['Train_RMSE_Std'],\n",
    "#             label='Train RMSE', color='blue', alpha=0.7, capsize=5)\n",
    "    \n",
    "#     plt.bar(x + width/2, plot_data['Test_RMSE_Mean'], width,\n",
    "#             yerr=plot_data['Test_RMSE_Std'],\n",
    "#             label='Test RMSE', color='red', alpha=0.7, capsize=5)\n",
    "    \n",
    "#     # Customize plot\n",
    "#     plt.xlabel('Group')\n",
    "#     plt.ylabel('RMSE')\n",
    "#     plt.title('Bayesian Model Performance by Group (Mean ± Std)')\n",
    "#     plt.xticks(x, valid_groups, rotation=45)\n",
    "#     plt.legend()\n",
    "#     plt.grid(True, axis='y', alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     return plt.gcf()\n",
    "\n",
    "# def plot_predictions_vs_actual(results, fold_idx=0, split='test'):\n",
    "#     \"\"\"\n",
    "#     Create a scatter plot of predicted vs actual values\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     results : dict\n",
    "#         Results from frequency_based_cross_validation function\n",
    "#     fold_idx : int\n",
    "#         Index of the fold to plot\n",
    "#     split : str\n",
    "#         'train' or 'test' to specify which split to plot\n",
    "#     \"\"\"\n",
    "#     # Get data\n",
    "#     if split == 'train':\n",
    "#         data_dict = results['all_train_data']\n",
    "#     else:\n",
    "#         data_dict = results['all_test_data']\n",
    "    \n",
    "#     # Check if data exists\n",
    "#     if f'{fold_idx}_true' not in data_dict or f'{fold_idx}_pred' not in data_dict:\n",
    "#         print(f\"No data available for fold {fold_idx} {split} split\")\n",
    "#         return None\n",
    "    \n",
    "#     # Get true and predicted values\n",
    "#     y_true = data_dict[f'{fold_idx}_true']\n",
    "#     y_pred = data_dict[f'{fold_idx}_pred']\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "#     corr = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "    \n",
    "#     # Create plot\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "    \n",
    "#     # Plot diagonal line (perfect predictions)\n",
    "#     min_val = min(y_true.min(), y_pred.min())\n",
    "#     max_val = max(y_true.max(), y_pred.max())\n",
    "#     plt.plot([min_val, max_val], [min_val, max_val], 'k--')\n",
    "    \n",
    "#     # Plot predictions\n",
    "#     plt.scatter(y_true, y_pred, alpha=0.7)\n",
    "    \n",
    "#     # Add details\n",
    "#     plt.xlabel('Actual Values')\n",
    "#     plt.ylabel('Predicted Values')\n",
    "#     plt.title(f'Predicted vs Actual - Fold {fold_idx+1} ({split.capitalize()} Set)\\nRMSE: {rmse:.4f}, Correlation: {corr:.4f}')\n",
    "#     plt.grid(True, alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     return plt.gcf()\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Assuming final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx is your dataframe\n",
    "#     # and 'Synapse to IHC Ratio per Freq (y2)' is your target\n",
    "    \n",
    "#     # Run cross-validation\n",
    "#     cv_results = frequency_based_cross_validation(\n",
    "#         data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx,\n",
    "#         target_column='Synapse to IHC Ratio per Freq (y2)',\n",
    "#         n_splits=3,\n",
    "#         thresh=0\n",
    "#     )\n",
    "    \n",
    "#     # Plot group-specific RMSE\n",
    "#     plot_group_rmse(cv_results)\n",
    "    \n",
    "#     # Plot predictions vs actual for first fold\n",
    "#     plot_predictions_vs_actual(cv_results, fold_idx=0, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db98data = pd.DataFrame(group_metrics_df.iloc[-1,:]).T\n",
    "# group_metrics_df_copy = group_metrics_df.copy()\n",
    "# group_metrics_df_copy.iloc[-1,:] = group_metrics_df_copy.iloc[0,:]\n",
    "# group_metrics_df_copy = group_metrics_df_copy[1:]\n",
    "# # group_metrics_df_copy.iloc[0,:] = group_metrics_df_copy.iloc[1,:]\n",
    "# r14 = group_metrics_df_copy.iloc[0,:]\n",
    "# r6 = group_metrics_df_copy.iloc[1,:]\n",
    "# r8 = group_metrics_df_copy.iloc[2,:]\n",
    "# group_metrics_df_copy.iloc[0,:] = r6\n",
    "# # group_metrics_df_copy.iloc[1,:] = r8\n",
    "# group_metrics_df_copy.iloc[2,:] = r14\n",
    "# # group_metrics_df_copy['Group'] = group_metrics_df_copy['Group'].apply(lambda x: f\"'{x}'\")\n",
    "# db101 = pd.DataFrame(group_metrics_df_copy.iloc[-1,:]).T\n",
    "# group_metrics_df_copy.drop(group_metrics_df_copy.tail(1).index,inplace=True)\n",
    "# # group_metrics_df_copy = pd.concat([group_metrics_df_copy, db98data], axis=0)\n",
    "# # group_metrics_df_copy = pd.concat([group_metrics_df_copy, db101], axis=0)\n",
    "# group_metrics_df_copy_final = pd.concat([group_metrics_df_copy, db98data, db101], ignore_index=True)\n",
    "\n",
    "# group_metrics_df_copy_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_manorimagepred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
