{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import os\n",
    "import struct\n",
    "import datetime\n",
    "# from skfda import FDataGrid\n",
    "# from skfda.preprocessing.dim_reduction import FPCA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import torch.nn as nn\n",
    "import splitfolders\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import find_peaks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np4\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import torch\n",
    "import torch.distributed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ABRA_35 import interpolate_and_smooth, CNN, plot_wave, calculate_and_plot_wave, plot_waves_single_frequency, arfread, get_str, calculate_hearing_threshold, all_thresholds, peak_finding\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_modeltesting(K, X, y):\n",
    "    kf = KFold(n_splits=K)\n",
    "\n",
    "    train_fold_RMSES = []\n",
    "    test_fold_RMSES = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "        print(f'Processing Fold {i+1}')\n",
    "        X_train, y_train = X.iloc[train_index,:], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index,:], y.iloc[test_index]\n",
    "\n",
    "        y_preds_train = model.predict(X_train)\n",
    "        RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "        print(f'Train RMSE = {RMSE_train}')\n",
    "        train_fold_RMSES.append(RMSE_train)\n",
    "\n",
    "        y_preds_test = model.predict(X_test)\n",
    "        RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "        print(f'Test RMSE = {RMSE_test}\\n')\n",
    "        test_fold_RMSES.append(RMSE_test)\n",
    "\n",
    "    avg_train_RMSE = np.mean(train_fold_RMSES)\n",
    "    avg_test_RMSE = np.mean(test_fold_RMSES)\n",
    "\n",
    "    print(f'Average Train RMSE across {K} folds: {avg_train_RMSE}')\n",
    "    print(f'Average Test RMSE across {K} folds: {avg_test_RMSE}')\n",
    "\n",
    "    return avg_train_RMSE, avg_test_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfold_by_feature(X, y, model, stratify_col, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform cross-validation stratified by a specific feature column,\n",
    "    but exclude that column from being used as a predictor.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        The feature matrix (must be a pandas DataFrame)\n",
    "    y : Series or array-like\n",
    "        The target variable\n",
    "    model : estimator object\n",
    "        The model to evaluate\n",
    "    stratify_col : str\n",
    "        Name of the column in X to stratify by (will be excluded from predictors)\n",
    "    n_splits : int, default=5\n",
    "        Number of folds\n",
    "    random_state : int, default=42\n",
    "        Random state for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    train_rmse_scores : list\n",
    "        RMSE scores for training sets\n",
    "    test_rmse_scores : list\n",
    "        RMSE scores for test sets\n",
    "    \"\"\"\n",
    "    # Ensure X is a DataFrame\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise TypeError(\"X must be a pandas DataFrame to use column name for stratification\")\n",
    "    \n",
    "    # Extract the stratification column\n",
    "    stratify_values = X[stratify_col].values\n",
    "    \n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Lists to store the RMSE scores for each fold\n",
    "    train_rmse_scores = []\n",
    "    test_rmse_scores = []\n",
    "    \n",
    "    # Remove the stratify column from the features\n",
    "    X_for_model = X.drop(columns=[stratify_col])\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, stratify_values)):\n",
    "        print(f'Processing Fold {i+1}')\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test = X_for_model.iloc[train_index], X_for_model.iloc[test_index]\n",
    "        \n",
    "        if isinstance(y, pd.Series):\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        else:\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        \n",
    "        # Store the scores\n",
    "        train_rmse_scores.append(train_rmse)\n",
    "        test_rmse_scores.append(test_rmse)\n",
    "        \n",
    "        # Print fold statistics with stratification distribution\n",
    "        train_strat_dist = X.iloc[train_index][stratify_col].value_counts(normalize=True).to_dict()\n",
    "        test_strat_dist = X.iloc[test_index][stratify_col].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        print(f'Fold {i+1} - Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}')\n",
    "        print(f'  Train distribution of {stratify_col}: {train_strat_dist}')\n",
    "        print(f'  Test distribution of {stratify_col}: {test_strat_dist}')\n",
    "    \n",
    "    # Calculate and print average scores\n",
    "    avg_train_rmse = np.mean(train_rmse_scores)\n",
    "    avg_test_rmse = np.mean(test_rmse_scores)\n",
    "    \n",
    "    print(f'\\nAverage Train RMSE: {avg_train_rmse:.4f}')\n",
    "    print(f'Average Test RMSE: {avg_test_rmse:.4f}')\n",
    "    \n",
    "    return train_rmse_scores, test_rmse_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = 128\n",
    "filter2 = 32\n",
    "dropout1 = 0.5\n",
    "dropout2 = 0.3\n",
    "dropout_fc = 0.1\n",
    "\n",
    "# Model initialization\n",
    "peak_finding_model = CNN(filter1, filter2, dropout1, dropout2, dropout_fc)\n",
    "model_loader = torch.load('./models/waveI_cnn.pth')\n",
    "peak_finding_model.load_state_dict(model_loader)\n",
    "peak_finding_model.eval()\n",
    "\n",
    "def peak_finding(wave):\n",
    "    # Prepare waveform\n",
    "    waveform=interpolate_and_smooth(wave) # Added indexing per calculate and plot wave function\n",
    "    # waveform_torch = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0) archived ABRA\n",
    "    waveform_torch = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).unsqueeze(0) #newer ABRA\n",
    "    # print(waveform_torch)\n",
    "    # Get prediction from model\n",
    "    outputs = peak_finding_model(waveform_torch)\n",
    "    prediction = int(round(outputs.detach().numpy()[0][0], 0))\n",
    "    # prediction_test = int(round(outputs.detach().numpy()[0], 0))\n",
    "    # print(\"Model output:\", outputs, \"Prediction true start:\", prediction)\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    smoothed_waveform = gaussian_filter1d(waveform, sigma=1)\n",
    "\n",
    "    # Find peaks and troughs\n",
    "    n = 18\n",
    "    t = 14\n",
    "    # start_point = prediction - 9 archived ABRA\n",
    "    start_point = prediction - 6 #newer ABRA\n",
    "    smoothed_peaks, _ = find_peaks(smoothed_waveform[start_point:], distance=n)\n",
    "    smoothed_troughs, _ = find_peaks(-smoothed_waveform, distance=t)\n",
    "    sorted_indices = np.argsort(smoothed_waveform[smoothed_peaks+start_point])\n",
    "    highest_smoothed_peaks = np.sort(smoothed_peaks[sorted_indices[-5:]] + start_point)\n",
    "    relevant_troughs = np.array([])\n",
    "    for p in range(len(highest_smoothed_peaks)):\n",
    "        c = 0\n",
    "        for t in smoothed_troughs:\n",
    "            if t > highest_smoothed_peaks[p]:\n",
    "                if p != 4:\n",
    "                    try:\n",
    "                        if t < highest_smoothed_peaks[p+1]:\n",
    "                            relevant_troughs = np.append(relevant_troughs, int(t))\n",
    "                            break\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                else:\n",
    "                    relevant_troughs = np.append(relevant_troughs, int(t))\n",
    "                    break\n",
    "    relevant_troughs = relevant_troughs.astype('i')\n",
    "    return highest_smoothed_peaks, relevant_troughs\n",
    "\n",
    "def extract_metadata(metadata_lines):\n",
    "    # Dictionary to store extracted metadata\n",
    "    metadata = {}\n",
    "    \n",
    "    for line in metadata_lines:\n",
    "        # Extract SW FREQ\n",
    "        freq_match = re.search(r'SW FREQ:\\s*(\\d+\\.?\\d*)', line)\n",
    "        if freq_match:\n",
    "            metadata['SW_FREQ'] = float(freq_match.group(1))\n",
    "        \n",
    "        # Extract LEVELS\n",
    "        levels_match = re.search(r':LEVELS:\\s*([^:]+)', line)\n",
    "        if levels_match:\n",
    "            # Split levels and convert to list of floats\n",
    "            metadata['LEVELS'] = [float(level) for level in levels_match.group(1).split(';') if level]\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def read_custom_tsv(file_path):\n",
    "    # Read the entire file\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split the content into metadata and data sections\n",
    "    metadata_lines = []\n",
    "    data_section = None\n",
    "    \n",
    "    # Find the ':DATA' marker\n",
    "    data_start = content.find(':DATA')\n",
    "    \n",
    "    if data_start != -1:\n",
    "        # Extract metadata (lines before ':DATA')\n",
    "        metadata_lines = content[:data_start].split('\\n')\n",
    "        \n",
    "        # Extract data section\n",
    "        data_section = content[data_start:].split(':DATA')[1].strip()\n",
    "    \n",
    "    # Extract specific metadata\n",
    "    metadata = extract_metadata(metadata_lines)\n",
    "    \n",
    "    # Read the data section directly\n",
    "    try:\n",
    "        # Use StringIO to create a file-like object from the data section\n",
    "        raw_data = pd.read_csv(\n",
    "            io.StringIO(data_section), \n",
    "            sep='\\s+',  # Use whitespace as separator\n",
    "            header=None\n",
    "        )\n",
    "        raw_data = raw_data.T\n",
    "        # Add metadata columns to the DataFrame\n",
    "        if 'SW_FREQ' in metadata:\n",
    "            raw_data['Freq(kHz)'] = metadata['SW_FREQ']\n",
    "            # raw_data['Freq(Hz)'] = raw_data['Freq(Hz)'].apply(lambda x: x*1000)\n",
    "        \n",
    "        if 'LEVELS' in metadata:\n",
    "            # Repeat levels to match the number of rows\n",
    "            levels_repeated = metadata['LEVELS'] * (len(raw_data) // len(metadata['LEVELS']) + 1)\n",
    "            raw_data['Level(dB)'] = levels_repeated[:len(raw_data)]\n",
    "        \n",
    "        filtered_data = raw_data.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "        filtered_data.columns = filtered_data.columns.map(str)\n",
    "\n",
    "        columns = ['Freq(kHz)'] + ['Level(dB)'] + [col for col in filtered_data.columns if col.isnumeric() == True]\n",
    "        filtered_data = filtered_data[columns]\n",
    "        return filtered_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data: {e}\")\n",
    "        return None, metadata\n",
    "\n",
    "\n",
    "def peaks_troughs_amp_final(df, freq, db, time_scale=10, multiply_y_factor=1.0, units='Microvolts'):\n",
    "    db_column = 'Level(dB)'\n",
    "    \n",
    "    khz = df[(df['Freq(kHz)'] == freq) & (df[db_column] == db)]\n",
    "    if not khz.empty:\n",
    "        index = khz.index.values[0]\n",
    "        final = df.loc[index, '0':].dropna()\n",
    "        final = pd.to_numeric(final, errors='coerce').dropna()\n",
    "\n",
    "        target = int(244 * (time_scale / 10))\n",
    "        \n",
    "        # Process the wave as in calculate_and_plot_wave\n",
    "        y_values = interpolate_and_smooth(final, target)\n",
    "        \n",
    "        # Apply scaling factor\n",
    "        y_values *= multiply_y_factor\n",
    "        \n",
    "        # Handle units conversion if needed\n",
    "        if units == 'Nanovolts':\n",
    "            y_values /= 1000\n",
    "            \n",
    "        # Generate normalized version for peak finding\n",
    "        y_values_fpf = interpolate_and_smooth(y_values[:244])\n",
    "        \n",
    "        # Standardize and normalize for peak finding, exactly as in the original\n",
    "        flattened_data = y_values_fpf.flatten().reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        standardized_data = scaler.fit_transform(flattened_data)\n",
    "        min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = min_max_scaler.fit_transform(standardized_data).reshape(y_values_fpf.shape)\n",
    "        y_values_fpf = interpolate_and_smooth(scaled_data[:244])\n",
    "        \n",
    "        # Find peaks using the normalized data\n",
    "        highest_peaks, relevant_troughs = peak_finding(y_values_fpf)\n",
    "        \n",
    "        # Calculate amplitude on the processed but non-normalized data\n",
    "        if highest_peaks.size > 0 and relevant_troughs.size > 0:\n",
    "            # Following the same approach as in the display_metrics_table function\n",
    "            first_peak_amplitude = y_values[highest_peaks[0]] - y_values[relevant_troughs[0]]\n",
    "            return highest_peaks, relevant_troughs, first_peak_amplitude\n",
    "    \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL DATA SPLIT\n",
    "\n",
    "time_scale = 18\n",
    "amp_per_freq = {'Subject': [], 'Freq(kHz) (x1)': [], 'Level(dB) (x2)': [], 'Amplitude (x3)':[]}\n",
    "start_path = '/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/abr_data/WPZ Electrophysiology'\n",
    "for subject in os.listdir(start_path):\n",
    "    # print(\"Subject:\",subject)\n",
    "    for fq in os.listdir(os.path.join(start_path,subject)):\n",
    "        # print(fq)\n",
    "        if fq.startswith('ABR') and fq.endswith('.tsv'):\n",
    "            path = os.path.join(start_path,subject,fq)\n",
    "            data_df = read_custom_tsv(path)\n",
    "            # print(data_df)\n",
    "            freqs = data_df['Freq(kHz)'].unique().tolist()\n",
    "            levels = data_df['Level(dB)'].unique().tolist()\n",
    "            for freq in freqs:\n",
    "                for lvl in levels:\n",
    "                    # print(\"Frequency=\",freq, \"Level=\", lvl)\n",
    "                    _, _, amp = peaks_troughs_amp_final(df=data_df, freq=freq, db=lvl, time_scale=time_scale)\n",
    "                    # print(f'Amplitude: {amp}\\n')\n",
    "                    amp_per_freq['Subject'].append(subject)\n",
    "                    amp_per_freq['Freq(kHz) (x1)'].append(freq)\n",
    "                    amp_per_freq['Level(dB) (x2)'].append(lvl)\n",
    "                    amp_per_freq['Amplitude (x3)'].append(amp)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "amp_df_full = pd.DataFrame(data=amp_per_freq)\n",
    "\n",
    "raw_synapse_counts = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Ribbon and Synapse Counts.xlsx')\n",
    "raw_synapse_counts = raw_synapse_counts.mask(lambda x: x.isnull()).dropna()\n",
    "raw_synapse_counts['Synapses to IHC (y1)'] = raw_synapse_counts.iloc[:,6]\n",
    "raw_synapse_counts['vx (x4)'] = raw_synapse_counts['vx']\n",
    "raw_synapse_counts.drop(columns=['vx'], inplace=True)\n",
    "raw_synapse_counts.rename(columns={'Freq':'Freq(kHz) (x1)'}, inplace=True)\n",
    "# raw_synapse_counts['Freq(Hz) (x1)'] = raw_synapse_counts['Freq(Hz) (x1)'].apply(lambda x: x*1000) # PUTTING BACK\n",
    "raw_synapse_counts.rename(columns={'Case':'Subject', 'IHCs' : 'IHCs (y2)'}, inplace=True)\n",
    "\n",
    "paired = amp_df_full.join(raw_synapse_counts.set_index(['Subject', 'Freq(kHz) (x1)']), on=['Subject', 'Freq(kHz) (x1)'])\n",
    "slice = paired[paired['Subject']=='WPZ174'][['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs (y2)']]\n",
    "final = paired[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs (y2)']]\n",
    "final_clean = final.dropna()\n",
    "\n",
    "# adding in the strain feature\n",
    "strains = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Mouse groups.xlsx')\n",
    "final_clean_strained = final_clean.join(strains.set_index('ID#'), on='Subject')\n",
    "final_clean_strained['Strain'] = final_clean_strained['Strain'].str.strip()\n",
    "final_clean_strained = final_clean_strained.rename(columns={'Strain': 'Strain (x5)'})\n",
    "final_clean_strained = final_clean_strained.dropna()\n",
    "final_clean_strained_foundation = final_clean_strained.copy()\n",
    "final_clean_strained = final_clean_strained[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)', 'Strain (x5)', 'Synapses to IHC (y1)', 'Group']]\n",
    "np.unique(final_clean_strained['Group'])\n",
    "\n",
    "final_clean_70 = final_clean[final_clean['Level(dB) (x2)'] >= 70.0]\n",
    "final_clean_strained_70 = final_clean_strained[final_clean_strained['Level(dB) (x2)'] >= 70.0]\n",
    "# np.unique(final_clean['Level(dB) (x2)']) max level is 80 db\n",
    "len(final_clean), len(final_clean_70) # 10000 less data points!!!\n",
    "\n",
    "final_clean_strained_grouped = final_clean_strained.copy()\n",
    "final_clean_strained_grouped['Group - dB'] = final_clean_strained_grouped['Group'].apply(lambda x: x.split(' ')[0] if x.split(' ')[0].endswith('dB') else 'Control')\n",
    "final_clean_strained_grouped['Group - Time Elapsed'] = final_clean_strained_grouped['Group'].apply(lambda x: x.split(' ')[1] if x.split(' ')[1].endswith(('h', 'wks', 'w')) else x.split(' ')[0])\n",
    "final_clean_strained_grouped.head()\n",
    "\n",
    "final_clean_strained_grouped_pos = final_clean_strained_grouped.copy()\n",
    "final_clean_strained_grouped_pos['Amplitude (x3)'] = final_clean_strained_grouped['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "len(final_clean_strained_grouped_pos[final_clean_strained_grouped_pos['Amplitude (x3)'] < 0])\n",
    "\n",
    "final_clean_strained_grouped_pos['Amplitude (x3)'] = final_clean_strained_grouped['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# final_clean_strained_grouped_pos[(final_clean_strained_grouped_pos['Subject'] == 'WPZ66') & (final_clean_strained_grouped_pos['Amplitude (x3)'] ==0.055901451434921576)\n",
    "final_clean_strained_grouped_pos_cleangroup = final_clean_strained_grouped_pos.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup['Group'] = final_clean_strained_grouped_pos_cleangroup['Group'].apply(lambda x: x.strip())\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup['Group'])\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup.head()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs = final_clean_strained_grouped_pos_cleangroup.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - dB']\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed']\n",
    "final_clean_strained_grouped_pos_cleangroup_vs = final_clean_strained_grouped_pos_cleangroup_vs[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)',\n",
    "       'vx (x4)', 'Strain (x5)','Group - dB (x6)', 'Group - Time Elapsed', 'Group','Synapses to IHC (y1)']]\n",
    "\n",
    "def split_on_number(input_string):\n",
    "    return re.findall(r\"[A-Za-z]+|\\d+\", input_string)\n",
    "\n",
    "hrs_week = 24*7\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed = final_clean_strained_grouped_pos_cleangroup_vs.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: '0dB' if x == 'Control' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'].apply(lambda x: x[1])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'].apply(lambda x: \"wks\" if x == 'w' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Hours Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed.apply(lambda row: row['Group - Time Elapsed - Magn.']* hrs_week if row['Group - Time Elapsed - Unit'] == 'wks' else row['Group - Time Elapsed - Magn.'], axis = 1)\n",
    "\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Days Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Hours Elapsed (x7)'].apply(lambda x: x/24)\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Freq(kHz) (x1)</th>\n",
       "      <th>Level(dB) (x2)</th>\n",
       "      <th>Amplitude (x3)</th>\n",
       "      <th>vx (x4)</th>\n",
       "      <th>Strain (x5)</th>\n",
       "      <th>Group - dB (x6)</th>\n",
       "      <th>Group - Time Elapsed</th>\n",
       "      <th>Group</th>\n",
       "      <th>Synapses to IHC (y1)</th>\n",
       "      <th>Synapses</th>\n",
       "      <th>IHCs</th>\n",
       "      <th>Group - Time Elapsed - Split</th>\n",
       "      <th>Group - Time Elapsed - Magn.</th>\n",
       "      <th>Group - Time Elapsed - Unit</th>\n",
       "      <th>Group - Hours Elapsed (x7)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.154224</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.634279</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12187 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Freq(kHz) (x1)  Level(dB) (x2)  Amplitude (x3) vx (x4)  \\\n",
       "0     WPZ145            45.2            70.0        0.033579      v1   \n",
       "0     WPZ145            45.2            70.0        0.033579      v2   \n",
       "1     WPZ145            45.2            75.0        0.034262      v1   \n",
       "1     WPZ145            45.2            75.0        0.034262      v2   \n",
       "2     WPZ145            45.2            80.0        0.154224      v1   \n",
       "...      ...             ...             ...             ...     ...   \n",
       "7328  WPZ101            32.0            60.0        1.634279      v2   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v1   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v2   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v1   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v2   \n",
       "\n",
       "     Strain (x5)  Group - dB (x6) Group - Time Elapsed           Group  \\\n",
       "0          C57B6               98                 8wks  98dB 8wks post   \n",
       "0          C57B6               98                 8wks  98dB 8wks post   \n",
       "1          C57B6               98                 8wks  98dB 8wks post   \n",
       "1          C57B6               98                 8wks  98dB 8wks post   \n",
       "2          C57B6               98                 8wks  98dB 8wks post   \n",
       "...          ...              ...                  ...             ...   \n",
       "7328       C57B6                0                 8wks       8wks ctrl   \n",
       "7329       C57B6                0                 8wks       8wks ctrl   \n",
       "7329       C57B6                0                 8wks       8wks ctrl   \n",
       "7330       C57B6                0                 8wks       8wks ctrl   \n",
       "7330       C57B6                0                 8wks       8wks ctrl   \n",
       "\n",
       "      Synapses to IHC (y1)  Synapses IHCs Group - Time Elapsed - Split  \\\n",
       "0                 8.750000      77.0  8.8                     [8, wks]   \n",
       "0                10.888889      98.0    9                     [8, wks]   \n",
       "1                 8.750000      77.0  8.8                     [8, wks]   \n",
       "1                10.888889      98.0    9                     [8, wks]   \n",
       "2                 8.750000      77.0  8.8                     [8, wks]   \n",
       "...                    ...       ...  ...                          ...   \n",
       "7328             15.463918     150.0  9.7                     [8, wks]   \n",
       "7329             16.923077     154.0  9.1                     [8, wks]   \n",
       "7329             15.463918     150.0  9.7                     [8, wks]   \n",
       "7330             16.923077     154.0  9.1                     [8, wks]   \n",
       "7330             15.463918     150.0  9.7                     [8, wks]   \n",
       "\n",
       "      Group - Time Elapsed - Magn. Group - Time Elapsed - Unit  \\\n",
       "0                                8                         wks   \n",
       "0                                8                         wks   \n",
       "1                                8                         wks   \n",
       "1                                8                         wks   \n",
       "2                                8                         wks   \n",
       "...                            ...                         ...   \n",
       "7328                             8                         wks   \n",
       "7329                             8                         wks   \n",
       "7329                             8                         wks   \n",
       "7330                             8                         wks   \n",
       "7330                             8                         wks   \n",
       "\n",
       "      Group - Hours Elapsed (x7)  \n",
       "0                           1344  \n",
       "0                           1344  \n",
       "1                           1344  \n",
       "1                           1344  \n",
       "2                           1344  \n",
       "...                          ...  \n",
       "7328                        1344  \n",
       "7329                        1344  \n",
       "7329                        1344  \n",
       "7330                        1344  \n",
       "7330                        1344  \n",
       "\n",
       "[12187 rows x 16 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEW DATA SPLIT\n",
    "\n",
    "time_scale = 18\n",
    "amp_per_freq = {'Subject': [], 'Freq(kHz) (x1)': [], 'Level(dB) (x2)': [], 'Amplitude (x3)':[]}\n",
    "start_path = '/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/abr_data/WPZ Electrophysiology'\n",
    "for subject in os.listdir(start_path):\n",
    "    # print(\"Subject:\",subject)\n",
    "    for fq in os.listdir(os.path.join(start_path,subject)):\n",
    "        # print(fq)\n",
    "        if fq.startswith('ABR') and fq.endswith('.tsv'):\n",
    "            path = os.path.join(start_path,subject,fq)\n",
    "            data_df = read_custom_tsv(path)\n",
    "            # print(data_df)\n",
    "            freqs = data_df['Freq(kHz)'].unique().tolist()\n",
    "            levels = data_df['Level(dB)'].unique().tolist()\n",
    "            for freq in freqs:\n",
    "                for lvl in levels:\n",
    "                    # print(\"Frequency=\",freq, \"Level=\", lvl)\n",
    "                    _, _, amp = peaks_troughs_amp_final(df=data_df, freq=freq, db=lvl, time_scale=time_scale)\n",
    "                    # print(f'Amplitude: {amp}\\n')\n",
    "                    amp_per_freq['Subject'].append(subject)\n",
    "                    amp_per_freq['Freq(kHz) (x1)'].append(freq)\n",
    "                    amp_per_freq['Level(dB) (x2)'].append(lvl)\n",
    "                    amp_per_freq['Amplitude (x3)'].append(amp)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "amp_df_full = pd.DataFrame(data=amp_per_freq)\n",
    "\n",
    "raw_synapse_counts = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Ribbon and Synapse Counts.xlsx')\n",
    "raw_synapse_counts = raw_synapse_counts.mask(lambda x: x.isnull()).dropna()\n",
    "raw_synapse_counts['Synapses to IHC (y1)'] = raw_synapse_counts.iloc[:,6]\n",
    "raw_synapse_counts['vx (x4)'] = raw_synapse_counts['vx']\n",
    "raw_synapse_counts.drop(columns=['vx'], inplace=True)\n",
    "raw_synapse_counts.rename(columns={'Freq':'Freq(kHz) (x1)'}, inplace=True)\n",
    "# raw_synapse_counts['Freq(Hz) (x1)'] = raw_synapse_counts['Freq(Hz) (x1)'].apply(lambda x: x*1000) # PUTTING BACK\n",
    "raw_synapse_counts.rename(columns={'Case':'Subject'}, inplace=True)\n",
    "\n",
    "paired2 = amp_df_full.join(raw_synapse_counts.set_index(['Subject', 'Freq(kHz) (x1)']), on=['Subject', 'Freq(kHz) (x1)'])\n",
    "# lilslice = paired[paired['Subject']=='WPZ174'][['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs']]\n",
    "final2 = paired2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'Synapses', 'IHCs']]\n",
    "final_clean2 = final2.dropna()\n",
    "\n",
    "# adding in the strain feature\n",
    "strains = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Mouse groups.xlsx')\n",
    "final_clean_strained2 = final_clean2.join(strains.set_index('ID#'), on='Subject')\n",
    "final_clean_strained2['Strain'] = final_clean_strained2['Strain'].str.strip()\n",
    "final_clean_strained2 = final_clean_strained2.rename(columns={'Strain': 'Strain (x5)'})\n",
    "final_clean_strained2 = final_clean_strained2.dropna()\n",
    "final_clean_strained2 = final_clean_strained2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)', 'Strain (x5)', 'Synapses to IHC (y1)', 'Group', 'Synapses', 'IHCs']]\n",
    "# np.unique(final_clean_strained2['Group'])\n",
    "\n",
    "# final_clean_70 = final_clean[final_clean['Level(dB) (x2)'] >= 70.0]\n",
    "# final_clean_strained_70 = final_clean_strained[final_clean_strained['Level(dB) (x2)'] >= 70.0]\n",
    "# # np.unique(final_clean['Level(dB) (x2)']) max level is 80 db\n",
    "# len(final_clean), len(final_clean_70) # 10000 less data points!!!\n",
    "\n",
    "final_clean_strained_grouped2 = final_clean_strained2.copy()\n",
    "final_clean_strained_grouped2['Group - dB'] = final_clean_strained_grouped2['Group'].apply(lambda x: x.split(' ')[0] if x.split(' ')[0].endswith('dB') else 'Control')\n",
    "final_clean_strained_grouped2['Group - Time Elapsed'] = final_clean_strained_grouped2['Group'].apply(lambda x: x.split(' ')[1] if x.split(' ')[1].endswith(('h', 'wks', 'w')) else x.split(' ')[0])\n",
    "final_clean_strained_grouped2.head()\n",
    "\n",
    "final_clean_strained_grouped_pos2 = final_clean_strained_grouped2.copy()\n",
    "final_clean_strained_grouped_pos2['Amplitude (x3)'] = final_clean_strained_grouped2['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "len(final_clean_strained_grouped_pos2[final_clean_strained_grouped_pos2['Amplitude (x3)'] < 0])\n",
    "\n",
    "final_clean_strained_grouped_pos2['Amplitude (x3)'] = final_clean_strained_grouped2['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# final_clean_strained_grouped_pos[(final_clean_strained_grouped_pos['Subject'] == 'WPZ66') & (final_clean_strained_grouped_pos['Amplitude (x3)'] ==0.055901451434921576)\n",
    "final_clean_strained_grouped_pos_cleangroup2 = final_clean_strained_grouped_pos2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup2['Group'] = final_clean_strained_grouped_pos_cleangroup2['Group'].apply(lambda x: x.strip())\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup2['Group'])\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup2.head()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2 = final_clean_strained_grouped_pos_cleangroup2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs2['Group - dB']\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed']\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2 = final_clean_strained_grouped_pos_cleangroup_vs2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)',\n",
    "       'vx (x4)', 'Strain (x5)','Group - dB (x6)', 'Group - Time Elapsed', 'Group','Synapses to IHC (y1)', 'Synapses', 'IHCs']]\n",
    "\n",
    "def split_on_number(input_string):\n",
    "    return re.findall(r\"[A-Za-z]+|\\d+\", input_string)\n",
    "\n",
    "hrs_week = 24*7\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2 = final_clean_strained_grouped_pos_cleangroup_vs2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: '0dB' if x == 'Control' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'].apply(lambda x: x[1])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'].apply(lambda x: \"wks\" if x == 'w' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Hours Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2.apply(lambda row: row['Group - Time Elapsed - Magn.']* hrs_week if row['Group - Time Elapsed - Unit'] == 'wks' else row['Group - Time Elapsed - Magn.'], axis = 1)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Days Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Hours Elapsed (x7)'].apply(lambda x: x/24)\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Freq(kHz) (x1)</th>\n",
       "      <th>Level(dB) (x2)</th>\n",
       "      <th>Amplitude (x3)</th>\n",
       "      <th>vx (x4)</th>\n",
       "      <th>Synapses to IHC (y1)</th>\n",
       "      <th>IHCs (y2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v1</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v2</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v1</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v2</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.154224</td>\n",
       "      <td>v1</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.634279</td>\n",
       "      <td>v2</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v1</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v2</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v1</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v2</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12187 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Freq(kHz) (x1)  Level(dB) (x2)  Amplitude (x3) vx (x4)  \\\n",
       "0     WPZ145            45.2            70.0        0.033579      v1   \n",
       "0     WPZ145            45.2            70.0        0.033579      v2   \n",
       "1     WPZ145            45.2            75.0        0.034262      v1   \n",
       "1     WPZ145            45.2            75.0        0.034262      v2   \n",
       "2     WPZ145            45.2            80.0        0.154224      v1   \n",
       "...      ...             ...             ...             ...     ...   \n",
       "7328  WPZ101            32.0            60.0        1.634279      v2   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v1   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v2   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v1   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v2   \n",
       "\n",
       "      Synapses to IHC (y1) IHCs (y2)  \n",
       "0                 8.750000       8.8  \n",
       "0                10.888889         9  \n",
       "1                 8.750000       8.8  \n",
       "1                10.888889         9  \n",
       "2                 8.750000       8.8  \n",
       "...                    ...       ...  \n",
       "7328             15.463918       9.7  \n",
       "7329             16.923077       9.1  \n",
       "7329             15.463918       9.7  \n",
       "7330             16.923077       9.1  \n",
       "7330             15.463918       9.7  \n",
       "\n",
       "[12187 rows x 7 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Lin Reg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_clean_strained_grouped_pos_cleangroup_vs_timed[['Freq(kHz) (x1)', 'Level(dB) (x2)','Amplitude (x3)']]\n",
    "y = final_clean_strained_grouped_pos_cleangroup_vs_timed['Synapses to IHC (y1)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8962291261784285, 2.895859167040614)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vanilla = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Train RMSE = 2.913936454557555\n",
      "Test RMSE = 2.8239328735809175\n",
      "\n",
      "Processing Fold 2\n",
      "Train RMSE = 2.98472400080733\n",
      "Test RMSE = 2.5109567657958833\n",
      "\n",
      "Processing Fold 3\n",
      "Train RMSE = 2.8023395289110073\n",
      "Test RMSE = 3.2444697246817285\n",
      "\n",
      "Processing Fold 4\n",
      "Train RMSE = 2.9618158381505606\n",
      "Test RMSE = 2.617029707707716\n",
      "\n",
      "Processing Fold 5\n",
      "Train RMSE = 2.8131074445144497\n",
      "Test RMSE = 3.2069717077308724\n",
      "\n",
      "Average Train RMSE across 5 folds: 2.8951846533881804\n",
      "Average Test RMSE across 5 folds: 2.8806721558994233\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "K=5\n",
    "kf = KFold(n_splits=K)\n",
    "\n",
    "train_fold_RMSES = []\n",
    "test_fold_RMSES = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    print(f'Processing Fold {i+1}')\n",
    "    X_train, y_train = X.iloc[train_index,:], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index,:], y.iloc[test_index]\n",
    "\n",
    "    y_preds_train = model.predict(X_train)\n",
    "    RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "    print(f'Train RMSE = {RMSE_train}')\n",
    "    train_fold_RMSES.append(RMSE_train)\n",
    "\n",
    "    y_preds_test = model.predict(X_test)\n",
    "    RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "    print(f'Test RMSE = {RMSE_test}\\n')\n",
    "    test_fold_RMSES.append(RMSE_test)\n",
    "\n",
    "avg_train_RMSE = np.mean(train_fold_RMSES)\n",
    "avg_test_RMSE = np.mean(test_fold_RMSES)\n",
    "\n",
    "print(f'Average Train RMSE across {K} folds: {avg_train_RMSE}')\n",
    "print(f'Average Test RMSE across {K} folds: {avg_test_RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject', 'FreqkHz', 'LeveldB', 'Amplitude', 'vx (x4)', 'Strain (x5)',\n",
       "       'Group - dB (x6)', 'Group - Time Elapsed', 'Group', 'Synapses_to_IHC',\n",
       "       'Group - Time Elapsed - Split', 'Group - Time Elapsed - Magn.',\n",
       "       'Group - Time Elapsed - Unit', 'Group - Hours Elapsed (x7)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed_ols.rename(columns = {'Freq(kHz) (x1)' : 'FreqkHz', 'Level(dB) (x2)': 'LeveldB', 'Amplitude (x3)' : 'Amplitude', 'Synapses to IHC (y1)' : 'Synapses_to_IHC'})\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_ols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        Synapses_to_IHC   R-squared:                       0.087\n",
      "Model:                            OLS   Adj. R-squared:                  0.087\n",
      "Method:                 Least Squares   F-statistic:                     389.0\n",
      "Date:                Thu, 27 Mar 2025   Prob (F-statistic):          2.75e-241\n",
      "Time:                        16:57:15   Log-Likelihood:                -30252.\n",
      "No. Observations:               12187   AIC:                         6.051e+04\n",
      "Df Residuals:                   12183   BIC:                         6.054e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     16.9318      0.076    224.028      0.000      16.784      17.080\n",
      "FreqkHz       -0.0212      0.002    -10.034      0.000      -0.025      -0.017\n",
      "LeveldB       -0.0436      0.002    -27.151      0.000      -0.047      -0.040\n",
      "Amplitude      1.8119      0.072     25.203      0.000       1.671       1.953\n",
      "==============================================================================\n",
      "Omnibus:                     1189.536   Durbin-Watson:                   0.426\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1570.508\n",
      "Skew:                          -0.835   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.548   Cond. No.                         159.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Partial F-test for Amplitude:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12184.0  107543.230986      0.0          NaN         NaN            NaN\n",
      "1   12183.0  102214.200102      1.0  5329.030883  635.171857  1.148661e-136\n",
      "\n",
      "Partial F-test for FreqkHz:\n",
      "   df_resid            ssr  df_diff    ss_diff           F        Pr(>F)\n",
      "0   12184.0  103058.980812      0.0        NaN         NaN           NaN\n",
      "1   12183.0  102214.200102      1.0  844.78071  100.690152  1.328264e-23\n",
      "\n",
      "Partial F-test for LeveldB:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12184.0  108399.132479      0.0          NaN         NaN            NaN\n",
      "1   12183.0  102214.200102      1.0  6184.932377  737.187505  1.143657e-157\n",
      "\n",
      "Partial F-test for FreqkHz and LeveldB together:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12185.0  110540.565956      0.0          NaN         NaN            NaN\n",
      "1   12183.0  102214.200102      2.0  8326.365854  496.213418  6.688783e-208\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Full model\n",
    "full_model = ols('Synapses_to_IHC ~ FreqkHz + LeveldB + Amplitude', \n",
    "                data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"Full Model Summary:\")\n",
    "print(full_model.summary())\n",
    "\n",
    "# Partial F-test for Amplitude\n",
    "reduced_model1 = ols('Synapses_to_IHC ~ FreqkHz + LeveldB', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for Amplitude:\")\n",
    "print(anova_lm(reduced_model1, full_model))\n",
    "\n",
    "# Partial F-test for FreqkHz\n",
    "reduced_model2 = ols('Synapses_to_IHC ~ LeveldB + Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz:\")\n",
    "print(anova_lm(reduced_model2, full_model))\n",
    "\n",
    "# Partial F-test for LeveldB\n",
    "reduced_model3 = ols('Synapses_to_IHC ~ FreqkHz + Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for LeveldB:\")\n",
    "print(anova_lm(reduced_model3, full_model))\n",
    "\n",
    "# Partial F-test for FreqkHz and LeveldB jointly\n",
    "reduced_model4 = ols('Synapses_to_IHC ~ Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz and LeveldB together:\")\n",
    "print(anova_lm(reduced_model4, full_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C57B6', 'CBA/CaJ'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed['Strain (x5)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded = final_clean_strained_grouped_pos_cleangroup_vs_timed.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'].apply(lambda x: 0 if x == 'C57B6' else 1)\n",
    "\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded[['Freq(kHz) (x1)', 'Level(dB) (x2)','Amplitude (x3)', 'Strain (x5)']]\n",
    "y = final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Synapses to IHC (y1)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2, random_state=42, stratify=final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8396751633699444, 2.8321396400722816)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strain_strat = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model_strain_strat.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model_strain_strat.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.8593, Test RMSE: 2.7928\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.8486, Test RMSE: 2.8358\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8546, Test RMSE: 2.8118\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8024, Test RMSE: 3.0167\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.8627, Test RMSE: 2.7774\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "\n",
      "Average Train RMSE: 2.8455\n",
      "Average Test RMSE: 2.8469\n"
     ]
    }
   ],
   "source": [
    "train_rmses, test_rmses = stratified_kfold_by_feature(X, y, model_strain_strat, stratify_col='Strain (x5)', n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on the Average between Viewing Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'])\n",
    "subs = np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'])\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['CrossFreq_SIHCRatio (y2)'] = 0\n",
    "for freq in freqs:\n",
    "    for sub in subs:\n",
    "        mask = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub)] # global for updates\n",
    "        if len(mask) > 0:\n",
    "\n",
    "            mask1 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['vx (x4)'] == 'v1')]\n",
    "            mask2 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['vx (x4)'] == 'v2')]\n",
    "\n",
    "            if not mask1.empty and not mask2.empty:\n",
    "                mask1 = mask1.reset_index().iloc[0,:]\n",
    "                mask2 = mask2.reset_index().iloc[0,:]\n",
    "\n",
    "                total_syns = float(mask1['Synapses'] + mask2['Synapses'])\n",
    "                total_ihcs = float(mask1['IHCs'] + mask2['IHCs'])\n",
    "                ratio = total_syns / total_ihcs\n",
    "                # print(total_syns, total_ihcs)\n",
    "                # if total_syns == 0.0 or total_ihcs == 0.0:\n",
    "                #     print(sub, freq)\n",
    "                mask_index = mask.index\n",
    "                final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[mask_index,'CrossFreq_SIHCRatio (y2)'] = ratio\n",
    "\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['CrossFreq_SIHCRatio (y2)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Freq(kHz) (x1)</th>\n",
       "      <th>Level(dB) (x2)</th>\n",
       "      <th>Amplitude (x3)</th>\n",
       "      <th>vx (x4)</th>\n",
       "      <th>Strain (x5)</th>\n",
       "      <th>Group - dB (x6)</th>\n",
       "      <th>Group - Time Elapsed</th>\n",
       "      <th>Group</th>\n",
       "      <th>Synapses to IHC (y1)</th>\n",
       "      <th>Synapses</th>\n",
       "      <th>IHCs</th>\n",
       "      <th>Group - Time Elapsed - Split</th>\n",
       "      <th>Group - Time Elapsed - Magn.</th>\n",
       "      <th>Group - Time Elapsed - Unit</th>\n",
       "      <th>Group - Hours Elapsed (x7)</th>\n",
       "      <th>CrossFreq_SIHCRatio (y2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>9.831461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>9.831461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>9.831461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>9.831461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.154224</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>9.831461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.634279</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>16.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>16.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>16.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>16.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "      <td>16.170213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12187 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Freq(kHz) (x1)  Level(dB) (x2)  Amplitude (x3) vx (x4)  \\\n",
       "0     WPZ145            45.2            70.0        0.033579      v1   \n",
       "0     WPZ145            45.2            70.0        0.033579      v2   \n",
       "1     WPZ145            45.2            75.0        0.034262      v1   \n",
       "1     WPZ145            45.2            75.0        0.034262      v2   \n",
       "2     WPZ145            45.2            80.0        0.154224      v1   \n",
       "...      ...             ...             ...             ...     ...   \n",
       "7328  WPZ101            32.0            60.0        1.634279      v2   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v1   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v2   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v1   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v2   \n",
       "\n",
       "     Strain (x5)  Group - dB (x6) Group - Time Elapsed           Group  \\\n",
       "0          C57B6               98                 8wks  98dB 8wks post   \n",
       "0          C57B6               98                 8wks  98dB 8wks post   \n",
       "1          C57B6               98                 8wks  98dB 8wks post   \n",
       "1          C57B6               98                 8wks  98dB 8wks post   \n",
       "2          C57B6               98                 8wks  98dB 8wks post   \n",
       "...          ...              ...                  ...             ...   \n",
       "7328       C57B6                0                 8wks       8wks ctrl   \n",
       "7329       C57B6                0                 8wks       8wks ctrl   \n",
       "7329       C57B6                0                 8wks       8wks ctrl   \n",
       "7330       C57B6                0                 8wks       8wks ctrl   \n",
       "7330       C57B6                0                 8wks       8wks ctrl   \n",
       "\n",
       "      Synapses to IHC (y1)  Synapses IHCs Group - Time Elapsed - Split  \\\n",
       "0                 8.750000      77.0  8.8                     [8, wks]   \n",
       "0                10.888889      98.0    9                     [8, wks]   \n",
       "1                 8.750000      77.0  8.8                     [8, wks]   \n",
       "1                10.888889      98.0    9                     [8, wks]   \n",
       "2                 8.750000      77.0  8.8                     [8, wks]   \n",
       "...                    ...       ...  ...                          ...   \n",
       "7328             15.463918     150.0  9.7                     [8, wks]   \n",
       "7329             16.923077     154.0  9.1                     [8, wks]   \n",
       "7329             15.463918     150.0  9.7                     [8, wks]   \n",
       "7330             16.923077     154.0  9.1                     [8, wks]   \n",
       "7330             15.463918     150.0  9.7                     [8, wks]   \n",
       "\n",
       "      Group - Time Elapsed - Magn. Group - Time Elapsed - Unit  \\\n",
       "0                                8                         wks   \n",
       "0                                8                         wks   \n",
       "1                                8                         wks   \n",
       "1                                8                         wks   \n",
       "2                                8                         wks   \n",
       "...                            ...                         ...   \n",
       "7328                             8                         wks   \n",
       "7329                             8                         wks   \n",
       "7329                             8                         wks   \n",
       "7330                             8                         wks   \n",
       "7330                             8                         wks   \n",
       "\n",
       "      Group - Hours Elapsed (x7)  CrossFreq_SIHCRatio (y2)  \n",
       "0                           1344                  9.831461  \n",
       "0                           1344                  9.831461  \n",
       "1                           1344                  9.831461  \n",
       "1                           1344                  9.831461  \n",
       "2                           1344                  9.831461  \n",
       "...                          ...                       ...  \n",
       "7328                        1344                 16.170213  \n",
       "7329                        1344                 16.170213  \n",
       "7329                        1344                 16.170213  \n",
       "7330                        1344                 16.170213  \n",
       "7330                        1344                 16.170213  \n",
       "\n",
       "[12187 rows x 17 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[['Freq(kHz) (x1)', 'Level(dB) (x2)','Amplitude (x3)']]\n",
    "y = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['CrossFreq_SIHCRatio (y2)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8550383868161306, 2.809730708641642)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_avg = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model_avg.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model_avg.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Train RMSE = 2.886838782352169\n",
      "Test RMSE = 2.6770189314300614\n",
      "\n",
      "Processing Fold 2\n",
      "Train RMSE = 2.8975812792576545\n",
      "Test RMSE = 2.6301996813955\n",
      "\n",
      "Processing Fold 3\n",
      "Train RMSE = 2.7386335902853784\n",
      "Test RMSE = 3.240606795032601\n",
      "\n",
      "Processing Fold 4\n",
      "Train RMSE = 2.926657181804546\n",
      "Test RMSE = 2.49796415741554\n",
      "\n",
      "Processing Fold 5\n",
      "Train RMSE = 2.776022020542586\n",
      "Test RMSE = 3.1107275550318314\n",
      "\n",
      "Average Train RMSE across 5 folds: 2.8451465708484664\n",
      "Average Test RMSE across 5 folds: 2.831303424061107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.8451465708484664, 2.831303424061107)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_modeltesting(5, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV and strat with average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Strain (x5)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Strain (x5)'].apply(lambda x: 0 if x == 'C57B6' else 1)\n",
    "\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.782994962533814, 2.784551261309025)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded[['Freq(kHz) (x1)', 'Level(dB) (x2)','Amplitude (x3)', 'Strain (x5)']]\n",
    "y = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['CrossFreq_SIHCRatio (y2)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2, random_state=42, stratify=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Strain (x5)'])\n",
    "\n",
    "model_avg_strat = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model_avg_strat.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model_avg_strat.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.8593, Test RMSE: 2.7928\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.8486, Test RMSE: 2.8358\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8546, Test RMSE: 2.8118\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8024, Test RMSE: 3.0167\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.8627, Test RMSE: 2.7774\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "\n",
      "Average Train RMSE: 2.8455\n",
      "Average Test RMSE: 2.8469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.8593100269612495,\n",
       "  2.8485848543093146,\n",
       "  2.8545606174936444,\n",
       "  2.802416986249799,\n",
       "  2.8627248637946963],\n",
       " [2.792816529817402,\n",
       "  2.8358183967258204,\n",
       "  2.8117558719870215,\n",
       "  3.0166896322711962,\n",
       "  2.7774033198878034])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratified_kfold_by_feature(X, y, model_avg_strat, 'Strain (x5)', n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance Tests - Avg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject', 'FreqkHz', 'LeveldB', 'Amplitude', 'vx (x4)', 'Strain (x5)',\n",
       "       'Group - dB (x6)', 'Group - Time Elapsed', 'Group',\n",
       "       'Synapses to IHC (y1)', 'Synapses', 'IHCs',\n",
       "       'Group - Time Elapsed - Split', 'Group - Time Elapsed - Magn.',\n",
       "       'Group - Time Elapsed - Unit', 'Group - Hours Elapsed (x7)',\n",
       "       'CrossFreqSIHCRatio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols.rename(columns = {'Freq(kHz) (x1)' : 'FreqkHz', 'Level(dB) (x2)': 'LeveldB', 'Amplitude (x3)' : 'Amplitude', 'CrossFreq_SIHCRatio (y2)' : 'CrossFreqSIHCRatio'})\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FreqkHz</th>\n",
       "      <td>875.532365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.068882</td>\n",
       "      <td>3.308869e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeveldB</th>\n",
       "      <td>6010.878572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>741.935936</td>\n",
       "      <td>1.215870e-158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amplitude</th>\n",
       "      <td>5163.762006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>637.374479</td>\n",
       "      <td>4.026487e-137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>98701.963503</td>\n",
       "      <td>12183.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sum_sq       df           F         PR(>F)\n",
       "FreqkHz      875.532365      1.0  108.068882   3.308869e-25\n",
       "LeveldB     6010.878572      1.0  741.935936  1.215870e-158\n",
       "Amplitude   5163.762006      1.0  637.374479  4.026487e-137\n",
       "Residual   98701.963503  12183.0         NaN            NaN"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude', data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     CrossFreqSIHCRatio   R-squared:                       0.089\n",
      "Model:                            OLS   Adj. R-squared:                  0.088\n",
      "Method:                 Least Squares   F-statistic:                     395.2\n",
      "Date:                Thu, 27 Mar 2025   Prob (F-statistic):          5.83e-245\n",
      "Time:                        16:52:40   Log-Likelihood:                -30039.\n",
      "No. Observations:               12187   AIC:                         6.009e+04\n",
      "Df Residuals:                   12183   BIC:                         6.011e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     16.8852      0.074    227.352      0.000      16.740      17.031\n",
      "FreqkHz       -0.0216      0.002    -10.396      0.000      -0.026      -0.018\n",
      "LeveldB       -0.0430      0.002    -27.239      0.000      -0.046      -0.040\n",
      "Amplitude      1.7836      0.071     25.246      0.000       1.645       1.922\n",
      "==============================================================================\n",
      "Omnibus:                     2120.809   Durbin-Watson:                   0.117\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3995.496\n",
      "Skew:                          -1.083   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.783   Cond. No.                         159.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Partial F-test for Amplitude:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12184.0  103865.725509      0.0          NaN         NaN            NaN\n",
      "1   12183.0   98701.963503      1.0  5163.762006  637.374479  4.026487e-137\n",
      "\n",
      "Partial F-test for FreqkHz:\n",
      "   df_resid           ssr  df_diff     ss_diff           F        Pr(>F)\n",
      "0   12184.0  99577.495868      0.0         NaN         NaN           NaN\n",
      "1   12183.0  98701.963503      1.0  875.532365  108.068882  3.308869e-25\n",
      "\n",
      "Partial F-test for LeveldB:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12184.0  104712.842075      0.0          NaN         NaN            NaN\n",
      "1   12183.0   98701.963503      1.0  6010.878572  741.935936  1.215870e-158\n",
      "\n",
      "Partial F-test for FreqkHz and LeveldB together:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12185.0  106882.219443      0.0          NaN         NaN            NaN\n",
      "1   12183.0   98701.963503      2.0  8180.255941  504.853473  2.279990e-211\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Full model\n",
    "full_model = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude', \n",
    "                data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"Full Model Summary:\")\n",
    "print(full_model.summary())\n",
    "\n",
    "# Partial F-test for Amplitude\n",
    "reduced_model1 = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for Amplitude:\")\n",
    "print(anova_lm(reduced_model1, full_model))\n",
    "\n",
    "# Partial F-test for FreqkHz\n",
    "reduced_model2 = ols('CrossFreqSIHCRatio ~ LeveldB + Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz:\")\n",
    "print(anova_lm(reduced_model2, full_model))\n",
    "\n",
    "# Partial F-test for LeveldB\n",
    "reduced_model3 = ols('CrossFreqSIHCRatio ~ FreqkHz + Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for LeveldB:\")\n",
    "print(anova_lm(reduced_model3, full_model))\n",
    "\n",
    "# Partial F-test for FreqkHz and LeveldB jointly\n",
    "reduced_model4 = ols('CrossFreqSIHCRatio ~ Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz and LeveldB together:\")\n",
    "print(anova_lm(reduced_model4, full_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_manorimagepred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
