{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import os\n",
    "import struct\n",
    "import datetime\n",
    "# from skfda import FDataGrid\n",
    "# from skfda.preprocessing.dim_reduction import FPCA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import torch.nn as nn\n",
    "import splitfolders\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import find_peaks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np4\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import torch\n",
    "import torch.distributed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ABRA_35 import interpolate_and_smooth, CNN, plot_wave, calculate_and_plot_wave, plot_waves_single_frequency, arfread, get_str, calculate_hearing_threshold, all_thresholds, peak_finding\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_modeltesting(K, X, y, mod):\n",
    "    kf = KFold(n_splits=K)\n",
    "\n",
    "    train_fold_RMSES = []\n",
    "    test_fold_RMSES = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "        print(f'Processing Fold {i+1}')\n",
    "        X_train, y_train = X.iloc[train_index,:], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index,:], y.iloc[test_index]\n",
    "\n",
    "        y_preds_train = mod.predict(X_train)\n",
    "        RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "        print(f'Train RMSE = {RMSE_train}')\n",
    "        train_fold_RMSES.append(RMSE_train)\n",
    "\n",
    "        y_preds_test = mod.predict(X_test)\n",
    "        RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "        print(f'Test RMSE = {RMSE_test}\\n')\n",
    "        test_fold_RMSES.append(RMSE_test)\n",
    "\n",
    "    avg_train_RMSE = np.mean(train_fold_RMSES)\n",
    "    avg_test_RMSE = np.mean(test_fold_RMSES)\n",
    "\n",
    "    print(f'Average Train RMSE across {K} folds: {avg_train_RMSE}')\n",
    "    print(f'Average Test RMSE across {K} folds: {avg_test_RMSE}')\n",
    "\n",
    "    return avg_train_RMSE, avg_test_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfold_by_feature(X, y, model, stratify_col, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform cross-validation stratified by a specific feature column,\n",
    "    but exclude that column from being used as a predictor.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        The feature matrix (must be a pandas DataFrame)\n",
    "    y : Series or array-like\n",
    "        The target variable\n",
    "    model : estimator object\n",
    "        The model to evaluate\n",
    "    stratify_col : str\n",
    "        Name of the column in X to stratify by (will be excluded from predictors)\n",
    "    n_splits : int, default=5\n",
    "        Number of folds\n",
    "    random_state : int, default=42\n",
    "        Random state for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    train_rmse_scores : list\n",
    "        RMSE scores for training sets\n",
    "    test_rmse_scores : list\n",
    "        RMSE scores for test sets\n",
    "    \"\"\"\n",
    "    # Ensure X is a DataFrame\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise TypeError(\"X must be a pandas DataFrame to use column name for stratification\")\n",
    "    \n",
    "    # Extract the stratification column\n",
    "    stratify_values = X[stratify_col].values\n",
    "    \n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Lists to store the RMSE scores for each fold\n",
    "    train_rmse_scores = []\n",
    "    test_rmse_scores = []\n",
    "    \n",
    "    # Remove the stratify column from the features\n",
    "    X_for_model = X.drop(columns=[stratify_col])\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, stratify_values)):\n",
    "        print(f'Processing Fold {i+1}')\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test = X_for_model.iloc[train_index], X_for_model.iloc[test_index]\n",
    "        \n",
    "        if isinstance(y, pd.Series):\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        else:\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        \n",
    "        # Store the scores\n",
    "        train_rmse_scores.append(train_rmse)\n",
    "        test_rmse_scores.append(test_rmse)\n",
    "        \n",
    "        # Print fold statistics with stratification distribution\n",
    "        train_strat_dist = X.iloc[train_index][stratify_col].value_counts(normalize=True).to_dict()\n",
    "        test_strat_dist = X.iloc[test_index][stratify_col].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        print(f'Fold {i+1} - Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}')\n",
    "        print(f'  Train distribution of {stratify_col}: {train_strat_dist}')\n",
    "        print(f'  Test distribution of {stratify_col}: {test_strat_dist}')\n",
    "    \n",
    "    # Calculate and print average scores\n",
    "    avg_train_rmse = np.mean(train_rmse_scores)\n",
    "    avg_test_rmse = np.mean(test_rmse_scores)\n",
    "    \n",
    "    print(f'\\nAverage Train RMSE: {avg_train_rmse:.4f}')\n",
    "    print(f'Average Test RMSE: {avg_test_rmse:.4f}')\n",
    "    \n",
    "    return train_rmse_scores, test_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfold_by_feature2(X, y, model, stratify_col, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform cross-validation stratified by a specific feature column,\n",
    "    but exclude that column from being used as a predictor.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame\n",
    "        The feature matrix (must be a pandas DataFrame)\n",
    "    y : Series or array-like\n",
    "        The target variable\n",
    "    model : estimator object\n",
    "        The model to evaluate\n",
    "    stratify_col : str\n",
    "        Name of the column in X to stratify by (will be excluded from predictors)\n",
    "    n_splits : int, default=5\n",
    "        Number of folds\n",
    "    random_state : int, default=42\n",
    "        Random state for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    train_rmse_scores : list\n",
    "        RMSE scores for training sets\n",
    "    test_rmse_scores : list\n",
    "        RMSE scores for test sets\n",
    "    \"\"\"\n",
    "    # Ensure X is a DataFrame\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        raise TypeError(\"X must be a pandas DataFrame to use column name for stratification\")\n",
    "    \n",
    "    # Extract the stratification column\n",
    "    stratify_values = X[stratify_col].values\n",
    "    \n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Lists to store the RMSE scores for each fold\n",
    "    train_rmse_scores = []\n",
    "    test_rmse_scores = []\n",
    "    \n",
    "    # Remove the stratify column from the features\n",
    "    X_for_model = X.drop(columns=[stratify_col])\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, stratify_values)):\n",
    "        print(f'Processing Fold {i+1}')\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test = X_for_model.iloc[train_index], X_for_model.iloc[test_index]\n",
    "        \n",
    "        if isinstance(y, pd.Series):\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        else:\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        # model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        \n",
    "        # Store the scores\n",
    "        train_rmse_scores.append(train_rmse)\n",
    "        test_rmse_scores.append(test_rmse)\n",
    "        \n",
    "        # Print fold statistics with stratification distribution\n",
    "        train_strat_dist = X.iloc[train_index][stratify_col].value_counts(normalize=True).to_dict()\n",
    "        test_strat_dist = X.iloc[test_index][stratify_col].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        print(f'Fold {i+1} - Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}')\n",
    "        # print(f'  Train distribution of {stratify_col}: {train_strat_dist}')\n",
    "        # print(f'  Test distribution of {stratify_col}: {test_strat_dist}')\n",
    "    \n",
    "    # Calculate and print average scores\n",
    "    avg_train_rmse = np.mean(train_rmse_scores)\n",
    "    avg_test_rmse = np.mean(test_rmse_scores)\n",
    "    \n",
    "    print(f'\\nAverage Train RMSE: {avg_train_rmse:.4f}')\n",
    "    print(f'Average Test RMSE: {avg_test_rmse:.4f}')\n",
    "    \n",
    "    \n",
    "    return train_rmse_scores, test_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_grouped_kfold_by_feature_ridge(X, y, data, group_col, stratify_col, numerical_cols, n_splits=5, \n",
    "                                             random_state=42, alpha=0.01, \n",
    "                                             formula='CrossFreqSIHCRatio ~ FreqkHz_scaled + Amplitude_scaled + FreqkHz_scaled*Amplitude_scaled'):\n",
    "    \"\"\"\n",
    "    Perform group k-fold cross-validation with approximate stratification.\n",
    "    This ensures that data from the same subject stays together while approximately maintaining the distribution of stratify_col.\n",
    "    \"\"\"\n",
    "    # Get unique groups and their corresponding stratify values\n",
    "    unique_groups = data[group_col].unique()\n",
    "    group_to_stratify = {group: data[data[group_col] == group][stratify_col].iloc[0] for group in unique_groups}\n",
    "    \n",
    "    # Create a DataFrame with group-level info\n",
    "    group_df = pd.DataFrame({\n",
    "        'group': list(group_to_stratify.keys()),\n",
    "        'stratify_value': list(group_to_stratify.values())\n",
    "    })\n",
    "    \n",
    "    # Split at the group level with stratification\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    group_splits = list(skf.split(group_df, group_df['stratify_value']))\n",
    "    \n",
    "    RMSE_train_total = 0\n",
    "    RMSE_test_total = 0\n",
    "    \n",
    "    for i, (train_groups_idx, test_groups_idx) in enumerate(group_splits):\n",
    "        train_groups = group_df.iloc[train_groups_idx]['group'].values\n",
    "        test_groups = group_df.iloc[test_groups_idx]['group'].values\n",
    "        \n",
    "        train_mask = data[group_col].isin(train_groups)\n",
    "        test_mask = data[group_col].isin(test_groups)\n",
    "        \n",
    "        train_data = data[train_mask].copy()\n",
    "        test_data = data[test_mask].copy()\n",
    "        \n",
    "        for col in numerical_cols:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(train_data[[col]])\n",
    "            train_data[f'{col}_scaled'] = scaler.transform(train_data[[col]])\n",
    "            test_data[f'{col}_scaled'] = scaler.transform(test_data[[col]])\n",
    "        \n",
    "        model = smf.ols(formula, data=train_data).fit_regularized(L1_wt=0.0, alpha=alpha)\n",
    "        \n",
    "        y_preds_train = model.predict(train_data)\n",
    "        RMSE_train = np.sqrt(mean_squared_error(train_data['CrossFreqSIHCRatio'], y_preds_train))\n",
    "        RMSE_train_total += RMSE_train\n",
    "        \n",
    "        y_preds_test = model.predict(test_data)\n",
    "        RMSE_test = np.sqrt(mean_squared_error(test_data['CrossFreqSIHCRatio'], y_preds_test))\n",
    "        RMSE_test_total += RMSE_test\n",
    "        \n",
    "        print(f\"Fold {i+1}/{n_splits}: Train RMSE = {RMSE_train:.4f}, Test RMSE = {RMSE_test:.4f}\")\n",
    "        print(f\"              Train groups: {len(train_groups)}, Test groups: {len(test_groups)}\")\n",
    "        print(f\"              Train data points: {len(train_data)}, Test data points: {len(test_data)}\")\n",
    "        \n",
    "    avg_train_RMSE = RMSE_train_total / n_splits\n",
    "    avg_test_RMSE = RMSE_test_total / n_splits\n",
    "    \n",
    "    print(f\"\\nFinal Results - Avg Train RMSE = {avg_train_RMSE:.5f}, Avg Test RMSE = {avg_test_RMSE:.5f}\")\n",
    "    \n",
    "    return avg_train_RMSE, avg_test_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stratified_kfold_by_feature_ridge(X, y, data, stratify_col, numerical_cols, n_splits=5, random_state=42, alpha=0.01, formula='CrossFreqSIHCRatio ~ FreqkHz_scaled + Amplitude_scaled + FreqkHz_scaled*Amplitude_scaled'):\n",
    "#     stratify_values = X[stratify_col].values\n",
    "#     skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "#     RMSE_train_total = 0\n",
    "#     RMSE_test_total = 0\n",
    "#     for i, (train_index, test_index) in enumerate(skf.split(X, stratify_values)):\n",
    "\n",
    "#         train_data = data.iloc[train_index].copy()\n",
    "#         test_data = data.iloc[test_index].copy()\n",
    "\n",
    "#         scaler = StandardScaler()\n",
    "#         for col in numerical_cols:\n",
    "#             scaler.fit(train_data[[col]])\n",
    "#             train_data[f'{col}_scaled'] = scaler.transform(train_data[[col]])\n",
    "#             test_data[f'{col}_scaled'] = scaler.transform(test_data[[col]])\n",
    "\n",
    "\n",
    "#         model = smf.ols(formula, data=train_data).fit_regularized(L1_wt=0.0, alpha=alpha)\n",
    "\n",
    "#         y_preds_train = model.predict(train_data)\n",
    "#         RMSE_train = np.sqrt(mean_squared_error(train_data['CrossFreqSIHCRatio'], y_preds_train))\n",
    "#         RMSE_train_total += RMSE_train\n",
    "\n",
    "#         y_preds_test = model.predict(test_data)\n",
    "#         RMSE_test = np.sqrt(mean_squared_error(test_data['CrossFreqSIHCRatio'], y_preds_test))\n",
    "#         RMSE_test_total += RMSE_test\n",
    "\n",
    "#         print(f\"Fold {i+1}/{n_splits}: Train RMSE = {RMSE_train:.4f}, Test RMSE = {RMSE_test:.4f}\")\n",
    "\n",
    "#     avg_train_RMSE = RMSE_train_total / n_splits\n",
    "#     avg_test_RMSE = RMSE_test_total / n_splits\n",
    "\n",
    "#     print(f\"\\nFinal Results - Avg Train RMSE = {avg_train_RMSE:.5f}, Avg Test RMSE = {avg_test_RMSE:.5f}\")\n",
    "#     # return avg_train_RMSE, avg_test_RMSE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = 128\n",
    "filter2 = 32\n",
    "dropout1 = 0.5\n",
    "dropout2 = 0.3\n",
    "dropout_fc = 0.1\n",
    "\n",
    "# Model initialization\n",
    "peak_finding_model = CNN(filter1, filter2, dropout1, dropout2, dropout_fc)\n",
    "model_loader = torch.load('./models/waveI_cnn.pth')\n",
    "peak_finding_model.load_state_dict(model_loader)\n",
    "peak_finding_model.eval()\n",
    "\n",
    "def peak_finding(wave):\n",
    "    # Prepare waveform\n",
    "    waveform=interpolate_and_smooth(wave) # Added indexing per calculate and plot wave function\n",
    "    # waveform_torch = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0) archived ABRA\n",
    "    waveform_torch = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).unsqueeze(0) #newer ABRA\n",
    "    # print(waveform_torch)\n",
    "    # Get prediction from model\n",
    "    outputs = peak_finding_model(waveform_torch)\n",
    "    prediction = int(round(outputs.detach().numpy()[0][0], 0))\n",
    "    # prediction_test = int(round(outputs.detach().numpy()[0], 0))\n",
    "    # print(\"Model output:\", outputs, \"Prediction true start:\", prediction)\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    smoothed_waveform = gaussian_filter1d(waveform, sigma=1)\n",
    "\n",
    "    # Find peaks and troughs\n",
    "    n = 18\n",
    "    t = 14\n",
    "    # start_point = prediction - 9 archived ABRA\n",
    "    start_point = prediction - 6 #newer ABRA\n",
    "    smoothed_peaks, _ = find_peaks(smoothed_waveform[start_point:], distance=n)\n",
    "    smoothed_troughs, _ = find_peaks(-smoothed_waveform, distance=t)\n",
    "    sorted_indices = np.argsort(smoothed_waveform[smoothed_peaks+start_point])\n",
    "    highest_smoothed_peaks = np.sort(smoothed_peaks[sorted_indices[-5:]] + start_point)\n",
    "    relevant_troughs = np.array([])\n",
    "    for p in range(len(highest_smoothed_peaks)):\n",
    "        c = 0\n",
    "        for t in smoothed_troughs:\n",
    "            if t > highest_smoothed_peaks[p]:\n",
    "                if p != 4:\n",
    "                    try:\n",
    "                        if t < highest_smoothed_peaks[p+1]:\n",
    "                            relevant_troughs = np.append(relevant_troughs, int(t))\n",
    "                            break\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                else:\n",
    "                    relevant_troughs = np.append(relevant_troughs, int(t))\n",
    "                    break\n",
    "    relevant_troughs = relevant_troughs.astype('i')\n",
    "    return highest_smoothed_peaks, relevant_troughs\n",
    "\n",
    "def extract_metadata(metadata_lines):\n",
    "    # Dictionary to store extracted metadata\n",
    "    metadata = {}\n",
    "    \n",
    "    for line in metadata_lines:\n",
    "        # Extract SW FREQ\n",
    "        freq_match = re.search(r'SW FREQ:\\s*(\\d+\\.?\\d*)', line)\n",
    "        if freq_match:\n",
    "            metadata['SW_FREQ'] = float(freq_match.group(1))\n",
    "        \n",
    "        # Extract LEVELS\n",
    "        levels_match = re.search(r':LEVELS:\\s*([^:]+)', line)\n",
    "        if levels_match:\n",
    "            # Split levels and convert to list of floats\n",
    "            metadata['LEVELS'] = [float(level) for level in levels_match.group(1).split(';') if level]\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def read_custom_tsv(file_path):\n",
    "    # Read the entire file\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split the content into metadata and data sections\n",
    "    metadata_lines = []\n",
    "    data_section = None\n",
    "    \n",
    "    # Find the ':DATA' marker\n",
    "    data_start = content.find(':DATA')\n",
    "    \n",
    "    if data_start != -1:\n",
    "        # Extract metadata (lines before ':DATA')\n",
    "        metadata_lines = content[:data_start].split('\\n')\n",
    "        \n",
    "        # Extract data section\n",
    "        data_section = content[data_start:].split(':DATA')[1].strip()\n",
    "    \n",
    "    # Extract specific metadata\n",
    "    metadata = extract_metadata(metadata_lines)\n",
    "    \n",
    "    # Read the data section directly\n",
    "    try:\n",
    "        # Use StringIO to create a file-like object from the data section\n",
    "        raw_data = pd.read_csv(\n",
    "            io.StringIO(data_section), \n",
    "            sep='\\s+',  # Use whitespace as separator\n",
    "            header=None\n",
    "        )\n",
    "        raw_data = raw_data.T\n",
    "        # Add metadata columns to the DataFrame\n",
    "        if 'SW_FREQ' in metadata:\n",
    "            raw_data['Freq(kHz)'] = metadata['SW_FREQ']\n",
    "            # raw_data['Freq(Hz)'] = raw_data['Freq(Hz)'].apply(lambda x: x*1000)\n",
    "        \n",
    "        if 'LEVELS' in metadata:\n",
    "            # Repeat levels to match the number of rows\n",
    "            levels_repeated = metadata['LEVELS'] * (len(raw_data) // len(metadata['LEVELS']) + 1)\n",
    "            raw_data['Level(dB)'] = levels_repeated[:len(raw_data)]\n",
    "        \n",
    "        filtered_data = raw_data.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "        filtered_data.columns = filtered_data.columns.map(str)\n",
    "\n",
    "        columns = ['Freq(kHz)'] + ['Level(dB)'] + [col for col in filtered_data.columns if col.isnumeric() == True]\n",
    "        filtered_data = filtered_data[columns]\n",
    "        return filtered_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data: {e}\")\n",
    "        return None, metadata\n",
    "\n",
    "\n",
    "def peaks_troughs_amp_final(df, freq, db, time_scale=10, multiply_y_factor=1.0, units='Microvolts'):\n",
    "    db_column = 'Level(dB)'\n",
    "    \n",
    "    khz = df[(df['Freq(kHz)'] == freq) & (df[db_column] == db)]\n",
    "    if not khz.empty:\n",
    "        index = khz.index.values[0]\n",
    "        final = df.loc[index, '0':].dropna()\n",
    "        final = pd.to_numeric(final, errors='coerce').dropna()\n",
    "\n",
    "        target = int(244 * (time_scale / 10))\n",
    "        \n",
    "        # Process the wave as in calculate_and_plot_wave\n",
    "        y_values = interpolate_and_smooth(final, target)\n",
    "        \n",
    "        # Apply scaling factor\n",
    "        y_values *= multiply_y_factor\n",
    "        \n",
    "        # Handle units conversion if needed\n",
    "        if units == 'Nanovolts':\n",
    "            y_values /= 1000\n",
    "            \n",
    "        # Generate normalized version for peak finding\n",
    "        y_values_fpf = interpolate_and_smooth(y_values[:244])\n",
    "        \n",
    "        # Standardize and normalize for peak finding, exactly as in the original\n",
    "        flattened_data = y_values_fpf.flatten().reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        standardized_data = scaler.fit_transform(flattened_data)\n",
    "        min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = min_max_scaler.fit_transform(standardized_data).reshape(y_values_fpf.shape)\n",
    "        y_values_fpf = interpolate_and_smooth(scaled_data[:244])\n",
    "        \n",
    "        # Find peaks using the normalized data\n",
    "        highest_peaks, relevant_troughs = peak_finding(y_values_fpf)\n",
    "        \n",
    "        # Calculate amplitude on the processed but non-normalized data\n",
    "        if highest_peaks.size > 0 and relevant_troughs.size > 0:\n",
    "            # Following the same approach as in the display_metrics_table function\n",
    "            first_peak_amplitude = y_values[highest_peaks[0]] - y_values[relevant_troughs[0]]\n",
    "            return highest_peaks, relevant_troughs, first_peak_amplitude\n",
    "    \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL DATA SPLIT\n",
    "\n",
    "time_scale = 18\n",
    "amp_per_freq = {'Subject': [], 'Freq(kHz) (x1)': [], 'Level(dB) (x2)': [], 'Amplitude (x3)':[]}\n",
    "start_path = '/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/abr_data/WPZ Electrophysiology'\n",
    "for subject in os.listdir(start_path):\n",
    "    # print(\"Subject:\",subject)\n",
    "    for fq in os.listdir(os.path.join(start_path,subject)):\n",
    "        # print(fq)\n",
    "        if fq.startswith('ABR') and fq.endswith('.tsv'):\n",
    "            path = os.path.join(start_path,subject,fq)\n",
    "            data_df = read_custom_tsv(path)\n",
    "            # print(data_df)\n",
    "            freqs = data_df['Freq(kHz)'].unique().tolist()\n",
    "            levels = data_df['Level(dB)'].unique().tolist()\n",
    "            for freq in freqs:\n",
    "                for lvl in levels:\n",
    "                    # print(\"Frequency=\",freq, \"Level=\", lvl)\n",
    "                    _, _, amp = peaks_troughs_amp_final(df=data_df, freq=freq, db=lvl, time_scale=time_scale)\n",
    "                    # print(f'Amplitude: {amp}\\n')\n",
    "                    amp_per_freq['Subject'].append(subject)\n",
    "                    amp_per_freq['Freq(kHz) (x1)'].append(freq)\n",
    "                    amp_per_freq['Level(dB) (x2)'].append(lvl)\n",
    "                    amp_per_freq['Amplitude (x3)'].append(amp)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "amp_df_full = pd.DataFrame(data=amp_per_freq)\n",
    "\n",
    "raw_synapse_counts = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Ribbon and Synapse Counts.xlsx')\n",
    "raw_synapse_counts = raw_synapse_counts.mask(lambda x: x.isnull()).dropna()\n",
    "raw_synapse_counts['Synapses to IHC (y1)'] = raw_synapse_counts.iloc[:,6]\n",
    "raw_synapse_counts['vx (x4)'] = raw_synapse_counts['vx']\n",
    "raw_synapse_counts.drop(columns=['vx'], inplace=True)\n",
    "raw_synapse_counts.rename(columns={'Freq':'Freq(kHz) (x1)'}, inplace=True)\n",
    "# raw_synapse_counts['Freq(Hz) (x1)'] = raw_synapse_counts['Freq(Hz) (x1)'].apply(lambda x: x*1000) # PUTTING BACK\n",
    "raw_synapse_counts.rename(columns={'Case':'Subject', 'IHCs' : 'IHCs (y2)'}, inplace=True)\n",
    "\n",
    "paired = amp_df_full.join(raw_synapse_counts.set_index(['Subject', 'Freq(kHz) (x1)']), on=['Subject', 'Freq(kHz) (x1)'])\n",
    "slice = paired[paired['Subject']=='WPZ174'][['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs (y2)']]\n",
    "final = paired[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs (y2)']]\n",
    "final_clean = final.dropna()\n",
    "\n",
    "# adding in the strain feature\n",
    "strains = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Mouse groups.xlsx')\n",
    "final_clean_strained = final_clean.join(strains.set_index('ID#'), on='Subject')\n",
    "final_clean_strained['Strain'] = final_clean_strained['Strain'].str.strip()\n",
    "final_clean_strained = final_clean_strained.rename(columns={'Strain': 'Strain (x5)'})\n",
    "final_clean_strained = final_clean_strained.dropna()\n",
    "final_clean_strained_foundation = final_clean_strained.copy()\n",
    "final_clean_strained = final_clean_strained[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)', 'Strain (x5)', 'Synapses to IHC (y1)', 'Group']]\n",
    "np.unique(final_clean_strained['Group'])\n",
    "\n",
    "final_clean_70 = final_clean[final_clean['Level(dB) (x2)'] >= 70.0]\n",
    "final_clean_strained_70 = final_clean_strained[final_clean_strained['Level(dB) (x2)'] >= 70.0]\n",
    "# np.unique(final_clean['Level(dB) (x2)']) max level is 80 db\n",
    "len(final_clean), len(final_clean_70) # 10000 less data points!!!\n",
    "\n",
    "final_clean_strained_grouped = final_clean_strained.copy()\n",
    "final_clean_strained_grouped['Group - dB'] = final_clean_strained_grouped['Group'].apply(lambda x: x.split(' ')[0] if x.split(' ')[0].endswith('dB') else 'Control')\n",
    "final_clean_strained_grouped['Group - Time Elapsed'] = final_clean_strained_grouped['Group'].apply(lambda x: x.split(' ')[1] if x.split(' ')[1].endswith(('h', 'wks', 'w')) else x.split(' ')[0])\n",
    "final_clean_strained_grouped.head()\n",
    "\n",
    "final_clean_strained_grouped_pos = final_clean_strained_grouped.copy()\n",
    "final_clean_strained_grouped_pos['Amplitude (x3)'] = final_clean_strained_grouped['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "len(final_clean_strained_grouped_pos[final_clean_strained_grouped_pos['Amplitude (x3)'] < 0])\n",
    "\n",
    "final_clean_strained_grouped_pos['Amplitude (x3)'] = final_clean_strained_grouped['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# final_clean_strained_grouped_pos[(final_clean_strained_grouped_pos['Subject'] == 'WPZ66') & (final_clean_strained_grouped_pos['Amplitude (x3)'] ==0.055901451434921576)\n",
    "final_clean_strained_grouped_pos_cleangroup = final_clean_strained_grouped_pos.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup['Group'] = final_clean_strained_grouped_pos_cleangroup['Group'].apply(lambda x: x.strip())\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup['Group'])\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup.head()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs = final_clean_strained_grouped_pos_cleangroup.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - dB']\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed']\n",
    "final_clean_strained_grouped_pos_cleangroup_vs = final_clean_strained_grouped_pos_cleangroup_vs[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)',\n",
    "       'vx (x4)', 'Strain (x5)','Group - dB (x6)', 'Group - Time Elapsed', 'Group','Synapses to IHC (y1)']]\n",
    "\n",
    "def split_on_number(input_string):\n",
    "    return re.findall(r\"[A-Za-z]+|\\d+\", input_string)\n",
    "\n",
    "hrs_week = 24*7\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed = final_clean_strained_grouped_pos_cleangroup_vs.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: '0dB' if x == 'Control' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Magn.'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Split'].apply(lambda x: x[1])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Time Elapsed - Unit'].apply(lambda x: \"wks\" if x == 'w' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Hours Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed.apply(lambda row: row['Group - Time Elapsed - Magn.']* hrs_week if row['Group - Time Elapsed - Unit'] == 'wks' else row['Group - Time Elapsed - Magn.'], axis = 1)\n",
    "\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Days Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Hours Elapsed (x7)'].apply(lambda x: x/24)\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Freq(kHz) (x1)</th>\n",
       "      <th>Level(dB) (x2)</th>\n",
       "      <th>Amplitude (x3)</th>\n",
       "      <th>vx (x4)</th>\n",
       "      <th>Strain (x5)</th>\n",
       "      <th>Group - dB (x6)</th>\n",
       "      <th>Group - Time Elapsed</th>\n",
       "      <th>Group</th>\n",
       "      <th>Synapses to IHC (y1)</th>\n",
       "      <th>Synapses</th>\n",
       "      <th>IHCs</th>\n",
       "      <th>Group - Time Elapsed - Split</th>\n",
       "      <th>Group - Time Elapsed - Magn.</th>\n",
       "      <th>Group - Time Elapsed - Unit</th>\n",
       "      <th>Group - Hours Elapsed (x7)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.154224</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>98</td>\n",
       "      <td>8wks</td>\n",
       "      <td>98dB 8wks post</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.634279</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v1</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>0</td>\n",
       "      <td>8wks</td>\n",
       "      <td>8wks ctrl</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>[8, wks]</td>\n",
       "      <td>8</td>\n",
       "      <td>wks</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12187 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Freq(kHz) (x1)  Level(dB) (x2)  Amplitude (x3) vx (x4)  \\\n",
       "0     WPZ145            45.2            70.0        0.033579      v1   \n",
       "0     WPZ145            45.2            70.0        0.033579      v2   \n",
       "1     WPZ145            45.2            75.0        0.034262      v1   \n",
       "1     WPZ145            45.2            75.0        0.034262      v2   \n",
       "2     WPZ145            45.2            80.0        0.154224      v1   \n",
       "...      ...             ...             ...             ...     ...   \n",
       "7328  WPZ101            32.0            60.0        1.634279      v2   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v1   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v2   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v1   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v2   \n",
       "\n",
       "     Strain (x5)  Group - dB (x6) Group - Time Elapsed           Group  \\\n",
       "0          C57B6               98                 8wks  98dB 8wks post   \n",
       "0          C57B6               98                 8wks  98dB 8wks post   \n",
       "1          C57B6               98                 8wks  98dB 8wks post   \n",
       "1          C57B6               98                 8wks  98dB 8wks post   \n",
       "2          C57B6               98                 8wks  98dB 8wks post   \n",
       "...          ...              ...                  ...             ...   \n",
       "7328       C57B6                0                 8wks       8wks ctrl   \n",
       "7329       C57B6                0                 8wks       8wks ctrl   \n",
       "7329       C57B6                0                 8wks       8wks ctrl   \n",
       "7330       C57B6                0                 8wks       8wks ctrl   \n",
       "7330       C57B6                0                 8wks       8wks ctrl   \n",
       "\n",
       "      Synapses to IHC (y1)  Synapses IHCs Group - Time Elapsed - Split  \\\n",
       "0                 8.750000      77.0  8.8                     [8, wks]   \n",
       "0                10.888889      98.0    9                     [8, wks]   \n",
       "1                 8.750000      77.0  8.8                     [8, wks]   \n",
       "1                10.888889      98.0    9                     [8, wks]   \n",
       "2                 8.750000      77.0  8.8                     [8, wks]   \n",
       "...                    ...       ...  ...                          ...   \n",
       "7328             15.463918     150.0  9.7                     [8, wks]   \n",
       "7329             16.923077     154.0  9.1                     [8, wks]   \n",
       "7329             15.463918     150.0  9.7                     [8, wks]   \n",
       "7330             16.923077     154.0  9.1                     [8, wks]   \n",
       "7330             15.463918     150.0  9.7                     [8, wks]   \n",
       "\n",
       "      Group - Time Elapsed - Magn. Group - Time Elapsed - Unit  \\\n",
       "0                                8                         wks   \n",
       "0                                8                         wks   \n",
       "1                                8                         wks   \n",
       "1                                8                         wks   \n",
       "2                                8                         wks   \n",
       "...                            ...                         ...   \n",
       "7328                             8                         wks   \n",
       "7329                             8                         wks   \n",
       "7329                             8                         wks   \n",
       "7330                             8                         wks   \n",
       "7330                             8                         wks   \n",
       "\n",
       "      Group - Hours Elapsed (x7)  \n",
       "0                           1344  \n",
       "0                           1344  \n",
       "1                           1344  \n",
       "1                           1344  \n",
       "2                           1344  \n",
       "...                          ...  \n",
       "7328                        1344  \n",
       "7329                        1344  \n",
       "7329                        1344  \n",
       "7330                        1344  \n",
       "7330                        1344  \n",
       "\n",
       "[12187 rows x 16 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEW DATA SPLIT\n",
    "\n",
    "time_scale = 18\n",
    "amp_per_freq = {'Subject': [], 'Freq(kHz) (x1)': [], 'Level(dB) (x2)': [], 'Amplitude (x3)':[]}\n",
    "start_path = '/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/abr_data/WPZ Electrophysiology'\n",
    "for subject in os.listdir(start_path):\n",
    "    # print(\"Subject:\",subject)\n",
    "    for fq in os.listdir(os.path.join(start_path,subject)):\n",
    "        # print(fq)\n",
    "        if fq.startswith('ABR') and fq.endswith('.tsv'):\n",
    "            path = os.path.join(start_path,subject,fq)\n",
    "            data_df = read_custom_tsv(path)\n",
    "            # print(data_df)\n",
    "            freqs = data_df['Freq(kHz)'].unique().tolist()\n",
    "            levels = data_df['Level(dB)'].unique().tolist()\n",
    "            for freq in freqs:\n",
    "                for lvl in levels:\n",
    "                    # print(\"Frequency=\",freq, \"Level=\", lvl)\n",
    "                    _, _, amp = peaks_troughs_amp_final(df=data_df, freq=freq, db=lvl, time_scale=time_scale)\n",
    "                    # print(f'Amplitude: {amp}\\n')\n",
    "                    amp_per_freq['Subject'].append(subject)\n",
    "                    amp_per_freq['Freq(kHz) (x1)'].append(freq)\n",
    "                    amp_per_freq['Level(dB) (x2)'].append(lvl)\n",
    "                    amp_per_freq['Amplitude (x3)'].append(amp)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "amp_df_full = pd.DataFrame(data=amp_per_freq)\n",
    "\n",
    "raw_synapse_counts = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Ribbon and Synapse Counts.xlsx')\n",
    "raw_synapse_counts = raw_synapse_counts.mask(lambda x: x.isnull()).dropna()\n",
    "raw_synapse_counts['Synapses to IHC (y1)'] = raw_synapse_counts.iloc[:,6]\n",
    "raw_synapse_counts['vx (x4)'] = raw_synapse_counts['vx']\n",
    "raw_synapse_counts.drop(columns=['vx'], inplace=True)\n",
    "raw_synapse_counts.rename(columns={'Freq':'Freq(kHz) (x1)'}, inplace=True)\n",
    "# raw_synapse_counts['Freq(Hz) (x1)'] = raw_synapse_counts['Freq(Hz) (x1)'].apply(lambda x: x*1000) # PUTTING BACK\n",
    "raw_synapse_counts.rename(columns={'Case':'Subject'}, inplace=True)\n",
    "\n",
    "paired2 = amp_df_full.join(raw_synapse_counts.set_index(['Subject', 'Freq(kHz) (x1)']), on=['Subject', 'Freq(kHz) (x1)'])\n",
    "# lilslice = paired[paired['Subject']=='WPZ174'][['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'IHCs']]\n",
    "final2 = paired2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)','Synapses to IHC (y1)', 'Synapses', 'IHCs']]\n",
    "final_clean2 = final2.dropna()\n",
    "\n",
    "# adding in the strain feature\n",
    "strains = pd.read_excel('/Users/leahashebir/Downloads/Manor_Practicum/liberman_data/WPZ Mouse groups.xlsx')\n",
    "final_clean_strained2 = final_clean2.join(strains.set_index('ID#'), on='Subject')\n",
    "final_clean_strained2['Strain'] = final_clean_strained2['Strain'].str.strip()\n",
    "final_clean_strained2 = final_clean_strained2.rename(columns={'Strain': 'Strain (x5)'})\n",
    "final_clean_strained2 = final_clean_strained2.dropna()\n",
    "final_clean_strained2 = final_clean_strained2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)', 'vx (x4)', 'Strain (x5)', 'Synapses to IHC (y1)', 'Group', 'Synapses', 'IHCs']]\n",
    "# np.unique(final_clean_strained2['Group'])\n",
    "\n",
    "# final_clean_70 = final_clean[final_clean['Level(dB) (x2)'] >= 70.0]\n",
    "# final_clean_strained_70 = final_clean_strained[final_clean_strained['Level(dB) (x2)'] >= 70.0]\n",
    "# # np.unique(final_clean['Level(dB) (x2)']) max level is 80 db\n",
    "# len(final_clean), len(final_clean_70) # 10000 less data points!!!\n",
    "\n",
    "final_clean_strained_grouped2 = final_clean_strained2.copy()\n",
    "final_clean_strained_grouped2['Group - dB'] = final_clean_strained_grouped2['Group'].apply(lambda x: x.split(' ')[0] if x.split(' ')[0].endswith('dB') else 'Control')\n",
    "final_clean_strained_grouped2['Group - Time Elapsed'] = final_clean_strained_grouped2['Group'].apply(lambda x: x.split(' ')[1] if x.split(' ')[1].endswith(('h', 'wks', 'w')) else x.split(' ')[0])\n",
    "final_clean_strained_grouped2.head()\n",
    "\n",
    "final_clean_strained_grouped_pos2 = final_clean_strained_grouped2.copy()\n",
    "final_clean_strained_grouped_pos2['Amplitude (x3)'] = final_clean_strained_grouped2['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "len(final_clean_strained_grouped_pos2[final_clean_strained_grouped_pos2['Amplitude (x3)'] < 0])\n",
    "\n",
    "final_clean_strained_grouped_pos2['Amplitude (x3)'] = final_clean_strained_grouped2['Amplitude (x3)'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "# final_clean_strained_grouped_pos[(final_clean_strained_grouped_pos['Subject'] == 'WPZ66') & (final_clean_strained_grouped_pos['Amplitude (x3)'] ==0.055901451434921576)\n",
    "final_clean_strained_grouped_pos_cleangroup2 = final_clean_strained_grouped_pos2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup2['Group'] = final_clean_strained_grouped_pos_cleangroup2['Group'].apply(lambda x: x.strip())\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup2['Group'])\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup2.head()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2 = final_clean_strained_grouped_pos_cleangroup2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs2['Group - dB']\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs['Group - Time Elapsed']\n",
    "final_clean_strained_grouped_pos_cleangroup_vs2 = final_clean_strained_grouped_pos_cleangroup_vs2[['Subject', 'Freq(kHz) (x1)', 'Level(dB) (x2)', 'Amplitude (x3)',\n",
    "       'vx (x4)', 'Strain (x5)','Group - dB (x6)', 'Group - Time Elapsed', 'Group','Synapses to IHC (y1)', 'Synapses', 'IHCs']]\n",
    "\n",
    "def split_on_number(input_string):\n",
    "    return re.findall(r\"[A-Za-z]+|\\d+\", input_string)\n",
    "\n",
    "hrs_week = 24*7\n",
    "\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2 = final_clean_strained_grouped_pos_cleangroup_vs2.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: '0dB' if x == 'Control' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - dB (x6)'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed'].apply(split_on_number)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'].apply(lambda x: x[0])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Magn.'].apply(lambda x: int(x.strip()))\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Split'].apply(lambda x: x[1])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Time Elapsed - Unit'].apply(lambda x: \"wks\" if x == 'w' else x)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2['Group - Hours Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2.apply(lambda row: row['Group - Time Elapsed - Magn.']* hrs_week if row['Group - Time Elapsed - Unit'] == 'wks' else row['Group - Time Elapsed - Magn.'], axis = 1)\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Days Elapsed (x7)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - Hours Elapsed (x7)'].apply(lambda x: x/24)\n",
    "# final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed['Group - dB (x6)'].apply(lambda )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Freq(kHz) (x1)</th>\n",
       "      <th>Level(dB) (x2)</th>\n",
       "      <th>Amplitude (x3)</th>\n",
       "      <th>vx (x4)</th>\n",
       "      <th>Synapses to IHC (y1)</th>\n",
       "      <th>Synapses</th>\n",
       "      <th>IHCs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v1</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>v2</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v1</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>v2</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WPZ145</td>\n",
       "      <td>45.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.154224</td>\n",
       "      <td>v1</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.634279</td>\n",
       "      <td>v2</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v1</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.769193</td>\n",
       "      <td>v2</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v1</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>WPZ101</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.023154</td>\n",
       "      <td>v2</td>\n",
       "      <td>15.463918</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12187 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Freq(kHz) (x1)  Level(dB) (x2)  Amplitude (x3) vx (x4)  \\\n",
       "0     WPZ145            45.2            70.0        0.033579      v1   \n",
       "0     WPZ145            45.2            70.0        0.033579      v2   \n",
       "1     WPZ145            45.2            75.0        0.034262      v1   \n",
       "1     WPZ145            45.2            75.0        0.034262      v2   \n",
       "2     WPZ145            45.2            80.0        0.154224      v1   \n",
       "...      ...             ...             ...             ...     ...   \n",
       "7328  WPZ101            32.0            60.0        1.634279      v2   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v1   \n",
       "7329  WPZ101            32.0            70.0        1.769193      v2   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v1   \n",
       "7330  WPZ101            32.0            80.0        1.023154      v2   \n",
       "\n",
       "      Synapses to IHC (y1)  Synapses IHCs  \n",
       "0                 8.750000      77.0  8.8  \n",
       "0                10.888889      98.0    9  \n",
       "1                 8.750000      77.0  8.8  \n",
       "1                10.888889      98.0    9  \n",
       "2                 8.750000      77.0  8.8  \n",
       "...                    ...       ...  ...  \n",
       "7328             15.463918     150.0  9.7  \n",
       "7329             16.923077     154.0  9.1  \n",
       "7329             15.463918     150.0  9.7  \n",
       "7330             16.923077     154.0  9.1  \n",
       "7330             15.463918     150.0  9.7  \n",
       "\n",
       "[12187 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Lin Reg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_clean_strained_grouped_pos_cleangroup_vs_timed[['Freq(kHz) (x1)', 'Level(dB) (x2)','Amplitude (x3)']]\n",
    "y = final_clean_strained_grouped_pos_cleangroup_vs_timed['Synapses to IHC (y1)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8962291261784285, 2.895859167040614)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vanilla = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model_vanilla.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model_vanilla.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Train RMSE = 2.913936454557555\n",
      "Test RMSE = 2.8239328735809175\n",
      "\n",
      "Processing Fold 2\n",
      "Train RMSE = 2.98472400080733\n",
      "Test RMSE = 2.5109567657958833\n",
      "\n",
      "Processing Fold 3\n",
      "Train RMSE = 2.8023395289110073\n",
      "Test RMSE = 3.2444697246817285\n",
      "\n",
      "Processing Fold 4\n",
      "Train RMSE = 2.9618158381505606\n",
      "Test RMSE = 2.617029707707716\n",
      "\n",
      "Processing Fold 5\n",
      "Train RMSE = 2.8131074445144497\n",
      "Test RMSE = 3.2069717077308724\n",
      "\n",
      "Average Train RMSE across 5 folds: 2.8951846533881804\n",
      "Average Test RMSE across 5 folds: 2.8806721558994233\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "K=5\n",
    "kf = KFold(n_splits=K)\n",
    "\n",
    "train_fold_RMSES = []\n",
    "test_fold_RMSES = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    print(f'Processing Fold {i+1}')\n",
    "    X_train, y_train = X.iloc[train_index,:], y.iloc[train_index]\n",
    "    X_test, y_test = X.iloc[test_index,:], y.iloc[test_index]\n",
    "\n",
    "    y_preds_train = model_vanilla.predict(X_train)\n",
    "    RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "    print(f'Train RMSE = {RMSE_train}')\n",
    "    train_fold_RMSES.append(RMSE_train)\n",
    "\n",
    "    y_preds_test = model_vanilla.predict(X_test)\n",
    "    RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "    print(f'Test RMSE = {RMSE_test}\\n')\n",
    "    test_fold_RMSES.append(RMSE_test)\n",
    "\n",
    "avg_train_RMSE = np.mean(train_fold_RMSES)\n",
    "avg_test_RMSE = np.mean(test_fold_RMSES)\n",
    "\n",
    "print(f'Average Train RMSE across {K} folds: {avg_train_RMSE}')\n",
    "print(f'Average Test RMSE across {K} folds: {avg_test_RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject', 'FreqkHz', 'LeveldB', 'Amplitude', 'vx (x4)', 'Strain (x5)',\n",
       "       'Group - dB (x6)', 'Group - Time Elapsed', 'Group', 'Synapses_to_IHC',\n",
       "       'Group - Time Elapsed - Split', 'Group - Time Elapsed - Magn.',\n",
       "       'Group - Time Elapsed - Unit', 'Group - Hours Elapsed (x7)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed_ols.rename(columns = {'Freq(kHz) (x1)' : 'FreqkHz', 'Level(dB) (x2)': 'LeveldB', 'Amplitude (x3)' : 'Amplitude', 'Synapses to IHC (y1)' : 'Synapses_to_IHC'})\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_ols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        Synapses_to_IHC   R-squared:                       0.087\n",
      "Model:                            OLS   Adj. R-squared:                  0.087\n",
      "Method:                 Least Squares   F-statistic:                     389.0\n",
      "Date:                Tue, 01 Apr 2025   Prob (F-statistic):          2.75e-241\n",
      "Time:                        21:25:51   Log-Likelihood:                -30252.\n",
      "No. Observations:               12187   AIC:                         6.051e+04\n",
      "Df Residuals:                   12183   BIC:                         6.054e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     16.9318      0.076    224.028      0.000      16.784      17.080\n",
      "FreqkHz       -0.0212      0.002    -10.034      0.000      -0.025      -0.017\n",
      "LeveldB       -0.0436      0.002    -27.151      0.000      -0.047      -0.040\n",
      "Amplitude      1.8119      0.072     25.203      0.000       1.671       1.953\n",
      "==============================================================================\n",
      "Omnibus:                     1189.536   Durbin-Watson:                   0.426\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1570.508\n",
      "Skew:                          -0.835   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.548   Cond. No.                         159.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Partial F-test for Amplitude:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12184.0  107543.230986      0.0          NaN         NaN            NaN\n",
      "1   12183.0  102214.200102      1.0  5329.030883  635.171857  1.148661e-136\n",
      "\n",
      "Partial F-test for FreqkHz:\n",
      "   df_resid            ssr  df_diff    ss_diff           F        Pr(>F)\n",
      "0   12184.0  103058.980812      0.0        NaN         NaN           NaN\n",
      "1   12183.0  102214.200102      1.0  844.78071  100.690152  1.328264e-23\n",
      "\n",
      "Partial F-test for LeveldB:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12184.0  108399.132479      0.0          NaN         NaN            NaN\n",
      "1   12183.0  102214.200102      1.0  6184.932377  737.187505  1.143657e-157\n",
      "\n",
      "Partial F-test for FreqkHz and LeveldB together:\n",
      "   df_resid            ssr  df_diff      ss_diff           F         Pr(>F)\n",
      "0   12185.0  110540.565956      0.0          NaN         NaN            NaN\n",
      "1   12183.0  102214.200102      2.0  8326.365854  496.213418  6.688783e-208\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Full model\n",
    "full_model = ols('Synapses_to_IHC ~ FreqkHz + LeveldB + Amplitude', \n",
    "                data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"Full Model Summary:\")\n",
    "print(full_model.summary())\n",
    "\n",
    "# Partial F-test for Amplitude\n",
    "reduced_model1 = ols('Synapses_to_IHC ~ FreqkHz + LeveldB', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for Amplitude:\")\n",
    "print(anova_lm(reduced_model1, full_model))\n",
    "\n",
    "# Partial F-test for FreqkHz\n",
    "reduced_model2 = ols('Synapses_to_IHC ~ LeveldB + Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz:\")\n",
    "print(anova_lm(reduced_model2, full_model))\n",
    "\n",
    "# Partial F-test for LeveldB\n",
    "reduced_model3 = ols('Synapses_to_IHC ~ FreqkHz + Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for LeveldB:\")\n",
    "print(anova_lm(reduced_model3, full_model))\n",
    "\n",
    "# Partial F-test for FreqkHz and LeveldB jointly\n",
    "reduced_model4 = ols('Synapses_to_IHC ~ Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz and LeveldB together:\")\n",
    "print(anova_lm(reduced_model4, full_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C57B6', 'CBA/CaJ'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed['Strain (x5)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded = final_clean_strained_grouped_pos_cleangroup_vs_timed.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'].apply(lambda x: 0 if x == 'C57B6' else 1)\n",
    "\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded[['Freq(kHz) (x1)', 'Level(dB) (x2)','Amplitude (x3)', 'Strain (x5)']]\n",
    "y = final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Synapses to IHC (y1)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2, random_state=42, stratify=final_clean_strained_grouped_pos_cleangroup_vs_timed_encoded['Strain (x5)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8396751633699444, 2.8321396400722816)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_strain_strat = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model_strain_strat.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model_strain_strat.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.9084, Test RMSE: 2.8473\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.9023, Test RMSE: 2.8721\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8971, Test RMSE: 2.8928\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8624, Test RMSE: 3.0302\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.9084, Test RMSE: 2.8462\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "\n",
      "Average Train RMSE: 2.8957\n",
      "Average Test RMSE: 2.8977\n"
     ]
    }
   ],
   "source": [
    "train_rmses, test_rmses = stratified_kfold_by_feature(X, y, model_strain_strat, stratify_col='Strain (x5)', n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting on the Average between Viewing Fields**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2['Freq(kHz) (x1)'])\n",
    "subs = np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2['Subject'])\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx = final_clean_strained_grouped_pos_cleangroup_vs_timed2.copy()\n",
    "for freq in freqs:\n",
    "    for sub in subs:\n",
    "        mask = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub)] # global for updates\n",
    "        if len(mask) > 0:\n",
    "\n",
    "            mask1 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['vx (x4)'] == 'v1')]\n",
    "            mask2 = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == freq) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == sub) & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['vx (x4)'] == 'v2')]\n",
    "\n",
    "            if not mask1.empty and not mask2.empty:\n",
    "                mask1 = mask1.reset_index().iloc[0,:]\n",
    "                mask2 = mask2.reset_index().iloc[0,:]\n",
    "\n",
    "                total_syns = float(mask1['Synapses'] + mask2['Synapses'])\n",
    "                total_ihcs = float(mask1['IHCs'] + mask2['IHCs'])\n",
    "                ratio = total_syns / total_ihcs\n",
    "                # print(total_syns, total_ihcs)\n",
    "                # if total_syns == 0.0 or total_ihcs == 0.0:\n",
    "                #     print(sub, freq)\n",
    "                mask_index = mask.index\n",
    "                final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[mask_index,'CrossFreq_SIHCRatio (y2)'] = ratio\n",
    "            elif mask1.empty:\n",
    "                mask2 = mask2.reset_index().iloc[0,:]\n",
    "                total_syns = float(mask2['Synapses'])\n",
    "                total_ihcs = float(mask2['IHCs'])\n",
    "                ratio = total_syns / total_ihcs\n",
    "                # print(total_syns, total_ihcs)\n",
    "                # if total_syns == 0.0 or total_ihcs == 0.0:\n",
    "                #     print(sub, freq)\n",
    "                mask_index = mask.index\n",
    "                final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[mask_index,'CrossFreq_SIHCRatio (y2)'] = ratio\n",
    "            elif mask2.empty:\n",
    "                mask1 = mask1.reset_index().iloc[0,:]\n",
    "                total_syns = float(mask1['Synapses'])\n",
    "                total_ihcs = float(mask1['IHCs'])\n",
    "                ratio = total_syns / total_ihcs\n",
    "                # print(total_syns, total_ihcs)\n",
    "                # if total_syns == 0.0 or total_ihcs == 0.0:\n",
    "                #     print(sub, freq)\n",
    "                mask_index = mask.index\n",
    "                final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.loc[mask_index,'CrossFreq_SIHCRatio (y2)'] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Freq(kHz) (x1)</th>\n",
       "      <th>Level(dB) (x2)</th>\n",
       "      <th>Amplitude (x3)</th>\n",
       "      <th>vx (x4)</th>\n",
       "      <th>Strain (x5)</th>\n",
       "      <th>Group - dB (x6)</th>\n",
       "      <th>Group - Time Elapsed</th>\n",
       "      <th>Group</th>\n",
       "      <th>Synapses to IHC (y1)</th>\n",
       "      <th>Synapses</th>\n",
       "      <th>IHCs</th>\n",
       "      <th>Group - Time Elapsed - Split</th>\n",
       "      <th>Group - Time Elapsed - Magn.</th>\n",
       "      <th>Group - Time Elapsed - Unit</th>\n",
       "      <th>Group - Hours Elapsed (x7)</th>\n",
       "      <th>CrossFreq_SIHCRatio (y2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.106536</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.069769</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.161671</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.148119</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.235307</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.376942</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.503456</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.509231</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.724831</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.032338</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>WPZ92</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.841859</td>\n",
       "      <td>v2</td>\n",
       "      <td>C57B6</td>\n",
       "      <td>90</td>\n",
       "      <td>24h</td>\n",
       "      <td>90dB 24h post</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[24, h]</td>\n",
       "      <td>24</td>\n",
       "      <td>h</td>\n",
       "      <td>24</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Freq(kHz) (x1)  Level(dB) (x2)  Amplitude (x3) vx (x4)  \\\n",
       "2834   WPZ92            32.0            10.0        0.106536      v2   \n",
       "2835   WPZ92            32.0            15.0        0.069769      v2   \n",
       "2836   WPZ92            32.0            20.0        0.161671      v2   \n",
       "2837   WPZ92            32.0            25.0        0.148119      v2   \n",
       "2838   WPZ92            32.0            30.0        0.209200      v2   \n",
       "2839   WPZ92            32.0            35.0        0.235307      v2   \n",
       "2840   WPZ92            32.0            40.0        0.376942      v2   \n",
       "2841   WPZ92            32.0            45.0        0.503456      v2   \n",
       "2842   WPZ92            32.0            50.0        0.509231      v2   \n",
       "2843   WPZ92            32.0            60.0        0.724831      v2   \n",
       "2844   WPZ92            32.0            70.0        1.032338      v2   \n",
       "2845   WPZ92            32.0            80.0        0.841859      v2   \n",
       "\n",
       "     Strain (x5)  Group - dB (x6) Group - Time Elapsed          Group  \\\n",
       "2834       C57B6               90                  24h  90dB 24h post   \n",
       "2835       C57B6               90                  24h  90dB 24h post   \n",
       "2836       C57B6               90                  24h  90dB 24h post   \n",
       "2837       C57B6               90                  24h  90dB 24h post   \n",
       "2838       C57B6               90                  24h  90dB 24h post   \n",
       "2839       C57B6               90                  24h  90dB 24h post   \n",
       "2840       C57B6               90                  24h  90dB 24h post   \n",
       "2841       C57B6               90                  24h  90dB 24h post   \n",
       "2842       C57B6               90                  24h  90dB 24h post   \n",
       "2843       C57B6               90                  24h  90dB 24h post   \n",
       "2844       C57B6               90                  24h  90dB 24h post   \n",
       "2845       C57B6               90                  24h  90dB 24h post   \n",
       "\n",
       "      Synapses to IHC (y1)  Synapses IHCs Group - Time Elapsed - Split  \\\n",
       "2834                  16.0     160.0   10                      [24, h]   \n",
       "2835                  16.0     160.0   10                      [24, h]   \n",
       "2836                  16.0     160.0   10                      [24, h]   \n",
       "2837                  16.0     160.0   10                      [24, h]   \n",
       "2838                  16.0     160.0   10                      [24, h]   \n",
       "2839                  16.0     160.0   10                      [24, h]   \n",
       "2840                  16.0     160.0   10                      [24, h]   \n",
       "2841                  16.0     160.0   10                      [24, h]   \n",
       "2842                  16.0     160.0   10                      [24, h]   \n",
       "2843                  16.0     160.0   10                      [24, h]   \n",
       "2844                  16.0     160.0   10                      [24, h]   \n",
       "2845                  16.0     160.0   10                      [24, h]   \n",
       "\n",
       "      Group - Time Elapsed - Magn. Group - Time Elapsed - Unit  \\\n",
       "2834                            24                           h   \n",
       "2835                            24                           h   \n",
       "2836                            24                           h   \n",
       "2837                            24                           h   \n",
       "2838                            24                           h   \n",
       "2839                            24                           h   \n",
       "2840                            24                           h   \n",
       "2841                            24                           h   \n",
       "2842                            24                           h   \n",
       "2843                            24                           h   \n",
       "2844                            24                           h   \n",
       "2845                            24                           h   \n",
       "\n",
       "      Group - Hours Elapsed (x7)  CrossFreq_SIHCRatio (y2)  \n",
       "2834                          24                      16.0  \n",
       "2835                          24                      16.0  \n",
       "2836                          24                      16.0  \n",
       "2837                          24                      16.0  \n",
       "2838                          24                      16.0  \n",
       "2839                          24                      16.0  \n",
       "2840                          24                      16.0  \n",
       "2841                          24                      16.0  \n",
       "2842                          24                      16.0  \n",
       "2843                          24                      16.0  \n",
       "2844                          24                      16.0  \n",
       "2845                          24                      16.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WPZ92\t32.0, WPZ157\t16.0\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx[(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Subject'] == 'WPZ92') & (final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx['Freq(kHz) (x1)'] == 32.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Stratification by Group/Strain..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Strain (x5)'] = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Strain (x5)'].apply(lambda x: 0 if x == 'C57B6' else 1)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Group'] = encoder.fit_transform(pd.DataFrame(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Group']))\n",
    "\n",
    "np.unique(final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.8761, Test RMSE: 2.8129\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.8743, Test RMSE: 2.8196\n",
      "  Train distribution of Strain (x5): {0: 0.8502410503641399, 1: 0.1497589496358601}\n",
      "  Test distribution of Strain (x5): {0: 0.850287120590648, 1: 0.14971287940935193}\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8671, Test RMSE: 2.8489\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8186, Test RMSE: 3.0378\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.8792, Test RMSE: 2.7988\n",
      "  Train distribution of Strain (x5): {0: 0.8502564102564103, 1: 0.14974358974358976}\n",
      "  Test distribution of Strain (x5): {0: 0.850225687320476, 1: 0.149774312679524}\n",
      "\n",
      "Average Train RMSE: 2.8630\n",
      "Average Test RMSE: 2.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.876107116157409,\n",
       "  2.8742805135151,\n",
       "  2.8670516441149805,\n",
       "  2.8185788663873,\n",
       "  2.879227826650186],\n",
       " [2.812929861567098,\n",
       "  2.8195807829938655,\n",
       "  2.8488572060885757,\n",
       "  3.037844671442923,\n",
       "  2.7988193972485713])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded[['Freq(kHz) (x1)', 'Amplitude (x3)', 'Strain (x5)']]\n",
    "y = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['CrossFreq_SIHCRatio (y2)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2, random_state=42, stratify=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Strain (x5)'])\n",
    "\n",
    "model_avg_strat = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model_avg_strat.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model_avg_strat.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test\n",
    "\n",
    "stratified_kfold_by_feature(X, y, model_avg_strat, 'Strain (x5)', n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.8800, Test RMSE: 2.7958\n",
      "  Train distribution of Group: {2: 0.14062980818545492, 1: 0.12667965945225151, 13: 0.09754846650938558, 6: 0.08667555646732998, 3: 0.08503436249871782, 9: 0.062057646938147505, 12: 0.05826238588573187, 7: 0.05744178890142579, 10: 0.056928915786234484, 11: 0.053031080110780594, 4: 0.053031080110780594, 8: 0.05221048312647451, 5: 0.050466714534824084, 0: 0.020002051492460766}\n",
      "  Test distribution of Group: {2: 0.14068908941755537, 1: 0.12674323215750616, 13: 0.09762100082034454, 6: 0.08654634946677604, 3: 0.08490566037735849, 9: 0.061936013125512716, 12: 0.05824446267432322, 7: 0.05742411812961444, 10: 0.05701394585726005, 11: 0.05291222313371616, 4: 0.05291222313371616, 8: 0.052091878589007386, 5: 0.05086136177194422, 0: 0.020098441345365054}\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.8568, Test RMSE: 2.8891\n",
      "  Train distribution of Group: {2: 0.14062980818545492, 1: 0.12667965945225151, 13: 0.09754846650938558, 6: 0.08667555646732998, 3: 0.08503436249871782, 9: 0.062057646938147505, 12: 0.05826238588573187, 7: 0.05744178890142579, 10: 0.056928915786234484, 11: 0.053031080110780594, 4: 0.05292850548774233, 8: 0.05221048312647451, 5: 0.050569289157862345, 0: 0.020002051492460766}\n",
      "  Test distribution of Group: {2: 0.14068908941755537, 1: 0.12674323215750616, 13: 0.09762100082034454, 6: 0.08654634946677604, 3: 0.08490566037735849, 9: 0.061936013125512716, 12: 0.05824446267432322, 7: 0.05742411812961444, 10: 0.05701394585726005, 4: 0.05332239540607055, 11: 0.05291222313371616, 8: 0.052091878589007386, 5: 0.05045118949958983, 0: 0.020098441345365054}\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8559, Test RMSE: 2.8930\n",
      "  Train distribution of Group: {2: 0.14061538461538461, 1: 0.12666666666666668, 13: 0.09753846153846153, 6: 0.08666666666666667, 3: 0.08502564102564103, 9: 0.06194871794871795, 12: 0.058256410256410256, 7: 0.057435897435897436, 10: 0.057025641025641026, 11: 0.05302564102564102, 4: 0.05302564102564102, 8: 0.0521025641025641, 5: 0.05056410256410256, 0: 0.020102564102564103}\n",
      "  Test distribution of Group: {2: 0.1407468198604842, 1: 0.12679524004924086, 13: 0.09766105867870332, 6: 0.08658186294624538, 3: 0.08494050061551088, 9: 0.062371768567911365, 12: 0.058268362741075094, 7: 0.057447681575707836, 10: 0.056627000410340585, 11: 0.05293393516618793, 4: 0.05293393516618793, 8: 0.05252359458350431, 5: 0.05047189167008617, 0: 0.019696347968814115}\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8578, Test RMSE: 2.8853\n",
      "  Train distribution of Group: {2: 0.1407179487179487, 1: 0.12676923076923077, 13: 0.09753846153846153, 6: 0.08656410256410256, 3: 0.08502564102564103, 9: 0.062051282051282054, 12: 0.058256410256410256, 7: 0.057435897435897436, 10: 0.05692307692307692, 4: 0.05302564102564102, 11: 0.05292307692307692, 8: 0.0522051282051282, 5: 0.05056410256410256, 0: 0.02}\n",
      "  Test distribution of Group: {2: 0.14033647927780057, 1: 0.12638489946655723, 13: 0.09766105867870332, 6: 0.08699220352892902, 3: 0.08494050061551088, 9: 0.06196142798522774, 12: 0.058268362741075094, 7: 0.057447681575707836, 10: 0.05703734099302421, 11: 0.053344275748871565, 4: 0.05293393516618793, 8: 0.05211325400082068, 5: 0.05047189167008617, 0: 0.020106688551497744}\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.8658, Test RMSE: 2.8535\n",
      "  Train distribution of Group: {2: 0.14061538461538461, 1: 0.12666666666666668, 13: 0.09764102564102564, 6: 0.08666666666666667, 3: 0.08492307692307692, 9: 0.062051282051282054, 12: 0.058256410256410256, 7: 0.057435897435897436, 10: 0.05692307692307692, 11: 0.05302564102564102, 4: 0.05302564102564102, 8: 0.0522051282051282, 5: 0.05056410256410256, 0: 0.02}\n",
      "  Test distribution of Group: {2: 0.1407468198604842, 1: 0.12679524004924086, 13: 0.09725071809601969, 6: 0.08658186294624538, 3: 0.0853508411981945, 9: 0.06196142798522774, 12: 0.058268362741075094, 7: 0.057447681575707836, 10: 0.05703734099302421, 11: 0.05293393516618793, 4: 0.05293393516618793, 8: 0.05211325400082068, 5: 0.05047189167008617, 0: 0.020106688551497744}\n",
      "\n",
      "Average Train RMSE: 2.8633\n",
      "Average Test RMSE: 2.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.879966966657405,\n",
       "  2.85684376676087,\n",
       "  2.8559312803125674,\n",
       "  2.8578221049862336,\n",
       "  2.865830441249474],\n",
       " [2.7958146695959796,\n",
       "  2.8891188347463856,\n",
       "  2.8930318721133785,\n",
       "  2.8852682674421444,\n",
       "  2.853474340888855])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_g = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded[['Freq(kHz) (x1)', 'Amplitude (x3)', 'Group']]\n",
    "y_g = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['CrossFreq_SIHCRatio (y2)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_g, y_g, shuffle = True, test_size=0.2, random_state=42, stratify=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded['Group'])\n",
    "\n",
    "model_avg_strat_g = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_preds_train = model_avg_strat_g.predict(X_train)\n",
    "RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "y_preds_test = model_avg_strat_g.predict(X_test)\n",
    "RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "RMSE_train, RMSE_test\n",
    "\n",
    "stratified_kfold_by_feature(X_g, y_g, model_avg_strat_g, 'Group', n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded.copy()\n",
    "final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols.rename(columns = {'Freq(kHz) (x1)' : 'FreqkHz', 'Level(dB) (x2)': 'LeveldB', 'Amplitude (x3)' : 'Amplitude', 'CrossFreq_SIHCRatio (y2)' : 'CrossFreqSIHCRatio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FreqkHz</th>\n",
       "      <td>812.289031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.721786</td>\n",
       "      <td>6.490847e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeveldB</th>\n",
       "      <td>6049.797561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>794.846634</td>\n",
       "      <td>1.834454e-169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amplitude</th>\n",
       "      <td>5342.640872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>701.937556</td>\n",
       "      <td>1.977891e-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FreqkHz:Amplitude</th>\n",
       "      <td>997.417925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.044762</td>\n",
       "      <td>3.453416e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>92720.571153</td>\n",
       "      <td>12182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sum_sq       df           F         PR(>F)\n",
       "FreqkHz              812.289031      1.0  106.721786   6.490847e-25\n",
       "LeveldB             6049.797561      1.0  794.846634  1.834454e-169\n",
       "Amplitude           5342.640872      1.0  701.937556  1.977891e-150\n",
       "FreqkHz:Amplitude    997.417925      1.0  131.044762   3.453416e-30\n",
       "Residual           92720.571153  12182.0         NaN            NaN"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude + FreqkHz*Amplitude', data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     CrossFreqSIHCRatio   R-squared:                       0.094\n",
      "Model:                            OLS   Adj. R-squared:                  0.094\n",
      "Method:                 Least Squares   F-statistic:                     422.5\n",
      "Date:                Tue, 01 Apr 2025   Prob (F-statistic):          4.18e-261\n",
      "Time:                        23:02:43   Log-Likelihood:                -29723.\n",
      "No. Observations:               12187   AIC:                         5.945e+04\n",
      "Df Residuals:                   12183   BIC:                         5.948e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     16.9107      0.072    233.672      0.000      16.769      17.053\n",
      "FreqkHz       -0.0208      0.002    -10.276      0.000      -0.025      -0.017\n",
      "Amplitude      1.8142      0.069     26.354      0.000       1.679       1.949\n",
      "LeveldB       -0.0436      0.002    -28.386      0.000      -0.047      -0.041\n",
      "==============================================================================\n",
      "Omnibus:                     1353.972   Durbin-Watson:                   0.116\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1860.006\n",
      "Skew:                          -0.898   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.662   Cond. No.                         159.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Partial F-test for FreqkHz*LeveldB:\n",
      "   df_resid           ssr  df_diff     ss_diff          F        Pr(>F)\n",
      "0   12183.0  93717.989078      0.0         NaN        NaN           NaN\n",
      "1   12182.0  93507.692502      1.0  210.296576  27.397028  1.684402e-07\n",
      "\n",
      "Partial F-test for FreqkHz*Amplitude:\n",
      "   df_resid           ssr  df_diff     ss_diff           F        Pr(>F)\n",
      "0   12183.0  93717.989078      0.0         NaN         NaN           NaN\n",
      "1   12182.0  92720.571153      1.0  997.417925  131.044762  3.453416e-30\n",
      "\n",
      "Partial F-test for LeveldB*Amplitude:\n",
      "   df_resid           ssr  df_diff     ss_diff          F    Pr(>F)\n",
      "0   12183.0  93717.989078      0.0         NaN        NaN       NaN\n",
      "1   12182.0  93545.210516      1.0  172.778562  22.500227  0.000002\n",
      "\n",
      "Partial F-test for ALL together:\n",
      "   df_resid           ssr  df_diff      ss_diff           F        Pr(>F)\n",
      "0   12183.0  93717.989078      0.0          NaN         NaN           NaN\n",
      "1   12180.0  91198.647889      3.0  2519.341188  112.156545  1.225536e-71\n"
     ]
    }
   ],
   "source": [
    "full_model = ols('CrossFreqSIHCRatio ~ FreqkHz + Amplitude + LeveldB', \n",
    "                data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"Full Model Summary:\")\n",
    "print(full_model.summary())\n",
    "\n",
    "# Partial F-test for Amplitude\n",
    "# reduced_model1 = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB', \n",
    "#                     data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "# print(\"\\nPartial F-test for Amplitude:\")\n",
    "# print(anova_lm(reduced_model1, full_model))\n",
    "\n",
    "# # Partial F-test for FreqkHz\n",
    "# reduced_model2 = ols('CrossFreqSIHCRatio ~ LeveldB + Amplitude', \n",
    "#                     data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "# print(\"\\nPartial F-test for FreqkHz:\")\n",
    "# print(anova_lm(reduced_model2, full_model))\n",
    "\n",
    "# # Partial F-test for LeveldB\n",
    "# reduced_model3 = ols('CrossFreqSIHCRatio ~ FreqkHz + Amplitude', \n",
    "#                     data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "# print(\"\\nPartial F-test for LeveldB:\")\n",
    "# print(anova_lm(reduced_model3, full_model))\n",
    "\n",
    "# # Partial F-test for FreqkHz and LeveldB jointly\n",
    "# reduced_model4 = ols('CrossFreqSIHCRatio ~ Amplitude', \n",
    "#                     data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "# print(\"\\nPartial F-test for FreqkHz and LeveldB together:\")\n",
    "# print(anova_lm(reduced_model4, full_model))\n",
    "\n",
    "# Testing interactions \n",
    "\n",
    "#  + FreqkHz*LeveldB + LeveldB*Amplitude + FreqkHz*Amplitude + FreqkHz*LeveldB*Amplitude\n",
    "\n",
    "reduced_model5 = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude + FreqkHz*LeveldB', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz*LeveldB:\")\n",
    "print(anova_lm(full_model, reduced_model5))\n",
    "\n",
    "# Partial F-test for FreqkHz\n",
    "reduced_model6 = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude + FreqkHz*Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for FreqkHz*Amplitude:\")\n",
    "print(anova_lm(full_model, reduced_model6))\n",
    "\n",
    "# Partial F-test for LeveldB\n",
    "reduced_model7 = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude + LeveldB*Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for LeveldB*Amplitude:\")\n",
    "print(anova_lm(full_model, reduced_model7))\n",
    "\n",
    "# # Partial F-test for FreqkHz and LeveldB jointly\n",
    "reduced_model8 = ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude + FreqkHz*LeveldB + FreqkHz*Amplitude + LeveldB*Amplitude + FreqkHz*Amplitude', \n",
    "                    data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(\"\\nPartial F-test for ALL together:\")\n",
    "print(anova_lm(full_model, reduced_model8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With freq*amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.8634, Test RMSE: 2.7797\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.8400, Test RMSE: 2.8739\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8384, Test RMSE: 2.8805\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8410, Test RMSE: 2.8703\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.8514, Test RMSE: 2.8285\n",
      "\n",
      "Average Train RMSE: 2.8468\n",
      "Average Test RMSE: 2.8466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.8633894674703457,\n",
       "  2.8400406735756554,\n",
       "  2.8383821283531283,\n",
       "  2.8409508143625306,\n",
       "  2.8514207318421323],\n",
       " [2.779740745751265,\n",
       "  2.873928949589066,\n",
       "  2.8804906660813816,\n",
       "  2.8703415846632523,\n",
       "  2.8285008855825273])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_g = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols[['FreqkHz', 'LeveldB','Amplitude', 'Group']]\n",
    "y_g = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols['CrossFreqSIHCRatio']\n",
    "\n",
    "model_final = smf.ols('CrossFreqSIHCRatio ~ FreqkHz + Amplitude + FreqkHz*Amplitude', data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "# stratified_kfold_by_feature(X, y, model_int, 'Strain (x5)', n_splits=5, random_state=42)\n",
    "# CV_modeltesting(5, X, y, model_int)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2)\n",
    "\n",
    "# y_preds_train = model_final.predict(X_train)\n",
    "# RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "# y_preds_test = model_final.predict(X_test)\n",
    "# RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "# RMSE_train, RMSE_test\n",
    "\n",
    "stratified_kfold_by_feature2(X_g, y_g, model_final, 'Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.8591, Test RMSE: 2.7973\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.8561, Test RMSE: 2.8094\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8519, Test RMSE: 2.8266\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8038, Test RMSE: 3.0128\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.8629, Test RMSE: 2.7818\n",
      "\n",
      "Average Train RMSE: 2.8468\n",
      "Average Test RMSE: 2.8456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.8591103256468577,\n",
       "  2.856136125559016,\n",
       "  2.851884276324155,\n",
       "  2.8038325598085154,\n",
       "  2.862884143136819],\n",
       " [2.797298345590854,\n",
       "  2.809421695573092,\n",
       "  2.8266305290599685,\n",
       "  3.0128277066905222,\n",
       "  2.7817875174949043])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_s = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols[['FreqkHz', 'LeveldB','Amplitude', 'Strain (x5)']]\n",
    "y_s = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols['CrossFreqSIHCRatio']\n",
    "\n",
    "model_final = smf.ols('CrossFreqSIHCRatio ~ FreqkHz + Amplitude + FreqkHz*Amplitude', data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "# stratified_kfold_by_feature(X, y, model_int, 'Strain (x5)', n_splits=5, random_state=42)\n",
    "# CV_modeltesting(5, X, y, model_int)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size=0.2)\n",
    "\n",
    "# y_preds_train = model_final.predict(X_train)\n",
    "# RMSE_train = np.sqrt(np.mean((y_train - y_preds_train)**2))\n",
    "\n",
    "# y_preds_test = model_final.predict(X_test)\n",
    "# RMSE_test = np.sqrt(np.mean((y_test - y_preds_test)**2))\n",
    "\n",
    "# RMSE_train, RMSE_test\n",
    "\n",
    "stratified_kfold_by_feature2(X_s, y_s, model_final, 'Strain (x5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1\n",
      "Fold 1 - Train RMSE: 2.8591, Test RMSE: 2.7973\n",
      "Processing Fold 2\n",
      "Fold 2 - Train RMSE: 2.8561, Test RMSE: 2.8094\n",
      "Processing Fold 3\n",
      "Fold 3 - Train RMSE: 2.8519, Test RMSE: 2.8266\n",
      "Processing Fold 4\n",
      "Fold 4 - Train RMSE: 2.8038, Test RMSE: 3.0128\n",
      "Processing Fold 5\n",
      "Fold 5 - Train RMSE: 2.8629, Test RMSE: 2.7818\n",
      "\n",
      "Average Train RMSE: 2.8468\n",
      "Average Test RMSE: 2.8456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.8591103256468577,\n",
       "  2.856136125559016,\n",
       "  2.851884276324155,\n",
       "  2.8038325598085154,\n",
       "  2.862884143136819],\n",
       " [2.797298345590854,\n",
       "  2.809421695573092,\n",
       "  2.8266305290599685,\n",
       "  3.0128277066905222,\n",
       "  2.7817875174949043])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratified_kfold_by_feature2(X, y, model_final, 'Strain (x5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge - Final Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.001,\n",
       "  'RMSE_train': 2.8455834814304968,\n",
       "  'RMSE_test': 2.852246833174837,\n",
       "  'diff': -0.006663351744340407},\n",
       " {'alpha': 0.01,\n",
       "  'RMSE_train': 2.8498024244913065,\n",
       "  'RMSE_test': 2.8555310747296168,\n",
       "  'diff': -0.005728650238310262},\n",
       " {'alpha': 0.1,\n",
       "  'RMSE_train': 3.178524520793153,\n",
       "  'RMSE_test': 3.1793500112421538,\n",
       "  'diff': -0.0008254904490008208},\n",
       " {'alpha': 1.0,\n",
       "  'RMSE_train': 8.127294857570236,\n",
       "  'RMSE_test': 8.130828026361188,\n",
       "  'diff': -0.0035331687909518905}]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_cols = ['FreqkHz','Amplitude']\n",
    "\n",
    "X_s = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols[['FreqkHz','Amplitude', 'Strain (x5)']]\n",
    "y_s = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols['CrossFreqSIHCRatio']\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    np.arange(len(X_s)), \n",
    "    shuffle=True, \n",
    "    test_size=0.2, \n",
    "    stratify=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols['Strain (x5)'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_data = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols.iloc[train_indices].copy()\n",
    "test_data = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols.iloc[test_indices].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data[numerical_cols])\n",
    "\n",
    "for col in numerical_cols:\n",
    "    scaler.fit(train_data[[col]])\n",
    "    train_data[f'{col}_scaled'] = scaler.transform(train_data[[col]])\n",
    "    test_data[f'{col}_scaled'] = scaler.transform(test_data[[col]])\n",
    "\n",
    "alphas = [0.001, 0.01, 0.1, 1.0]\n",
    "ridge_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    model_ridge = smf.ols('CrossFreqSIHCRatio ~ FreqkHz_scaled + Amplitude_scaled + FreqkHz_scaled*Amplitude_scaled', \n",
    "                         data=train_data).fit_regularized(L1_wt=0.0, alpha=alpha)\n",
    "    \n",
    "\n",
    "    y_preds_train = model_ridge.predict(train_data)\n",
    "    RMSE_train = np.sqrt(mean_squared_error(train_data['CrossFreqSIHCRatio'], y_preds_train))\n",
    "    \n",
    "    y_preds_test = model_ridge.predict(test_data)\n",
    "    RMSE_test = np.sqrt(mean_squared_error(test_data['CrossFreqSIHCRatio'], y_preds_test))\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'alpha': alpha,\n",
    "        'RMSE_train': RMSE_train,\n",
    "        'RMSE_test': RMSE_test,\n",
    "        'diff': RMSE_train - RMSE_test\n",
    "    })\n",
    "\n",
    "ridge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5: Train RMSE = 2.8208, Test RMSE = 2.9598\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9629, Test data points: 2558\n",
      "Fold 2/5: Train RMSE = 2.9051, Test RMSE = 2.7002\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9614, Test data points: 2573\n",
      "Fold 3/5: Train RMSE = 2.9207, Test RMSE = 2.5550\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9795, Test data points: 2392\n",
      "Fold 4/5: Train RMSE = 2.7828, Test RMSE = 3.1262\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9913, Test data points: 2274\n",
      "Fold 5/5: Train RMSE = 2.8111, Test RMSE = 3.0188\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9797, Test data points: 2390\n",
      "\n",
      "Final Results - Avg Train RMSE = 2.84809, Avg Test RMSE = 2.87200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.8480949151079744, 2.8719961215263488)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_s = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols[['FreqkHz','Amplitude','Strain (x5)']]\n",
    "y_s = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols['CrossFreqSIHCRatio']\n",
    "stratified_grouped_kfold_by_feature_ridge(X = X_s, y= y_s, data = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols, stratify_col = 'Strain (x5)', group_col='Subject', n_splits=5, numerical_cols=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5: Train RMSE = 2.8013, Test RMSE = 3.0530\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9883, Test data points: 2304\n",
      "Fold 2/5: Train RMSE = 2.8133, Test RMSE = 2.9886\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9856, Test data points: 2331\n",
      "Fold 3/5: Train RMSE = 2.7722, Test RMSE = 3.1319\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9665, Test data points: 2522\n",
      "Fold 4/5: Train RMSE = 2.9242, Test RMSE = 2.6332\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9475, Test data points: 2712\n",
      "Fold 5/5: Train RMSE = 2.9339, Test RMSE = 2.4790\n",
      "              Train groups: 84, Test groups: 21\n",
      "              Train data points: 9869, Test data points: 2318\n",
      "\n",
      "Final Results - Avg Train RMSE = 2.84898, Avg Test RMSE = 2.85715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.8489799511738716, 2.8571476500446336)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_g = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols[['FreqkHz','Amplitude', 'Group']]\n",
    "y_g = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols['CrossFreqSIHCRatio']\n",
    "stratified_grouped_kfold_by_feature_ridge(X = X_g, y= y_g, data = final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols, stratify_col = 'Group', group_col='Subject', n_splits=5, numerical_cols=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     CrossFreqSIHCRatio   R-squared:                       0.119\n",
      "Model:                            OLS   Adj. R-squared:                  0.118\n",
      "Method:                 Least Squares   F-statistic:                     234.2\n",
      "Date:                Tue, 01 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        22:22:32   Log-Likelihood:                -29556.\n",
      "No. Observations:               12187   AIC:                         5.913e+04\n",
      "Df Residuals:                   12179   BIC:                         5.919e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    15.8887      0.154    103.254      0.000      15.587      16.190\n",
      "FreqkHz                       0.0143      0.006      2.318      0.020       0.002       0.026\n",
      "LeveldB                      -0.0016      0.003     -0.455      0.649      -0.008       0.005\n",
      "Amplitude                    -0.3990      0.579     -0.689      0.491      -1.535       0.737\n",
      "FreqkHz:Amplitude             0.1283      0.025      5.146      0.000       0.079       0.177\n",
      "FreqkHz:LeveldB              -0.0016      0.000    -12.159      0.000      -0.002      -0.001\n",
      "Amplitude:LeveldB            -0.0012      0.008     -0.149      0.882      -0.017       0.014\n",
      "FreqkHz:Amplitude:LeveldB    -0.0003      0.000     -0.956      0.339      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     1450.612   Durbin-Watson:                   0.117\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2055.634\n",
      "Skew:                          -0.924   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.798   Cond. No.                     3.57e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.57e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model_ols = smf.ols('CrossFreqSIHCRatio ~ FreqkHz + LeveldB + Amplitude + FreqkHz*Amplitude + FreqkHz*Amplitude*LeveldB', data=final_clean_strained_grouped_pos_cleangroup_vs_timed2_avgvx_encoded_ols).fit()\n",
    "print(model_ols.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_manorimagepred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
